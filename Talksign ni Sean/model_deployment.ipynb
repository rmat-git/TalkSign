{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b3f1d2d-3e5c-4139-8030-ca2c8e51d677",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy<2\n",
      "  Using cached numpy-1.26.4-cp311-cp311-win_amd64.whl.metadata (61 kB)\n",
      "Using cached numpy-1.26.4-cp311-cp311-win_amd64.whl (15.8 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.4.0\n",
      "    Uninstalling numpy-2.4.0:\n",
      "      Successfully uninstalled numpy-2.4.0\n",
      "Successfully installed numpy-1.26.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\User\\Desktop\\JUPYTER NOTEBOOK\\my_venv\\Lib\\site-packages\\~.mpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\User\\Desktop\\JUPYTER NOTEBOOK\\my_venv\\Lib\\site-packages\\~=mpy'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-hub 0.16.1 requires tf-keras>=2.14.1, which is not installed.\n",
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Force install NumPy 1.x (compatible with everything)\n",
    "!pip install \"numpy<2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5df9b344-f881-4233-a333-34586c84425f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: mediapipe 0.10.31\n",
      "Uninstalling mediapipe-0.10.31:\n",
      "  Successfully uninstalled mediapipe-0.10.31\n",
      "Collecting mediapipe==0.10.11\n",
      "  Downloading mediapipe-0.10.11-cp311-cp311-win_amd64.whl.metadata (9.8 kB)\n",
      "Collecting absl-py (from mediapipe==0.10.11)\n",
      "  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting attrs>=19.1.0 (from mediapipe==0.10.11)\n",
      "  Downloading attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting flatbuffers>=2.0 (from mediapipe==0.10.11)\n",
      "  Downloading flatbuffers-25.12.19-py2.py3-none-any.whl.metadata (1.0 kB)\n",
      "Collecting jax (from mediapipe==0.10.11)\n",
      "  Downloading jax-0.8.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting matplotlib (from mediapipe==0.10.11)\n",
      "  Downloading matplotlib-3.10.8-cp311-cp311-win_amd64.whl.metadata (52 kB)\n",
      "Collecting numpy (from mediapipe==0.10.11)\n",
      "  Downloading numpy-2.4.0-cp311-cp311-win_amd64.whl.metadata (6.6 kB)\n",
      "Collecting opencv-contrib-python (from mediapipe==0.10.11)\n",
      "  Downloading opencv_contrib_python-4.12.0.88-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Collecting protobuf<4,>=3.11 (from mediapipe==0.10.11)\n",
      "  Downloading protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\n",
      "Collecting sounddevice>=0.4.4 (from mediapipe==0.10.11)\n",
      "  Downloading sounddevice-0.5.3-py3-none-win_amd64.whl.metadata (1.6 kB)\n",
      "Collecting CFFI>=1.0 (from sounddevice>=0.4.4->mediapipe==0.10.11)\n",
      "  Downloading cffi-2.0.0-cp311-cp311-win_amd64.whl.metadata (2.6 kB)\n",
      "Collecting pycparser (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe==0.10.11)\n",
      "  Downloading pycparser-2.23-py3-none-any.whl.metadata (993 bytes)\n",
      "Collecting jaxlib<=0.8.2,>=0.8.2 (from jax->mediapipe==0.10.11)\n",
      "  Downloading jaxlib-0.8.2-cp311-cp311-win_amd64.whl.metadata (1.4 kB)\n",
      "Collecting ml_dtypes>=0.5.0 (from jax->mediapipe==0.10.11)\n",
      "  Downloading ml_dtypes-0.5.4-cp311-cp311-win_amd64.whl.metadata (9.2 kB)\n",
      "Collecting opt_einsum (from jax->mediapipe==0.10.11)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting scipy>=1.13 (from jax->mediapipe==0.10.11)\n",
      "  Downloading scipy-1.16.3-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib->mediapipe==0.10.11)\n",
      "  Downloading contourpy-1.3.3-cp311-cp311-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib->mediapipe==0.10.11)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib->mediapipe==0.10.11)\n",
      "  Downloading fonttools-4.61.1-cp311-cp311-win_amd64.whl.metadata (116 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib->mediapipe==0.10.11)\n",
      "  Downloading kiwisolver-1.4.9-cp311-cp311-win_amd64.whl.metadata (6.4 kB)\n",
      "Collecting packaging>=20.0 (from matplotlib->mediapipe==0.10.11)\n",
      "  Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting pillow>=8 (from matplotlib->mediapipe==0.10.11)\n",
      "  Downloading pillow-12.1.0-cp311-cp311-win_amd64.whl.metadata (9.0 kB)\n",
      "Collecting pyparsing>=3 (from matplotlib->mediapipe==0.10.11)\n",
      "  Downloading pyparsing-3.3.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting python-dateutil>=2.7 (from matplotlib->mediapipe==0.10.11)\n",
      "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting six>=1.5 (from python-dateutil>=2.7->matplotlib->mediapipe==0.10.11)\n",
      "  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting numpy (from mediapipe==0.10.11)\n",
      "  Downloading numpy-2.2.6-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "Downloading mediapipe-0.10.11-cp311-cp311-win_amd64.whl (50.8 MB)\n",
      "   ---------------------------------------- 0.0/50.8 MB ? eta -:--:--\n",
      "   - -------------------------------------- 1.8/50.8 MB 11.2 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 7.6/50.8 MB 29.4 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 12.8/50.8 MB 24.4 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 21.0/50.8 MB 27.6 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 35.7/50.8 MB 37.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 50.8/50.8 MB 43.7 MB/s  0:00:01\n",
      "Downloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
      "Downloading attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "Downloading flatbuffers-25.12.19-py2.py3-none-any.whl (26 kB)\n",
      "Downloading sounddevice-0.5.3-py3-none-win_amd64.whl (364 kB)\n",
      "Downloading cffi-2.0.0-cp311-cp311-win_amd64.whl (182 kB)\n",
      "Downloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Downloading jax-0.8.2-py3-none-any.whl (2.9 MB)\n",
      "   ---------------------------------------- 0.0/2.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.9/2.9 MB 85.9 MB/s  0:00:00\n",
      "Downloading jaxlib-0.8.2-cp311-cp311-win_amd64.whl (60.3 MB)\n",
      "   ---------------------------------------- 0.0/60.3 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 15.5/60.3 MB 74.9 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 30.9/60.3 MB 72.9 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 38.5/60.3 MB 61.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 45.9/60.3 MB 54.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 54.5/60.3 MB 51.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 60.3/60.3 MB 49.9 MB/s  0:00:01\n",
      "Downloading ml_dtypes-0.5.4-cp311-cp311-win_amd64.whl (210 kB)\n",
      "Downloading scipy-1.16.3-cp311-cp311-win_amd64.whl (38.7 MB)\n",
      "   ---------------------------------------- 0.0/38.7 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 7.6/38.7 MB 39.3 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 15.2/38.7 MB 36.8 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 22.5/38.7 MB 36.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 30.7/38.7 MB 37.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.0/38.7 MB 37.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 38.7/38.7 MB 37.3 MB/s  0:00:01\n",
      "Downloading matplotlib-3.10.8-cp311-cp311-win_amd64.whl (8.1 MB)\n",
      "   ---------------------------------------- 0.0/8.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 8.1/8.1 MB 38.6 MB/s  0:00:00\n",
      "Downloading contourpy-1.3.3-cp311-cp311-win_amd64.whl (225 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.61.1-cp311-cp311-win_amd64.whl (2.3 MB)\n",
      "   ---------------------------------------- 0.0/2.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.3/2.3 MB 44.0 MB/s  0:00:00\n",
      "Downloading kiwisolver-1.4.9-cp311-cp311-win_amd64.whl (73 kB)\n",
      "Downloading packaging-25.0-py3-none-any.whl (66 kB)\n",
      "Downloading pillow-12.1.0-cp311-cp311-win_amd64.whl (7.0 MB)\n",
      "   ---------------------------------------- 0.0/7.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 7.0/7.0 MB 39.4 MB/s  0:00:00\n",
      "Downloading pyparsing-3.3.1-py3-none-any.whl (121 kB)\n",
      "Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "Downloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
      "Downloading opencv_contrib_python-4.12.0.88-cp37-abi3-win_amd64.whl (45.3 MB)\n",
      "   ---------------------------------------- 0.0/45.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 8.4/45.3 MB 40.0 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 16.8/45.3 MB 40.7 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 24.9/45.3 MB 40.5 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 33.0/45.3 MB 40.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 41.7/45.3 MB 40.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 45.3/45.3 MB 40.6 MB/s  0:00:01\n",
      "Downloading numpy-2.2.6-cp311-cp311-win_amd64.whl (12.9 MB)\n",
      "   ---------------------------------------- 0.0/12.9 MB ? eta -:--:--\n",
      "   ------------------------- -------------- 8.4/12.9 MB 40.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.9/12.9 MB 40.5 MB/s  0:00:00\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading pycparser-2.23-py3-none-any.whl (118 kB)\n",
      "Installing collected packages: flatbuffers, six, pyparsing, pycparser, protobuf, pillow, packaging, opt_einsum, numpy, kiwisolver, fonttools, cycler, attrs, absl-py, scipy, python-dateutil, opencv-contrib-python, ml_dtypes, contourpy, CFFI, sounddevice, matplotlib, jaxlib, jax, mediapipe\n",
      "\n",
      "  Attempting uninstall: flatbuffers\n",
      "\n",
      "    Found existing installation: flatbuffers 25.12.19\n",
      "\n",
      "    Uninstalling flatbuffers-25.12.19:\n",
      "\n",
      "      Successfully uninstalled flatbuffers-25.12.19\n",
      "\n",
      "  Attempting uninstall: six\n",
      "\n",
      "    Found existing installation: six 1.17.0\n",
      "\n",
      "    Uninstalling six-1.17.0:\n",
      "\n",
      "   - --------------------------------------  1/25 [six]\n",
      "   - --------------------------------------  1/25 [six]\n",
      "   - --------------------------------------  1/25 [six]\n",
      "   - --------------------------------------  1/25 [six]\n",
      "   - --------------------------------------  1/25 [six]\n",
      "   - --------------------------------------  1/25 [six]\n",
      "   - --------------------------------------  1/25 [six]\n",
      "   - --------------------------------------  1/25 [six]\n",
      "   - --------------------------------------  1/25 [six]\n",
      "   - --------------------------------------  1/25 [six]\n",
      "   - --------------------------------------  1/25 [six]\n",
      "      Successfully uninstalled six-1.17.0\n",
      "   - --------------------------------------  1/25 [six]\n",
      "  Attempting uninstall: pyparsing\n",
      "   - --------------------------------------  1/25 [six]\n",
      "    Found existing installation: pyparsing 3.2.3\n",
      "   - --------------------------------------  1/25 [six]\n",
      "    Uninstalling pyparsing-3.2.3:\n",
      "   - --------------------------------------  1/25 [six]\n",
      "      Successfully uninstalled pyparsing-3.2.3\n",
      "   - --------------------------------------  1/25 [six]\n",
      "   --- ------------------------------------  2/25 [pyparsing]\n",
      "  Attempting uninstall: pycparser\n",
      "   --- ------------------------------------  2/25 [pyparsing]\n",
      "    Found existing installation: pycparser 2.23\n",
      "   --- ------------------------------------  2/25 [pyparsing]\n",
      "    Uninstalling pycparser-2.23:\n",
      "   --- ------------------------------------  2/25 [pyparsing]\n",
      "      Successfully uninstalled pycparser-2.23\n",
      "   --- ------------------------------------  2/25 [pyparsing]\n",
      "   ---- -----------------------------------  3/25 [pycparser]\n",
      "   ---- -----------------------------------  3/25 [pycparser]\n",
      "  Attempting uninstall: protobuf\n",
      "   ---- -----------------------------------  3/25 [pycparser]\n",
      "    Found existing installation: protobuf 6.33.2\n",
      "   ---- -----------------------------------  3/25 [pycparser]\n",
      "    Uninstalling protobuf-6.33.2:\n",
      "   ---- -----------------------------------  3/25 [pycparser]\n",
      "      Successfully uninstalled protobuf-6.33.2\n",
      "   ---- -----------------------------------  3/25 [pycparser]\n",
      "   ------ ---------------------------------  4/25 [protobuf]\n",
      "   ------ ---------------------------------  4/25 [protobuf]\n",
      "   ------ ---------------------------------  4/25 [protobuf]\n",
      "   ------ ---------------------------------  4/25 [protobuf]\n",
      "   ------ ---------------------------------  4/25 [protobuf]\n",
      "   ------ ---------------------------------  4/25 [protobuf]\n",
      "   ------ ---------------------------------  4/25 [protobuf]\n",
      "   ------ ---------------------------------  4/25 [protobuf]\n",
      "   ------ ---------------------------------  4/25 [protobuf]\n",
      "   ------ ---------------------------------  4/25 [protobuf]\n",
      "   ------ ---------------------------------  4/25 [protobuf]\n",
      "   ------ ---------------------------------  4/25 [protobuf]\n",
      "   ------ ---------------------------------  4/25 [protobuf]\n",
      "   ------ ---------------------------------  4/25 [protobuf]\n",
      "   ------ ---------------------------------  4/25 [protobuf]\n",
      "   ------ ---------------------------------  4/25 [protobuf]\n",
      "   ------ ---------------------------------  4/25 [protobuf]\n",
      "   ------ ---------------------------------  4/25 [protobuf]\n",
      "   ------ ---------------------------------  4/25 [protobuf]\n",
      "   ------ ---------------------------------  4/25 [protobuf]\n",
      "   ------ ---------------------------------  4/25 [protobuf]\n",
      "  Attempting uninstall: pillow\n",
      "   ------ ---------------------------------  4/25 [protobuf]\n",
      "    Found existing installation: pillow 11.3.0\n",
      "   ------ ---------------------------------  4/25 [protobuf]\n",
      "   -------- -------------------------------  5/25 [pillow]\n",
      "    Uninstalling pillow-11.3.0:\n",
      "   -------- -------------------------------  5/25 [pillow]\n",
      "      Successfully uninstalled pillow-11.3.0\n",
      "   -------- -------------------------------  5/25 [pillow]\n",
      "   -------- -------------------------------  5/25 [pillow]\n",
      "   -------- -------------------------------  5/25 [pillow]\n",
      "   -------- -------------------------------  5/25 [pillow]\n",
      "   -------- -------------------------------  5/25 [pillow]\n",
      "   -------- -------------------------------  5/25 [pillow]\n",
      "   -------- -------------------------------  5/25 [pillow]\n",
      "   -------- -------------------------------  5/25 [pillow]\n",
      "   -------- -------------------------------  5/25 [pillow]\n",
      "   -------- -------------------------------  5/25 [pillow]\n",
      "   -------- -------------------------------  5/25 [pillow]\n",
      "   -------- -------------------------------  5/25 [pillow]\n",
      "   -------- -------------------------------  5/25 [pillow]\n",
      "   -------- -------------------------------  5/25 [pillow]\n",
      "   -------- -------------------------------  5/25 [pillow]\n",
      "   -------- -------------------------------  5/25 [pillow]\n",
      "   -------- -------------------------------  5/25 [pillow]\n",
      "   -------- -------------------------------  5/25 [pillow]\n",
      "   -------- -------------------------------  5/25 [pillow]\n",
      "   -------- -------------------------------  5/25 [pillow]\n",
      "   -------- -------------------------------  5/25 [pillow]\n",
      "   -------- -------------------------------  5/25 [pillow]\n",
      "   -------- -------------------------------  5/25 [pillow]\n",
      "   -------- -------------------------------  5/25 [pillow]\n",
      "   -------- -------------------------------  5/25 [pillow]\n",
      "  Attempting uninstall: packaging\n",
      "   -------- -------------------------------  5/25 [pillow]\n",
      "    Found existing installation: packaging 25.0\n",
      "   -------- -------------------------------  5/25 [pillow]\n",
      "    Uninstalling packaging-25.0:\n",
      "   -------- -------------------------------  5/25 [pillow]\n",
      "      Successfully uninstalled packaging-25.0\n",
      "   -------- -------------------------------  5/25 [pillow]\n",
      "   --------- ------------------------------  6/25 [packaging]\n",
      "  Attempting uninstall: opt_einsum\n",
      "   --------- ------------------------------  6/25 [packaging]\n",
      "    Found existing installation: opt_einsum 3.4.0\n",
      "   --------- ------------------------------  6/25 [packaging]\n",
      "    Uninstalling opt_einsum-3.4.0:\n",
      "   --------- ------------------------------  6/25 [packaging]\n",
      "      Successfully uninstalled opt_einsum-3.4.0\n",
      "   --------- ------------------------------  6/25 [packaging]\n",
      "   ----------- ----------------------------  7/25 [opt_einsum]\n",
      "   ----------- ----------------------------  7/25 [opt_einsum]\n",
      "  Attempting uninstall: numpy\n",
      "   ----------- ----------------------------  7/25 [opt_einsum]\n",
      "    Found existing installation: numpy 1.26.4\n",
      "   ----------- ----------------------------  7/25 [opt_einsum]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "    Uninstalling numpy-1.26.4:\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "  Attempting uninstall: kiwisolver\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "    Found existing installation: kiwisolver 1.4.8\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "    Uninstalling kiwisolver-1.4.8:\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "      Successfully uninstalled kiwisolver-1.4.8\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   -------------- -------------------------  9/25 [kiwisolver]\n",
      "   -------------- -------------------------  9/25 [kiwisolver]\n",
      "   -------------- -------------------------  9/25 [kiwisolver]\n",
      "   -------------- -------------------------  9/25 [kiwisolver]\n",
      "   -------------- -------------------------  9/25 [kiwisolver]\n",
      "   -------------- -------------------------  9/25 [kiwisolver]\n",
      "   -------------- -------------------------  9/25 [kiwisolver]\n",
      "   -------------- -------------------------  9/25 [kiwisolver]\n",
      "   -------------- -------------------------  9/25 [kiwisolver]\n",
      "   -------------- -------------------------  9/25 [kiwisolver]\n",
      "   -------------- -------------------------  9/25 [kiwisolver]\n",
      "   -------------- -------------------------  9/25 [kiwisolver]\n",
      "   -------------- -------------------------  9/25 [kiwisolver]\n",
      "   -------------- -------------------------  9/25 [kiwisolver]\n",
      "   -------------- -------------------------  9/25 [kiwisolver]\n",
      "   -------------- -------------------------  9/25 [kiwisolver]\n",
      "   -------------- -------------------------  9/25 [kiwisolver]\n",
      "  Attempting uninstall: fonttools\n",
      "   -------------- -------------------------  9/25 [kiwisolver]\n",
      "   ---------------- ----------------------- 10/25 [fonttools]\n",
      "    Found existing installation: fonttools 4.59.0\n",
      "   ---------------- ----------------------- 10/25 [fonttools]\n",
      "    Uninstalling fonttools-4.59.0:\n",
      "   ---------------- ----------------------- 10/25 [fonttools]\n",
      "      Successfully uninstalled fonttools-4.59.0\n",
      "   ---------------- ----------------------- 10/25 [fonttools]\n",
      "   ---------------- ----------------------- 10/25 [fonttools]\n",
      "   ---------------- ----------------------- 10/25 [fonttools]\n",
      "   ---------------- ----------------------- 10/25 [fonttools]\n",
      "   ---------------- ----------------------- 10/25 [fonttools]\n",
      "   ---------------- ----------------------- 10/25 [fonttools]\n",
      "   ---------------- ----------------------- 10/25 [fonttools]\n",
      "   ---------------- ----------------------- 10/25 [fonttools]\n",
      "   ---------------- ----------------------- 10/25 [fonttools]\n",
      "   ---------------- ----------------------- 10/25 [fonttools]\n",
      "   ---------------- ----------------------- 10/25 [fonttools]\n",
      "   ---------------- ----------------------- 10/25 [fonttools]\n",
      "   ---------------- ----------------------- 10/25 [fonttools]\n",
      "   ---------------- ----------------------- 10/25 [fonttools]\n",
      "   ---------------- ----------------------- 10/25 [fonttools]\n",
      "   ---------------- ----------------------- 10/25 [fonttools]\n",
      "   ---------------- ----------------------- 10/25 [fonttools]\n",
      "   ---------------- ----------------------- 10/25 [fonttools]\n",
      "   ---------------- ----------------------- 10/25 [fonttools]\n",
      "   ---------------- ----------------------- 10/25 [fonttools]\n",
      "   ---------------- ----------------------- 10/25 [fonttools]\n",
      "   ---------------- ----------------------- 10/25 [fonttools]\n",
      "   ---------------- ----------------------- 10/25 [fonttools]\n",
      "   ---------------- ----------------------- 10/25 [fonttools]\n",
      "   ---------------- ----------------------- 10/25 [fonttools]\n",
      "   ---------------- ----------------------- 10/25 [fonttools]\n",
      "   ---------------- ----------------------- 10/25 [fonttools]\n",
      "   ---------------- ----------------------- 10/25 [fonttools]\n",
      "   ---------------- ----------------------- 10/25 [fonttools]\n",
      "  Attempting uninstall: cycler\n",
      "   ---------------- ----------------------- 10/25 [fonttools]\n",
      "    Found existing installation: cycler 0.12.1\n",
      "   ---------------- ----------------------- 10/25 [fonttools]\n",
      "    Uninstalling cycler-0.12.1:\n",
      "   ---------------- ----------------------- 10/25 [fonttools]\n",
      "      Successfully uninstalled cycler-0.12.1\n",
      "   ---------------- ----------------------- 10/25 [fonttools]\n",
      "  Attempting uninstall: attrs\n",
      "   ---------------- ----------------------- 10/25 [fonttools]\n",
      "    Found existing installation: attrs 25.3.0\n",
      "   ---------------- ----------------------- 10/25 [fonttools]\n",
      "    Uninstalling attrs-25.3.0:\n",
      "   ---------------- ----------------------- 10/25 [fonttools]\n",
      "      Successfully uninstalled attrs-25.3.0\n",
      "   ---------------- ----------------------- 10/25 [fonttools]\n",
      "   ------------------- -------------------- 12/25 [attrs]\n",
      "   ------------------- -------------------- 12/25 [attrs]\n",
      "  Attempting uninstall: absl-py\n",
      "   ------------------- -------------------- 12/25 [attrs]\n",
      "    Found existing installation: absl-py 2.3.1\n",
      "   ------------------- -------------------- 12/25 [attrs]\n",
      "    Uninstalling absl-py-2.3.1:\n",
      "   ------------------- -------------------- 12/25 [attrs]\n",
      "      Successfully uninstalled absl-py-2.3.1\n",
      "   ------------------- -------------------- 12/25 [attrs]\n",
      "   -------------------- ------------------- 13/25 [absl-py]\n",
      "   -------------------- ------------------- 13/25 [absl-py]\n",
      "  Attempting uninstall: scipy\n",
      "   -------------------- ------------------- 13/25 [absl-py]\n",
      "    Found existing installation: scipy 1.15.3\n",
      "   -------------------- ------------------- 13/25 [absl-py]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "    Uninstalling scipy-1.15.3:\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "      Successfully uninstalled scipy-1.15.3\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "  Attempting uninstall: python-dateutil\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "    Found existing installation: python-dateutil 2.9.0.post0\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "    Uninstalling python-dateutil-2.9.0.post0:\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ------------------------ --------------- 15/25 [python-dateutil]\n",
      "      Successfully uninstalled python-dateutil-2.9.0.post0\n",
      "   ------------------------ --------------- 15/25 [python-dateutil]\n",
      "   ------------------------ --------------- 15/25 [python-dateutil]\n",
      "  Attempting uninstall: opencv-contrib-python\n",
      "   ------------------------ --------------- 15/25 [python-dateutil]\n",
      "    Found existing installation: opencv-contrib-python 4.11.0.86\n",
      "   ------------------------ --------------- 15/25 [python-dateutil]\n",
      "    Uninstalling opencv-contrib-python-4.11.0.86:\n",
      "   ------------------------ --------------- 15/25 [python-dateutil]\n",
      "   ------------------------- -------------- 16/25 [opencv-contrib-python]\n",
      "      Successfully uninstalled opencv-contrib-python-4.11.0.86\n",
      "   ------------------------- -------------- 16/25 [opencv-contrib-python]\n",
      "   ------------------------- -------------- 16/25 [opencv-contrib-python]\n",
      "   ------------------------- -------------- 16/25 [opencv-contrib-python]\n",
      "   ------------------------- -------------- 16/25 [opencv-contrib-python]\n",
      "   ------------------------- -------------- 16/25 [opencv-contrib-python]\n",
      "   ------------------------- -------------- 16/25 [opencv-contrib-python]\n",
      "   ------------------------- -------------- 16/25 [opencv-contrib-python]\n",
      "   ------------------------- -------------- 16/25 [opencv-contrib-python]\n",
      "   ------------------------- -------------- 16/25 [opencv-contrib-python]\n",
      "   ------------------------- -------------- 16/25 [opencv-contrib-python]\n",
      "   ------------------------- -------------- 16/25 [opencv-contrib-python]\n",
      "   ------------------------- -------------- 16/25 [opencv-contrib-python]\n",
      "   ------------------------- -------------- 16/25 [opencv-contrib-python]\n",
      "   ------------------------- -------------- 16/25 [opencv-contrib-python]\n",
      "   ------------------------- -------------- 16/25 [opencv-contrib-python]\n",
      "   ------------------------- -------------- 16/25 [opencv-contrib-python]\n",
      "   ------------------------- -------------- 16/25 [opencv-contrib-python]\n",
      "   ------------------------- -------------- 16/25 [opencv-contrib-python]\n",
      "   ------------------------- -------------- 16/25 [opencv-contrib-python]\n",
      "   ------------------------- -------------- 16/25 [opencv-contrib-python]\n",
      "   ------------------------- -------------- 16/25 [opencv-contrib-python]\n",
      "   ------------------------- -------------- 16/25 [opencv-contrib-python]\n",
      "   ------------------------- -------------- 16/25 [opencv-contrib-python]\n",
      "   ------------------------- -------------- 16/25 [opencv-contrib-python]\n",
      "   ------------------------- -------------- 16/25 [opencv-contrib-python]\n",
      "   ------------------------- -------------- 16/25 [opencv-contrib-python]\n",
      "  Attempting uninstall: ml_dtypes\n",
      "   ------------------------- -------------- 16/25 [opencv-contrib-python]\n",
      "    Found existing installation: ml_dtypes 0.5.3\n",
      "   ------------------------- -------------- 16/25 [opencv-contrib-python]\n",
      "    Uninstalling ml_dtypes-0.5.3:\n",
      "   ------------------------- -------------- 16/25 [opencv-contrib-python]\n",
      "      Successfully uninstalled ml_dtypes-0.5.3\n",
      "   ------------------------- -------------- 16/25 [opencv-contrib-python]\n",
      "   --------------------------- ------------ 17/25 [ml_dtypes]\n",
      "   --------------------------- ------------ 17/25 [ml_dtypes]\n",
      "   --------------------------- ------------ 17/25 [ml_dtypes]\n",
      "   --------------------------- ------------ 17/25 [ml_dtypes]\n",
      "   --------------------------- ------------ 17/25 [ml_dtypes]\n",
      "   --------------------------- ------------ 17/25 [ml_dtypes]\n",
      "   --------------------------- ------------ 17/25 [ml_dtypes]\n",
      "   --------------------------- ------------ 17/25 [ml_dtypes]\n",
      "   --------------------------- ------------ 17/25 [ml_dtypes]\n",
      "   --------------------------- ------------ 17/25 [ml_dtypes]\n",
      "   --------------------------- ------------ 17/25 [ml_dtypes]\n",
      "   --------------------------- ------------ 17/25 [ml_dtypes]\n",
      "   --------------------------- ------------ 17/25 [ml_dtypes]\n",
      "   --------------------------- ------------ 17/25 [ml_dtypes]\n",
      "   --------------------------- ------------ 17/25 [ml_dtypes]\n",
      "   --------------------------- ------------ 17/25 [ml_dtypes]\n",
      "   --------------------------- ------------ 17/25 [ml_dtypes]\n",
      "   --------------------------- ------------ 17/25 [ml_dtypes]\n",
      "  Attempting uninstall: contourpy\n",
      "   --------------------------- ------------ 17/25 [ml_dtypes]\n",
      "    Found existing installation: contourpy 1.3.2\n",
      "   --------------------------- ------------ 17/25 [ml_dtypes]\n",
      "    Uninstalling contourpy-1.3.2:\n",
      "   --------------------------- ------------ 17/25 [ml_dtypes]\n",
      "      Successfully uninstalled contourpy-1.3.2\n",
      "   --------------------------- ------------ 17/25 [ml_dtypes]\n",
      "   ---------------------------- ----------- 18/25 [contourpy]\n",
      "  Attempting uninstall: CFFI\n",
      "   ---------------------------- ----------- 18/25 [contourpy]\n",
      "    Found existing installation: cffi 2.0.0\n",
      "   ---------------------------- ----------- 18/25 [contourpy]\n",
      "   ------------------------------ --------- 19/25 [CFFI]\n",
      "    Uninstalling cffi-2.0.0:\n",
      "   ------------------------------ --------- 19/25 [CFFI]\n",
      "   ------------------------------ --------- 19/25 [CFFI]\n",
      "   ------------------------------ --------- 19/25 [CFFI]\n",
      "   ------------------------------ --------- 19/25 [CFFI]\n",
      "   ------------------------------ --------- 19/25 [CFFI]\n",
      "   ------------------------------ --------- 19/25 [CFFI]\n",
      "   ------------------------------ --------- 19/25 [CFFI]\n",
      "   ------------------------------ --------- 19/25 [CFFI]\n",
      "   ------------------------------ --------- 19/25 [CFFI]\n",
      "   ------------------------------ --------- 19/25 [CFFI]\n",
      "      Successfully uninstalled cffi-2.0.0\n",
      "   ------------------------------ --------- 19/25 [CFFI]\n",
      "   ------------------------------ --------- 19/25 [CFFI]\n",
      "   ------------------------------ --------- 19/25 [CFFI]\n",
      "   ------------------------------ --------- 19/25 [CFFI]\n",
      "   ------------------------------ --------- 19/25 [CFFI]\n",
      "   ------------------------------ --------- 19/25 [CFFI]\n",
      "   ------------------------------ --------- 19/25 [CFFI]\n",
      "   ------------------------------ --------- 19/25 [CFFI]\n",
      "   ------------------------------ --------- 19/25 [CFFI]\n",
      "   ------------------------------ --------- 19/25 [CFFI]\n",
      "   ------------------------------ --------- 19/25 [CFFI]\n",
      "   ------------------------------ --------- 19/25 [CFFI]\n",
      "   ------------------------------ --------- 19/25 [CFFI]\n",
      "   ------------------------------ --------- 19/25 [CFFI]\n",
      "   ------------------------------ --------- 19/25 [CFFI]\n",
      "   ------------------------------ --------- 19/25 [CFFI]\n",
      "   ------------------------------ --------- 19/25 [CFFI]\n",
      "   ------------------------------ --------- 19/25 [CFFI]\n",
      "   ------------------------------ --------- 19/25 [CFFI]\n",
      "   ------------------------------ --------- 19/25 [CFFI]\n",
      "  Attempting uninstall: sounddevice\n",
      "   ------------------------------ --------- 19/25 [CFFI]\n",
      "    Found existing installation: sounddevice 0.5.3\n",
      "   ------------------------------ --------- 19/25 [CFFI]\n",
      "    Uninstalling sounddevice-0.5.3:\n",
      "   ------------------------------ --------- 19/25 [CFFI]\n",
      "   -------------------------------- ------- 20/25 [sounddevice]\n",
      "   -------------------------------- ------- 20/25 [sounddevice]\n",
      "   -------------------------------- ------- 20/25 [sounddevice]\n",
      "   -------------------------------- ------- 20/25 [sounddevice]\n",
      "   -------------------------------- ------- 20/25 [sounddevice]\n",
      "   -------------------------------- ------- 20/25 [sounddevice]\n",
      "   -------------------------------- ------- 20/25 [sounddevice]\n",
      "   -------------------------------- ------- 20/25 [sounddevice]\n",
      "   -------------------------------- ------- 20/25 [sounddevice]\n",
      "   -------------------------------- ------- 20/25 [sounddevice]\n",
      "      Successfully uninstalled sounddevice-0.5.3\n",
      "   -------------------------------- ------- 20/25 [sounddevice]\n",
      "   -------------------------------- ------- 20/25 [sounddevice]\n",
      "   -------------------------------- ------- 20/25 [sounddevice]\n",
      "   -------------------------------- ------- 20/25 [sounddevice]\n",
      "   -------------------------------- ------- 20/25 [sounddevice]\n",
      "   -------------------------------- ------- 20/25 [sounddevice]\n",
      "   -------------------------------- ------- 20/25 [sounddevice]\n",
      "   -------------------------------- ------- 20/25 [sounddevice]\n",
      "   -------------------------------- ------- 20/25 [sounddevice]\n",
      "   -------------------------------- ------- 20/25 [sounddevice]\n",
      "   -------------------------------- ------- 20/25 [sounddevice]\n",
      "   -------------------------------- ------- 20/25 [sounddevice]\n",
      "   -------------------------------- ------- 20/25 [sounddevice]\n",
      "   -------------------------------- ------- 20/25 [sounddevice]\n",
      "   -------------------------------- ------- 20/25 [sounddevice]\n",
      "   -------------------------------- ------- 20/25 [sounddevice]\n",
      "   -------------------------------- ------- 20/25 [sounddevice]\n",
      "   -------------------------------- ------- 20/25 [sounddevice]\n",
      "   -------------------------------- ------- 20/25 [sounddevice]\n",
      "  Attempting uninstall: matplotlib\n",
      "   -------------------------------- ------- 20/25 [sounddevice]\n",
      "    Found existing installation: matplotlib 3.10.5\n",
      "   -------------------------------- ------- 20/25 [sounddevice]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "    Uninstalling matplotlib-3.10.5:\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\User\\Desktop\\JUPYTER NOTEBOOK\\my_venv\\Lib\\site-packages\\google\\~.pb'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\User\\Desktop\\JUPYTER NOTEBOOK\\my_venv\\Lib\\site-packages\\~il'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\User\\Desktop\\JUPYTER NOTEBOOK\\my_venv\\Lib\\site-packages\\~=mpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\User\\Desktop\\JUPYTER NOTEBOOK\\my_venv\\Lib\\site-packages\\~%mpy'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\User\\Desktop\\JUPYTER NOTEBOOK\\my_venv\\Lib\\site-packages\\~iwisolver'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\User\\Desktop\\JUPYTER NOTEBOOK\\my_venv\\Lib\\site-packages\\~-ipy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\User\\Desktop\\JUPYTER NOTEBOOK\\my_venv\\Lib\\site-packages\\~-ipy'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\User\\AppData\\Local\\Temp\\pip-uninstall-70s4qh4k'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\User\\Desktop\\JUPYTER NOTEBOOK\\my_venv\\Lib\\site-packages\\~l_dtypes'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\User\\AppData\\Local\\Temp\\pip-uninstall-045mpuj8'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\User\\Desktop\\JUPYTER NOTEBOOK\\my_venv\\Lib\\site-packages\\~-ounddevice_data'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'c:\\\\users\\\\user\\\\desktop\\\\jupyter notebook\\\\my_venv\\\\lib\\\\site-packages\\\\matplotlib\\\\backends\\\\_backend_agg.cp311-win_amd64.pyd'\n",
      "Check the permissions.\n",
      "\n",
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y mediapipe\n",
    "!pip install mediapipe==0.10.11 --force-reinstall --no-cache-dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f6983ac-9c32-45dc-b5d4-a7d8470a7807",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\JUPYTER NOTEBOOK\\my_venv\\Lib\\site-packages\\keras\\src\\export\\tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MediaPipe Version: 0.10.21\n",
      "TensorFlow Version: 2.19.1\n",
      "Keras Version: 3.13.0\n"
     ]
    }
   ],
   "source": [
    "import mediapipe as mp\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "print(f\"MediaPipe Version: {mp.__version__}\")\n",
    "print(f\"TensorFlow Version: {tf.__version__}\")\n",
    "print(f\"Keras Version: {keras.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dfd8e1b-802a-48ef-9260-415dc352ec8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\JUPYTER NOTEBOOK\\my_venv\\Lib\\site-packages\\keras\\src\\export\\tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading asl_alphabet_model.h5...\n",
      "Labels loaded: 26\n",
      "\n",
      "--- SYSTEM READY ---\n",
      "Press Q to Quit | C to Clear | B to Backspace\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import os\n",
    "import time\n",
    "from collections import deque\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "MODEL_PATH = \"asl_alphabet_model.h5\"  # Or .keras if you retrained\n",
    "LABEL_PATH = \"alphabet_labels.npy\"\n",
    "\n",
    "# --- 1. FEATURE EXTRACTOR (80 Features) ---\n",
    "def extract_features(kp_flat):\n",
    "    # Reshape (21 points, 3 dims)\n",
    "    landmarks = kp_flat.reshape(21, 3)\n",
    "    \n",
    "    # Normalize to Wrist\n",
    "    wrist = landmarks[0]\n",
    "    landmarks = landmarks - wrist\n",
    "    \n",
    "    # Scale Normalization\n",
    "    scale = np.linalg.norm(landmarks[12]) + 1e-6\n",
    "    landmarks = landmarks / scale\n",
    "    \n",
    "    flat_coords = landmarks.flatten() # 63 features\n",
    "    \n",
    "    # Distances\n",
    "    dists = []\n",
    "    tips = [4, 8, 12, 16, 20]\n",
    "    for i in range(1, 5): dists.append(np.linalg.norm(landmarks[tips[0]] - landmarks[tips[i]]))\n",
    "    for i in range(4): dists.append(np.linalg.norm(landmarks[tips[i]] - landmarks[tips[i+1]]))\n",
    "    for i in range(5): dists.append(np.linalg.norm(landmarks[tips[i]]))\n",
    "    \n",
    "    # Angles\n",
    "    angles = []\n",
    "    bases = [2, 5, 9, 13, 17]\n",
    "    vecs = [landmarks[tips[i]] - landmarks[bases[i]] for i in range(5)]\n",
    "    for i in range(4):\n",
    "        v1, v2 = vecs[i], vecs[i+1]\n",
    "        c = np.dot(v1, v2)/(np.linalg.norm(v1)*np.linalg.norm(v2)+1e-6)\n",
    "        angles.append(np.arccos(np.clip(c, -1, 1)))\n",
    "        \n",
    "    return np.concatenate([flat_coords, np.array(dists), np.array(angles)])\n",
    "\n",
    "# --- 2. LOAD MODEL ---\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    print(f\"CRITICAL ERROR: Model file '{MODEL_PATH}' not found.\")\n",
    "    print(\"Did you retrain and save the model?\")\n",
    "    exit()\n",
    "\n",
    "print(f\"Loading {MODEL_PATH}...\")\n",
    "try:\n",
    "    # Try generic load first\n",
    "    model = tf.keras.models.load_model(MODEL_PATH)\n",
    "except:\n",
    "    print(\"TF Load failed, trying Keras 3 native load...\")\n",
    "    try:\n",
    "        model = keras.saving.load_model(MODEL_PATH)\n",
    "    except Exception as e:\n",
    "        print(f\"FAILED to load model: {e}\")\n",
    "        exit()\n",
    "\n",
    "try:\n",
    "    labels = np.load(LABEL_PATH)\n",
    "    print(f\"Labels loaded: {len(labels)}\")\n",
    "except:\n",
    "    print(\"Labels missing, using default A-Z.\")\n",
    "    labels = np.array(list(\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"))\n",
    "\n",
    "# --- 3. SETUP MEDIAPIPE ---\n",
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "holistic = mp_holistic.Holistic(\n",
    "    static_image_mode=False,\n",
    "    model_complexity=1,\n",
    "    min_detection_confidence=0.7,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "buffer = deque(maxlen=5)\n",
    "last_time = 0\n",
    "word = \"\"\n",
    "\n",
    "print(\"\\n--- SYSTEM READY ---\")\n",
    "print(\"Press Q to Quit | C to Clear | B to Backspace\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret: break\n",
    "    \n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    res = holistic.process(rgb)\n",
    "    \n",
    "    kp_flat = None\n",
    "    \n",
    "    # Draw & Extract\n",
    "    if res.right_hand_landmarks:\n",
    "        mp_drawing.draw_landmarks(frame, res.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "        kp = np.array([[lm.x, lm.y, lm.z] for lm in res.right_hand_landmarks.landmark])\n",
    "        kp_flat = kp.flatten()\n",
    "        \n",
    "    elif res.left_hand_landmarks:\n",
    "        mp_drawing.draw_landmarks(frame, res.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "        kp = np.array([[lm.x, lm.y, lm.z] for lm in res.left_hand_landmarks.landmark])\n",
    "        kp[:, 0] = -kp[:, 0] # Mirror\n",
    "        kp_flat = kp.flatten()\n",
    "    else:\n",
    "        buffer.append((None, 0.0))\n",
    "\n",
    "    txt = \"Waiting...\"\n",
    "    \n",
    "    if kp_flat is not None:\n",
    "        # Predict\n",
    "        feats = extract_features(kp_flat)\n",
    "        \n",
    "        # Keras 3 / TF 2.20 prediction call\n",
    "        preds = model.predict(feats[np.newaxis], verbose=0)[0]\n",
    "        idx = np.argmax(preds)\n",
    "        prob = np.max(preds)\n",
    "        \n",
    "        buffer.append((idx, prob))\n",
    "        txt = f\"Scan: {labels[idx]} ({prob:.2f})\"\n",
    "\n",
    "    # Confirm Logic\n",
    "    if time.time() - last_time > 1.5:\n",
    "        valid = [x for x in buffer if x[0] is not None]\n",
    "        if len(valid) >= 4:\n",
    "            indices = [x[0] for x in valid]\n",
    "            candidate = max(set(indices), key=indices.count)\n",
    "            avg = np.mean([x[1] for x in valid if x[0] == candidate])\n",
    "            \n",
    "            if avg > 0.85:\n",
    "                l = str(labels[candidate])\n",
    "                if l == \"space\": word += \" \"\n",
    "                elif l == \"del\": word = word[:-1]\n",
    "                elif l == \"nothing\": pass\n",
    "                else: word += l\n",
    "                last_time = time.time()\n",
    "                buffer.clear()\n",
    "                cv2.rectangle(frame, (0,0), (640,480), (0,255,0), 5)\n",
    "\n",
    "    # UI\n",
    "    cv2.putText(frame, txt, (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)\n",
    "    cv2.putText(frame, word, (20, 450), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
    "    \n",
    "    cv2.imshow(\"ASL Pro (Friend's Stack)\", frame)\n",
    "    \n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'): break\n",
    "    elif key == ord('b'): word = word[:-1]\n",
    "    elif key == ord('c'): word = \"\"\n",
    "\n",
    "cap.release()\n",
    "holistic.close()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ea946a3-42cf-4083-97f7-0b29b2b100c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n",
      "Starting video loop...\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "MODEL_PATH = \"word_model.h5\"\n",
    "SEQ_LEN = 30\n",
    "NUM_LANDMARKS = 75\n",
    "THRESHOLD = 0.85\n",
    "STABILITY_FRAMES = 5\n",
    "last_valid_left = [0.0] * 63\n",
    "last_valid_right = [0.0] * 63\n",
    "\n",
    "TARGET_GLOSSES = [\n",
    "    \"me\", \"you\", \"we\", \"they\", \"she\",\n",
    "    \"who\", \"what\", \"yes\", \"no\", \"fine\", \"help\", \"meet\", \"good\",\n",
    "    \"want\", \"have\", \"like\", \"need\", \"go\", \"walk\", \n",
    "    \"play\", \"work\", \"learn\", \"eat\", \"drink\", \"finish\",\n",
    "    \"book\", \"family\", \"school\", \"computer\", \"deaf\"\n",
    "]\n",
    "\n",
    "# --- LOAD RESOURCES ---\n",
    "try:\n",
    "    model = tf.keras.models.load_model(MODEL_PATH)\n",
    "    print(\"Model loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")\n",
    "    exit()\n",
    "\n",
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils \n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "\n",
    "# --- HELPER FUNCTIONS ---\n",
    "def extract_landmarks_smart(results):\n",
    "    global last_valid_left, last_valid_right\n",
    "    vec = []\n",
    "    \n",
    "    # Pose (Always keep fresh)\n",
    "    if results.pose_landmarks:\n",
    "        for lm in results.pose_landmarks.landmark:\n",
    "            vec.extend([lm.x, lm.y, lm.z])\n",
    "    else:\n",
    "        vec.extend([0.0] * 99)\n",
    "        \n",
    "    # --- LEFT HAND (With Memory) ---\n",
    "    if results.left_hand_landmarks:\n",
    "        temp = []\n",
    "        for lm in results.left_hand_landmarks.landmark:\n",
    "            temp.extend([lm.x, lm.y, lm.z])\n",
    "        vec.extend(temp)\n",
    "        last_valid_left = temp # Update memory\n",
    "    else:\n",
    "        # If missing, use the memory (Ghost Hand)\n",
    "        vec.extend(last_valid_left)\n",
    "\n",
    "    # --- RIGHT HAND (With Memory) ---\n",
    "    if results.right_hand_landmarks:\n",
    "        temp = []\n",
    "        for lm in results.right_hand_landmarks.landmark:\n",
    "            temp.extend([lm.x, lm.y, lm.z])\n",
    "        vec.extend(temp)\n",
    "        last_valid_right = temp # Update memory\n",
    "    else:\n",
    "        vec.extend(last_valid_right)\n",
    "        \n",
    "    return vec\n",
    "\n",
    "def pre_process_landmarks(data):\n",
    "    df = pd.DataFrame(data)\n",
    "    df = df.replace(0.0, np.nan)\n",
    "    df = df.interpolate(method='linear', axis=0, limit_direction='both')\n",
    "    df = df.fillna(0.0)\n",
    "    data = df.values.astype(np.float32)\n",
    "    frames = data.reshape(-1, NUM_LANDMARKS, 3)\n",
    "    for i in range(frames.shape[0]):\n",
    "        frame = frames[i]\n",
    "        left = frame[11]\n",
    "        right = frame[12]\n",
    "        center = (left + right) / 2.0\n",
    "        width = np.linalg.norm(left - right) + 1e-6\n",
    "        frame = (frame - center) / (width / 2.0)\n",
    "        frames[i] = frame\n",
    "    return frames.reshape(-1, NUM_LANDMARKS * 3)\n",
    "\n",
    "def resize_sequence(sequence):\n",
    "    norm_seq = pre_process_landmarks(sequence)\n",
    "    res = np.zeros((SEQ_LEN, norm_seq.shape[1]))\n",
    "    for j in range(norm_seq.shape[1]):\n",
    "        res[:, j] = np.interp(\n",
    "            np.linspace(0, len(norm_seq)-1, SEQ_LEN),\n",
    "            np.arange(len(norm_seq)),\n",
    "            norm_seq[:, j]\n",
    "        )\n",
    "    return res\n",
    "\n",
    "# --- MAIN LOOP ---\n",
    "cap = cv2.VideoCapture(0)\n",
    "sequence_buffer = []\n",
    "prediction_history = []\n",
    "current_word = \"\"\n",
    "sentence = []\n",
    "\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    print(\"Starting video loop...\")\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret: \n",
    "            print(\"Ignoring empty camera frame.\")\n",
    "            continue\n",
    "        \n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = holistic.process(image)\n",
    "        \n",
    "        # --- DRAWING THE SKELETON ---\n",
    "        # Draw Pose (Body)\n",
    "        mp_drawing.draw_landmarks(\n",
    "            frame, \n",
    "            results.pose_landmarks, \n",
    "            mp_holistic.POSE_CONNECTIONS,\n",
    "            landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style()\n",
    "        )\n",
    "        \n",
    "        # Draw Left Hand\n",
    "        mp_drawing.draw_landmarks(\n",
    "            frame, \n",
    "            results.left_hand_landmarks, \n",
    "            mp_holistic.HAND_CONNECTIONS,\n",
    "            # Custom Style: Green dots for hands\n",
    "            mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2),\n",
    "            mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2)\n",
    "        )\n",
    "        \n",
    "        # Draw Right Hand\n",
    "        mp_drawing.draw_landmarks(\n",
    "            frame, \n",
    "            results.right_hand_landmarks, \n",
    "            mp_holistic.HAND_CONNECTIONS,\n",
    "            mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2),\n",
    "            mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2)\n",
    "        )\n",
    "\n",
    "        # --- LOGIC ---\n",
    "        hands_visible = (results.left_hand_landmarks is not None) or (results.right_hand_landmarks is not None)\n",
    "        \n",
    "        if not hands_visible:\n",
    "            sequence_buffer = [] \n",
    "            prediction_history = []\n",
    "            display_msg = \"Waiting for hands...\"\n",
    "            status_color = (0, 0, 255) # Red\n",
    "        else:\n",
    "            display_msg = \"Tracking...\"\n",
    "            status_color = (0, 255, 0) # Green\n",
    "            \n",
    "            # --- FIX IS HERE: Use the correct function name ---\n",
    "            landmarks = extract_landmarks_smart(results) \n",
    "            \n",
    "            sequence_buffer.append(landmarks)\n",
    "            if len(sequence_buffer) > 45: sequence_buffer.pop(0)\n",
    "                \n",
    "            if len(sequence_buffer) >= 30:\n",
    "                input_data = resize_sequence(np.array(sequence_buffer))\n",
    "                input_data = np.expand_dims(input_data, axis=0)\n",
    "                \n",
    "                res = model.predict(input_data, verbose=0)\n",
    "                conf = np.max(res)\n",
    "                idx = np.argmax(res)\n",
    "                \n",
    "                if conf > THRESHOLD:\n",
    "                    candidate = TARGET_GLOSSES[idx]\n",
    "                    prediction_history.append(candidate)\n",
    "                    if len(prediction_history) > STABILITY_FRAMES:\n",
    "                        prediction_history = prediction_history[-STABILITY_FRAMES:]\n",
    "                    \n",
    "                    if len(prediction_history) == STABILITY_FRAMES:\n",
    "                        if len(set(prediction_history)) == 1:\n",
    "                            stable_word = prediction_history[0]\n",
    "                            if stable_word != current_word:\n",
    "                                current_word = stable_word\n",
    "                                sentence.append(current_word)\n",
    "                                if len(sentence) > 5: sentence = sentence[-5:]\n",
    "                else:\n",
    "                    prediction_history.append(\"...\")\n",
    "\n",
    "        # --- UI OVERLAY ---\n",
    "        cv2.rectangle(frame, (0, 0), (640, 80), (245, 117, 16), -1)\n",
    "        cv2.putText(frame, f\"STATUS: {display_msg}\", (400, 30), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, status_color, 1)\n",
    "        cv2.putText(frame, f\"WORD: {current_word}\", (10, 30), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "        cv2.putText(frame, f\"SEN: {' '.join(sentence)}\", (10, 70), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)\n",
    "\n",
    "        cv2.imshow('TalkSign Live Test', frame)\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1e5c4e9-975f-4663-8a7f-d2e56610f053",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models...\n",
      "Word Model loaded: best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alphabet Model loaded: asl_alphabet_model.h5\n",
      "Starting Camera...\n",
      "SPACEBAR to toggle modes | Q to Quit\n",
      "Switched Mode: True\n",
      "Switched Mode: False\n",
      "Switched Mode: True\n",
      "Switched Mode: False\n",
      "Switched Mode: True\n",
      "Switched Mode: False\n",
      "Switched Mode: True\n",
      "Switched Mode: False\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "WORD_MODEL_PATH = \"best_model.h5\"\n",
    "ALPHA_MODEL_PATH = \"asl_alphabet_model.h5\" # Or .keras if you are using the new format\n",
    "SPELLING_MODE = False  # Start in Word Mode\n",
    "MODE_SWITCH_COOLDOWN = 1.0\n",
    "last_switch_time = 0\n",
    "\n",
    "# Tuning Parameters\n",
    "WORD_THRESHOLD = 0.85\n",
    "ALPHA_THRESHOLD = 0.90\n",
    "VELOCITY_THRESHOLD = 0.02\n",
    "STABILITY_FRAMES = 5\n",
    "WORD_COOLDOWN = 2.0 \n",
    "\n",
    "WORD_CLASSES = [\n",
    "    \"me\", \"you\", \"we\", \"they\", \"she\",\n",
    "    \"who\", \"what\", \"yes\", \"no\", \"fine\", \"help\", \"meet\", \"good\",\n",
    "    \"want\", \"have\", \"like\", \"need\", \"go\", \"walk\", \n",
    "    \"play\", \"work\", \"learn\", \"eat\", \"drink\", \"finish\",\n",
    "    \"book\", \"family\", \"school\", \"computer\", \"deaf\"\n",
    "]\n",
    "\n",
    "ALPHABET_CLASSES = list(\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\")\n",
    "\n",
    "# --- LOAD RESOURCES ---\n",
    "print(\"Loading models...\")\n",
    "try:\n",
    "    word_model = tf.keras.models.load_model(WORD_MODEL_PATH)\n",
    "    print(f\"Word Model loaded: {WORD_MODEL_PATH}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading Word Model: {e}\")\n",
    "\n",
    "try:\n",
    "    # Try standard load first, fallback to Keras 3 if needed\n",
    "    try:\n",
    "        alpha_model = tf.keras.models.load_model(ALPHA_MODEL_PATH)\n",
    "    except:\n",
    "        import keras\n",
    "        alpha_model = keras.saving.load_model(ALPHA_MODEL_PATH)\n",
    "    print(f\"Alphabet Model loaded: {ALPHA_MODEL_PATH}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading Alphabet Model: {e}\")\n",
    "\n",
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# --- HELPER FUNCTIONS ---\n",
    "\n",
    "def extract_body_landmarks(results):\n",
    "    \"\"\" Extracts 225 landmarks (Pose+Left+Right) for the WORD model. \"\"\"\n",
    "    vec = []\n",
    "    if results.pose_landmarks:\n",
    "        for lm in results.pose_landmarks.landmark:\n",
    "            vec.extend([lm.x, lm.y, lm.z])\n",
    "    else: vec.extend([0.0]*99)\n",
    "    if results.left_hand_landmarks:\n",
    "        for lm in results.left_hand_landmarks.landmark:\n",
    "            vec.extend([lm.x, lm.y, lm.z])\n",
    "    else: vec.extend([0.0]*63)\n",
    "    if results.right_hand_landmarks:\n",
    "        for lm in results.right_hand_landmarks.landmark:\n",
    "            vec.extend([lm.x, lm.y, lm.z])\n",
    "    else: vec.extend([0.0]*63)\n",
    "    return vec\n",
    "\n",
    "def pre_process_word_input(data):\n",
    "    \"\"\" Resizes sequence to 30 frames for the WORD model. \"\"\"\n",
    "    df = pd.DataFrame(data)\n",
    "    df = df.replace(0.0, np.nan)\n",
    "    df = df.interpolate(method='linear', axis=0, limit_direction='both')\n",
    "    df = df.fillna(0.0)\n",
    "    data = df.values.astype(np.float32)\n",
    "    frames = data.reshape(-1, 75, 3)\n",
    "    for i in range(frames.shape[0]):\n",
    "        frame = frames[i]\n",
    "        left = frame[11]\n",
    "        right = frame[12]\n",
    "        center = (left + right) / 2.0\n",
    "        width = np.linalg.norm(left - right) + 1e-6\n",
    "        frame = (frame - center) / (width / 2.0)\n",
    "        frames[i] = frame\n",
    "    norm_seq = frames.reshape(-1, 225)\n",
    "    res = np.zeros((30, 225))\n",
    "    for j in range(225):\n",
    "        res[:, j] = np.interp(np.linspace(0, len(norm_seq)-1, 30), np.arange(len(norm_seq)), norm_seq[:, j])\n",
    "    return np.expand_dims(res, axis=0)\n",
    "\n",
    "def extract_hand_for_alphabet(hand_landmarks):\n",
    "    \"\"\" \n",
    "    UPDATED: Extracts 80 Features (Coords + Distances + Angles) \n",
    "    Matches your new Alphabet Model training logic.\n",
    "    \"\"\"\n",
    "    if not hand_landmarks: return None\n",
    "    \n",
    "    # 1. Convert to NumPy (21, 3)\n",
    "    landmarks = np.array([[lm.x, lm.y, lm.z] for lm in hand_landmarks.landmark])\n",
    "    \n",
    "    # 2. Normalize to Wrist\n",
    "    wrist = landmarks[0]\n",
    "    landmarks = landmarks - wrist\n",
    "    \n",
    "    # 3. Scale Normalization\n",
    "    scale = np.linalg.norm(landmarks[12]) + 1e-6\n",
    "    landmarks = landmarks / scale\n",
    "    \n",
    "    flat_coords = landmarks.flatten() # 63 features\n",
    "    \n",
    "    # 4. Calculate Distances (13 features)\n",
    "    distances = []\n",
    "    tips = [4, 8, 12, 16, 20] # Thumb, Index, Middle, Ring, Pinky Tips\n",
    "    \n",
    "    # A. Thumb to others\n",
    "    for i in range(1, 5):\n",
    "        d = np.linalg.norm(landmarks[tips[0]] - landmarks[tips[i]])\n",
    "        distances.append(d)\n",
    "    # B. Adjacent tips\n",
    "    for i in range(4):\n",
    "        d = np.linalg.norm(landmarks[tips[i]] - landmarks[tips[i+1]])\n",
    "        distances.append(d)\n",
    "    # C. Wrist to tips\n",
    "    for i in range(5):\n",
    "        d = np.linalg.norm(landmarks[tips[i]]) \n",
    "        distances.append(d)\n",
    "        \n",
    "    # 5. Calculate Angles (4 features)\n",
    "    vectors = []\n",
    "    finger_bases = [2, 5, 9, 13, 17] # Proximal joints\n",
    "    for i in range(5):\n",
    "        vec = landmarks[tips[i]] - landmarks[finger_bases[i]]\n",
    "        vectors.append(vec)\n",
    "        \n",
    "    angles = []\n",
    "    for i in range(4):\n",
    "        v1 = vectors[i]\n",
    "        v2 = vectors[i+1]\n",
    "        cosine = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2) + 1e-6)\n",
    "        angle = np.arccos(np.clip(cosine, -1.0, 1.0))\n",
    "        angles.append(angle)\n",
    "    \n",
    "    # Total: 63 + 13 + 4 = 80 Features\n",
    "    features = np.concatenate([flat_coords, np.array(distances), np.array(angles)])\n",
    "    return features.reshape(1, -1)\n",
    "\n",
    "# --- MAIN LOOP ---\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Buffers\n",
    "sequence_buffer = []\n",
    "prediction_history = []\n",
    "sentence = []\n",
    "current_display_text = \"\"\n",
    "prev_wrist_pos = None\n",
    "\n",
    "print(\"Starting Camera...\")\n",
    "print(\"SPACEBAR to toggle modes | Q to Quit\")\n",
    "\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret: break\n",
    "        \n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = holistic.process(image)\n",
    "        \n",
    "        # --- UI VISUALS ---\n",
    "        # ORANGE = WORD MODE (Default)\n",
    "        # PURPLE = SPELLING MODE\n",
    "        border_color = (255, 0, 255) if SPELLING_MODE else (0, 165, 255) \n",
    "        cv2.rectangle(frame, (0, 0), (640, 60), border_color, -1)\n",
    "        \n",
    "        mode_label = \"MODE: FINGERSPELLING (Letters)\" if SPELLING_MODE else \"MODE: SIGNING (Words)\"\n",
    "        cv2.putText(frame, mode_label, (10, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "        \n",
    "        active_hand = results.right_hand_landmarks if results.right_hand_landmarks else results.left_hand_landmarks\n",
    "        \n",
    "        # Draw Landmarks\n",
    "        if results.right_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(frame, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "        if results.left_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(frame, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "        \n",
    "        # ---------------------------------------------------------\n",
    "        # LOGIC BRANCH\n",
    "        # ---------------------------------------------------------\n",
    "        if active_hand:\n",
    "            # Calculate Velocity\n",
    "            curr_wrist = np.array([active_hand.landmark[0].x, active_hand.landmark[0].y])\n",
    "            velocity = 0.0\n",
    "            if prev_wrist_pos is not None:\n",
    "                velocity = np.linalg.norm(curr_wrist - prev_wrist_pos)\n",
    "            prev_wrist_pos = curr_wrist\n",
    "\n",
    "            # --- BRANCH 1: SPELLING MODE ---\n",
    "            if SPELLING_MODE:\n",
    "                # In spelling mode, we ONLY look for static letters (Low Velocity)\n",
    "                if velocity < VELOCITY_THRESHOLD:\n",
    "                    # UPDATED FUNCTION CALL\n",
    "                    hand_input = extract_hand_for_alphabet(active_hand)\n",
    "                    \n",
    "                    if hand_input is not None:\n",
    "                        pred = alpha_model.predict(hand_input, verbose=0)\n",
    "                        if np.max(pred) > ALPHA_THRESHOLD:\n",
    "                            candidate = ALPHABET_CLASSES[np.argmax(pred)]\n",
    "                            prediction_history.append(candidate)\n",
    "                        else:\n",
    "                            prediction_history.append(\"...\")\n",
    "                else:\n",
    "                    prediction_history.append(\"...\") # Hand moving = noise in spelling\n",
    "            \n",
    "            # --- BRANCH 2: SIGNING MODE (Default) ---\n",
    "            else:\n",
    "                # In signing mode, we ONLY look for Words\n",
    "                # Check for Word input (Velocity High)\n",
    "                if velocity > VELOCITY_THRESHOLD:\n",
    "                    landmarks = extract_body_landmarks(results)\n",
    "                    sequence_buffer.append(landmarks)\n",
    "                    if len(sequence_buffer) > 45: sequence_buffer.pop(0)\n",
    "                    \n",
    "                    if len(sequence_buffer) >= 30:\n",
    "                        input_data = pre_process_word_input(sequence_buffer)\n",
    "                        pred = word_model.predict(input_data, verbose=0)\n",
    "                        \n",
    "                        if np.max(pred) > WORD_THRESHOLD:\n",
    "                            candidate = WORD_CLASSES[np.argmax(pred)]\n",
    "                            prediction_history.append(candidate)\n",
    "                        else:\n",
    "                            prediction_history.append(\"...\")\n",
    "                else:\n",
    "                    prediction_history.append(\"...\")\n",
    "\n",
    "            # --- STABILITY & DISPLAY ---\n",
    "            if len(prediction_history) > STABILITY_FRAMES:\n",
    "                prediction_history = prediction_history[-STABILITY_FRAMES:]\n",
    "            \n",
    "            if len(prediction_history) == STABILITY_FRAMES and len(set(prediction_history)) == 1:\n",
    "                stable_pred = prediction_history[0]\n",
    "                if stable_pred != \"...\" and stable_pred != current_display_text:\n",
    "                    current_display_text = stable_pred\n",
    "                    \n",
    "                    # Logic: If spelling, just add letter. If word, add word + space.\n",
    "                    if SPELLING_MODE:\n",
    "                         sentence.append(current_display_text)\n",
    "                    else:\n",
    "                         sentence.append(current_display_text)\n",
    "                    \n",
    "                    if len(sentence) > 7: sentence = sentence[-7:]\n",
    "\n",
    "        # --- DRAW TEXT ---\n",
    "        cv2.putText(frame, f\"Prediction: {current_display_text}\", (10, 450), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        \n",
    "        sentence_str = \" \".join(sentence) if not SPELLING_MODE else \"\".join(sentence)\n",
    "        cv2.putText(frame, f\"Sentence: {sentence_str}\", (10, 400), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "        \n",
    "        cv2.imshow('Hybrid TalkSign System', frame)\n",
    "        \n",
    "        # --- KEYBOARD TOGGLE ---\n",
    "        key = cv2.waitKey(10) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "        elif key == 32: # SPACE BAR\n",
    "            # Debounce the toggle\n",
    "            if time.time() - last_switch_time > 0.5:\n",
    "                SPELLING_MODE = not SPELLING_MODE\n",
    "                prediction_history = [] # Clear history on switch\n",
    "                current_display_text = \"\"\n",
    "                last_switch_time = time.time()\n",
    "                print(f\"Switched Mode: {SPELLING_MODE}\")\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ee1bbaac-ef03-4912-a79f-62a887481459",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-generativeai in c:\\users\\user\\desktop\\jupyter notebook\\my_venv\\lib\\site-packages (0.8.6)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in c:\\users\\user\\desktop\\jupyter notebook\\my_venv\\lib\\site-packages (from google-generativeai) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in c:\\users\\user\\desktop\\jupyter notebook\\my_venv\\lib\\site-packages (from google-generativeai) (2.28.1)\n",
      "Requirement already satisfied: google-api-python-client in c:\\users\\user\\desktop\\jupyter notebook\\my_venv\\lib\\site-packages (from google-generativeai) (2.187.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\user\\desktop\\jupyter notebook\\my_venv\\lib\\site-packages (from google-generativeai) (2.45.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\user\\desktop\\jupyter notebook\\my_venv\\lib\\site-packages (from google-generativeai) (5.29.5)\n",
      "Requirement already satisfied: pydantic in c:\\users\\user\\desktop\\jupyter notebook\\my_venv\\lib\\site-packages (from google-generativeai) (2.12.5)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\desktop\\jupyter notebook\\my_venv\\lib\\site-packages (from google-generativeai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\user\\desktop\\jupyter notebook\\my_venv\\lib\\site-packages (from google-generativeai) (4.14.1)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\user\\desktop\\jupyter notebook\\my_venv\\lib\\site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.27.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\user\\desktop\\jupyter notebook\\my_venv\\lib\\site-packages (from google-api-core->google-generativeai) (1.72.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in c:\\users\\user\\desktop\\jupyter notebook\\my_venv\\lib\\site-packages (from google-api-core->google-generativeai) (2.32.4)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in c:\\users\\user\\desktop\\jupyter notebook\\my_venv\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.74.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in c:\\users\\user\\desktop\\jupyter notebook\\my_venv\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in c:\\users\\user\\desktop\\jupyter notebook\\my_venv\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (6.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\user\\desktop\\jupyter notebook\\my_venv\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\user\\desktop\\jupyter notebook\\my_venv\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\user\\desktop\\jupyter notebook\\my_venv\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\desktop\\jupyter notebook\\my_venv\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\desktop\\jupyter notebook\\my_venv\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\desktop\\jupyter notebook\\my_venv\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.8.3)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\user\\desktop\\jupyter notebook\\my_venv\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in c:\\users\\user\\desktop\\jupyter notebook\\my_venv\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.31.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\user\\desktop\\jupyter notebook\\my_venv\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.3.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\user\\desktop\\jupyter notebook\\my_venv\\lib\\site-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
      "Requirement already satisfied: pyparsing<4,>=3.0.4 in c:\\users\\user\\desktop\\jupyter notebook\\my_venv\\lib\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\user\\desktop\\jupyter notebook\\my_venv\\lib\\site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\user\\desktop\\jupyter notebook\\my_venv\\lib\\site-packages (from pydantic->google-generativeai) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\user\\desktop\\jupyter notebook\\my_venv\\lib\\site-packages (from pydantic->google-generativeai) (0.4.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\desktop\\jupyter notebook\\my_venv\\lib\\site-packages (from tqdm->google-generativeai) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -U google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f66b212e-30a8-4334-aec8-e18abad2e7d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_16372\\1960841083.py:1: FutureWarning: \n",
      "\n",
      "All support for the `google.generativeai` package has ended. It will no longer be receiving \n",
      "updates or bug fixes. Please switch to the `google.genai` package as soon as possible.\n",
      "See README for more details:\n",
      "\n",
      "https://github.com/google-gemini/deprecated-generative-ai-python/blob/main/README.md\n",
      "\n",
      "  import google.generativeai as genai\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAW GLOSS                      | CORRECTED ENGLISH\n",
      "------------------------------------------------------------\n",
      "HELLO ME SEAN ME DEAF          | Hello, my name is Sean. I am deaf.\n",
      "YESTERDAY YOU SCHOOL GO        | You went to school yesterday.\n",
      "BOOK READ GOOD                 | It's a good book to read.\n",
      "SHE NO LIKE DRINK MILK         | She doesn't like milk.\n",
      "FINISH EAT                     | I have finished eating.\n",
      "FAMILY ME MEET TOMORROW        | My family and I will meet tomorrow.\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "import time\n",
    "from google.api_core import exceptions\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "# PASTE YOUR API KEY HERE\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyAPqqa0CGetkTOPhd0K3XlOvU7hhD7zbMY\" \n",
    "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
    "\n",
    "# SWITCH BACK TO 1.5 FLASH (Stable, High Limits)\n",
    "model = genai.GenerativeModel('gemini-2.5-flash')\n",
    "\n",
    "def correct_grammar_gemini(raw_gloss):\n",
    "    \"\"\"\n",
    "    Translates ASL Gloss to English with Auto-Retry for Rate Limits.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert ASL (American Sign Language) interpreter. \n",
    "    Translate the following ASL Gloss into natural, spoken English.\n",
    "    \n",
    "    - Fix the grammar, word order, and tense.\n",
    "    - Convert pronouns (ME -> I/My) correctly based on context.\n",
    "    - Do not output quotation marks or explanations. Just the sentence.\n",
    "\n",
    "    ASL Gloss: \"{raw_gloss}\"\n",
    "    English Translation:\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retry Logic (Tries 3 times if it hits a limit)\n",
    "    for attempt in range(3):\n",
    "        try:\n",
    "            response = model.generate_content(prompt)\n",
    "            return response.text.strip()\n",
    "            \n",
    "        except exceptions.ResourceExhausted:\n",
    "            print(f\"Rate limit hit. Waiting 5 seconds... (Attempt {attempt+1}/3)\")\n",
    "            time.sleep(5) # Wait before retrying\n",
    "            \n",
    "        except Exception as e:\n",
    "            return f\"Error: {e}\"\n",
    "            \n",
    "    return raw_gloss # Fallback if all retries fail\n",
    "\n",
    "# --- TEST SUITE ---\n",
    "test_sentences = [\n",
    "    \"HELLO ME SEAN ME DEAF\",\n",
    "    \"YESTERDAY YOU SCHOOL GO\",\n",
    "    \"BOOK READ GOOD\",\n",
    "    \"SHE NO LIKE DRINK MILK\",\n",
    "    \"FINISH EAT\", \n",
    "    \"FAMILY ME MEET TOMORROW\"\n",
    "]\n",
    "\n",
    "print(f\"{'RAW GLOSS':<30} | {'CORRECTED ENGLISH'}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for gloss in test_sentences:\n",
    "    english = correct_grammar_gemini(gloss)\n",
    "    print(f\"{gloss:<30} | {english}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ac9191d-5354-4f5b-92bc-decf384d1c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System Ready!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import tensorflow as tf\n",
    "import keras # Added for Keras 3 compatibility\n",
    "import pandas as pd\n",
    "import time\n",
    "import threading\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "WORD_MODEL_PATH = \"best_model.h5\"\n",
    "ALPHA_MODEL_PATH = \"asl_alphabet_model.h5\"\n",
    "\n",
    "# Google Gemini API Key\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyAPqqa0CGetkTOPhd0K3XlOvU7hhD7zbMY\" \n",
    "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
    "grammar_model = genai.GenerativeModel('gemini-2.5-flash') \n",
    "\n",
    "# Tuning Parameters\n",
    "WORD_THRESHOLD = 0.85\n",
    "ALPHA_THRESHOLD = 0.90\n",
    "STABILITY_FRAMES = 5\n",
    "PREDICTION_COOLDOWN = 2.0  # Seconds to wait after a sign\n",
    "AUTO_TRANSLATE_DELAY = 4.0 # Seconds of \"no hands\" before grammar check\n",
    "\n",
    "WORD_CLASSES = [\n",
    "    \"me\", \"you\", \"we\", \"they\", \"she\",\n",
    "    \"who\", \"what\", \"yes\", \"no\", \"fine\", \"help\", \"meet\", \"good\",\n",
    "    \"want\", \"have\", \"like\", \"need\", \"go\", \"walk\", \n",
    "    \"play\", \"work\", \"learn\", \"eat\", \"drink\", \"finish\",\n",
    "    \"book\", \"family\", \"school\", \"computer\", \"deaf\"\n",
    "]\n",
    "ALPHABET_CLASSES = list(\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\")\n",
    "\n",
    "# --- LOAD MODELS (Robust Loading) ---\n",
    "print(\"Loading Models...\")\n",
    "try:\n",
    "    word_model = tf.keras.models.load_model(WORD_MODEL_PATH)\n",
    "except:\n",
    "    word_model = keras.saving.load_model(WORD_MODEL_PATH)\n",
    "\n",
    "try:\n",
    "    # Try standard load first, fallback to Keras 3 if needed\n",
    "    alpha_model = tf.keras.models.load_model(ALPHA_MODEL_PATH)\n",
    "except:\n",
    "    alpha_model = keras.saving.load_model(ALPHA_MODEL_PATH)\n",
    "\n",
    "mp_holistic = mp.solutions.holistic\n",
    "print(\"System Ready!\")\n",
    "\n",
    "# --- HELPER: INPUT PROCESSING ---\n",
    "def extract_body_landmarks(results):\n",
    "    vec = []\n",
    "    if results.pose_landmarks:\n",
    "        for lm in results.pose_landmarks.landmark: vec.extend([lm.x, lm.y, lm.z])\n",
    "    else: vec.extend([0.0]*99)\n",
    "    if results.left_hand_landmarks:\n",
    "        for lm in results.left_hand_landmarks.landmark: vec.extend([lm.x, lm.y, lm.z])\n",
    "    else: vec.extend([0.0]*63)\n",
    "    if results.right_hand_landmarks:\n",
    "        for lm in results.right_hand_landmarks.landmark: vec.extend([lm.x, lm.y, lm.z])\n",
    "    else: vec.extend([0.0]*63)\n",
    "    return vec\n",
    "\n",
    "def pre_process_word_input(data):\n",
    "    df = pd.DataFrame(data).replace(0.0, np.nan).interpolate(limit_direction='both').fillna(0.0)\n",
    "    data = df.values.astype(np.float32).reshape(-1, 75, 3)\n",
    "    for i in range(data.shape[0]):\n",
    "        left, right = data[i, 11], data[i, 12] \n",
    "        center = (left + right) / 2.0\n",
    "        width = np.linalg.norm(left - right) + 1e-6\n",
    "        data[i] = (data[i] - center) / (width / 2.0)\n",
    "    norm_seq = data.reshape(-1, 225)\n",
    "    res = np.zeros((30, 225))\n",
    "    for j in range(225): res[:, j] = np.interp(np.linspace(0, len(norm_seq)-1, 30), np.arange(len(norm_seq)), norm_seq[:, j])\n",
    "    return np.expand_dims(res, axis=0)\n",
    "\n",
    "def extract_hand_for_alphabet(hand_landmarks):\n",
    "    \"\"\"\n",
    "    UPDATED: Extracts 80 Features (Coords + Distances + Angles)\n",
    "    Matches the 'Pro' Alphabet Model logic.\n",
    "    \"\"\"\n",
    "    if not hand_landmarks: return None\n",
    "    \n",
    "    # 1. Convert to NumPy (21, 3)\n",
    "    landmarks = np.array([[lm.x, lm.y, lm.z] for lm in hand_landmarks.landmark])\n",
    "    \n",
    "    # 2. Normalize to Wrist\n",
    "    wrist = landmarks[0]\n",
    "    landmarks = landmarks - wrist\n",
    "    \n",
    "    # 3. Scale Normalization (by Middle Finger Length)\n",
    "    scale = np.linalg.norm(landmarks[12]) + 1e-6\n",
    "    landmarks = landmarks / scale\n",
    "    \n",
    "    flat_coords = landmarks.flatten() # 63 features\n",
    "    \n",
    "    # 4. Calculate Distances (13 features)\n",
    "    distances = []\n",
    "    tips = [4, 8, 12, 16, 20] # Thumb, Index, Middle, Ring, Pinky Tips\n",
    "    \n",
    "    # A. Thumb to others\n",
    "    for i in range(1, 5):\n",
    "        d = np.linalg.norm(landmarks[tips[0]] - landmarks[tips[i]])\n",
    "        distances.append(d)\n",
    "    # B. Adjacent tips\n",
    "    for i in range(4):\n",
    "        d = np.linalg.norm(landmarks[tips[i]] - landmarks[tips[i+1]])\n",
    "        distances.append(d)\n",
    "    # C. Wrist to tips\n",
    "    for i in range(5):\n",
    "        d = np.linalg.norm(landmarks[tips[i]]) \n",
    "        distances.append(d)\n",
    "        \n",
    "    # 5. Calculate Angles (4 features)\n",
    "    vectors = []\n",
    "    finger_bases = [2, 5, 9, 13, 17] # Proximal joints\n",
    "    for i in range(5):\n",
    "        vec = landmarks[tips[i]] - landmarks[finger_bases[i]]\n",
    "        vectors.append(vec)\n",
    "        \n",
    "    angles = []\n",
    "    for i in range(4):\n",
    "        v1 = vectors[i]\n",
    "        v2 = vectors[i+1]\n",
    "        cosine = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2) + 1e-6)\n",
    "        angle = np.arccos(np.clip(cosine, -1.0, 1.0))\n",
    "        angles.append(angle)\n",
    "    \n",
    "    # Total: 63 + 13 + 4 = 80 Features\n",
    "    features = np.concatenate([flat_coords, np.array(distances), np.array(angles)])\n",
    "    return features.reshape(1, -1)\n",
    "\n",
    "# --- HELPER: GRAMMAR THREAD ---\n",
    "final_corrected_sentence = \"\"\n",
    "is_correcting = False\n",
    "\n",
    "def correct_grammar_async(raw_text):\n",
    "    global final_corrected_sentence, is_correcting\n",
    "    is_correcting = True\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert ASL (American Sign Language) interpreter. \n",
    "    Translate the following ASL Gloss into natural, spoken English.\n",
    "    \n",
    "    - Fix the grammar, word order, and tense.\n",
    "    - Convert pronouns (ME -> I/My) correctly based on context.\n",
    "    - Do not output quotation marks or explanations. Just the sentence.\n",
    "\n",
    "    ASL Gloss: \"{raw_text}\"\n",
    "    English Translation:\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = grammar_model.generate_content(prompt)\n",
    "        final_corrected_sentence = response.text.strip()\n",
    "    except:\n",
    "        final_corrected_sentence = \"Translation Error\"\n",
    "    is_correcting = False\n",
    "\n",
    "# --- MAIN LOOP ---\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Buffers\n",
    "sequence_buffer = []      \n",
    "prediction_history = []   \n",
    "raw_tokens = []           \n",
    "current_display_text = \"\"\n",
    "\n",
    "# Logic Flags\n",
    "SPELLING_MODE = False\n",
    "last_sign_time = time.time()\n",
    "hands_lost_time = None\n",
    "translation_triggered = False\n",
    "last_switch_time = 0\n",
    "\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret: break\n",
    "        \n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = holistic.process(image)\n",
    "        \n",
    "        hands_visible = (results.left_hand_landmarks is not None) or (results.right_hand_landmarks is not None)\n",
    "        active_hand = results.right_hand_landmarks or results.left_hand_landmarks\n",
    "        \n",
    "        # --- CALCULATE STATUS ---\n",
    "        time_since_sign = time.time() - last_sign_time\n",
    "        is_cooldown = time_since_sign < PREDICTION_COOLDOWN\n",
    "        \n",
    "        status_text = \"\"\n",
    "        status_color = (255, 255, 255)\n",
    "\n",
    "        # Priority 1: Cooldown (Show this even if hands are lost)\n",
    "        if is_cooldown:\n",
    "            status_text = f\"COOLDOWN ({PREDICTION_COOLDOWN - time_since_sign:.1f}s)\"\n",
    "            status_color = (0, 165, 255) # Orange\n",
    "        \n",
    "        # Priority 2: Waiting for Hands\n",
    "        elif not hands_visible:\n",
    "            status_text = \"WAITING FOR HANDS...\"\n",
    "            status_color = (100, 100, 100) # Gray\n",
    "        \n",
    "        # Priority 3: Tracking\n",
    "        else:\n",
    "            status_text = \"TRACKING...\"\n",
    "            status_color = (0, 255, 0) # Green\n",
    "\n",
    "        # --- LOGIC HANDLING ---\n",
    "        \n",
    "        # 1. AUTO-TRANSLATE (No Hands Logic)\n",
    "        if not hands_visible:\n",
    "            if hands_lost_time is None:\n",
    "                hands_lost_time = time.time()\n",
    "            \n",
    "            elif (time.time() - hands_lost_time > AUTO_TRANSLATE_DELAY) and not translation_triggered:\n",
    "                if len(raw_tokens) > 0:\n",
    "                    full_text = \"\".join(raw_tokens).strip()\n",
    "                    threading.Thread(target=correct_grammar_async, args=(full_text,)).start()\n",
    "                    raw_tokens = [] \n",
    "                    current_display_text = \"\"\n",
    "                    translation_triggered = True\n",
    "\n",
    "            sequence_buffer = []\n",
    "            prediction_history = []\n",
    "            \n",
    "        else:\n",
    "            # Hands Visible Logic\n",
    "            hands_lost_time = None\n",
    "            translation_triggered = False\n",
    "            \n",
    "            # If in cooldown, we just wait. If not, we predict.\n",
    "            if not is_cooldown:\n",
    "                if SPELLING_MODE:\n",
    "                    # ALPHABET MODE\n",
    "                    inp = extract_hand_for_alphabet(active_hand)\n",
    "                    if inp is not None:\n",
    "                        pred = alpha_model.predict(inp, verbose=0)\n",
    "                        if np.max(pred) > ALPHA_THRESHOLD:\n",
    "                            prediction_history.append(ALPHABET_CLASSES[np.argmax(pred)])\n",
    "                        else:\n",
    "                            prediction_history.append(\"...\")\n",
    "                else:\n",
    "                    # WORD MODE\n",
    "                    landmarks = extract_body_landmarks(results)\n",
    "                    sequence_buffer.append(landmarks)\n",
    "                    if len(sequence_buffer) > 45: sequence_buffer.pop(0)\n",
    "                    \n",
    "                    if len(sequence_buffer) >= 30:\n",
    "                        inp = pre_process_word_input(sequence_buffer)\n",
    "                        pred = word_model.predict(inp, verbose=0)\n",
    "                        if np.max(pred) > WORD_THRESHOLD:\n",
    "                            prediction_history.append(WORD_CLASSES[np.argmax(pred)])\n",
    "                        else:\n",
    "                            prediction_history.append(\"...\")\n",
    "\n",
    "                # Stability Check\n",
    "                if len(prediction_history) > STABILITY_FRAMES:\n",
    "                    prediction_history = prediction_history[-STABILITY_FRAMES:]\n",
    "                \n",
    "                if len(prediction_history) == STABILITY_FRAMES and len(set(prediction_history)) == 1:\n",
    "                    stable = prediction_history[0]\n",
    "                    \n",
    "                    if stable != \"...\" and stable != current_display_text:\n",
    "                        current_display_text = stable\n",
    "                        if SPELLING_MODE:\n",
    "                            raw_tokens.append(stable)\n",
    "                        else:\n",
    "                            raw_tokens.append(stable)\n",
    "                            raw_tokens.append(\" \")\n",
    "                        last_sign_time = time.time() # Trigger Cooldown\n",
    "\n",
    "        # --- UI DISPLAY ---\n",
    "        cv2.rectangle(frame, (0, 0), (640, 180), (30, 30, 30), -1)\n",
    "        \n",
    "        # Line 1: Mode (Always Visible)\n",
    "        mode_str = \"MODE: SPELLING (Letters)\" if SPELLING_MODE else \"MODE: SIGNING (Words)\"\n",
    "        mode_color = (255, 0, 255) if SPELLING_MODE else (0, 255, 0) # Purple / Green\n",
    "        cv2.putText(frame, mode_str, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, mode_color, 2)\n",
    "        \n",
    "        # Line 2: Status (Cooldown / Waiting / Tracking)\n",
    "        cv2.putText(frame, f\"STATUS: {status_text}\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.6, status_color, 1)\n",
    "\n",
    "        # Line 3: Raw Text\n",
    "        raw_str = \"\".join(raw_tokens)\n",
    "        if len(raw_str) > 40: raw_str = \"...\" + raw_str[-40:]\n",
    "        cv2.putText(frame, f\"RAW: {raw_str}\", (10, 100), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "        \n",
    "        # Line 4: Final Translation\n",
    "        final_str = \"Translating...\" if is_correcting else final_corrected_sentence\n",
    "        txt_color = (0, 255, 255) if is_correcting else (0, 255, 0)\n",
    "        cv2.putText(frame, f\"FINAL: {final_str}\", (10, 150), cv2.FONT_HERSHEY_SIMPLEX, 0.7, txt_color, 2)\n",
    "\n",
    "        # Draw Skeleton\n",
    "        if results.pose_landmarks:\n",
    "             mp.solutions.drawing_utils.draw_landmarks(frame, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                mp.solutions.drawing_utils.DrawingSpec(color=(255,255,255), thickness=1, circle_radius=1),\n",
    "                mp.solutions.drawing_utils.DrawingSpec(color=(180,180,180), thickness=1, circle_radius=1))\n",
    "        if results.right_hand_landmarks:\n",
    "            mp.solutions.drawing_utils.draw_landmarks(frame, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "        if results.left_hand_landmarks:\n",
    "            mp.solutions.drawing_utils.draw_landmarks(frame, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "\n",
    "        cv2.imshow('TalkSign Final', frame)\n",
    "        \n",
    "        # --- INPUTS ---\n",
    "        key = cv2.waitKey(10) & 0xFF\n",
    "        if key == ord('q'): break\n",
    "        elif key == 32: # SPACEBAR (Toggle Mode)\n",
    "            if time.time() - last_switch_time > 0.5:\n",
    "                SPELLING_MODE = not SPELLING_MODE\n",
    "                if raw_tokens and raw_tokens[-1] != \" \": raw_tokens.append(\" \")\n",
    "                prediction_history = []\n",
    "                last_switch_time = time.time()\n",
    "        elif key == ord('c'):\n",
    "            raw_tokens = []\n",
    "            final_corrected_sentence = \"\"\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6d6038-4f7f-4b92-b15d-d9013d278cd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
