{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b3f1d2d-3e5c-4139-8030-ca2c8e51d677",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ollama\n",
      "  Downloading ollama-0.6.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: httpx>=0.27 in c:\\users\\user\\desktop\\jupyter notebook\\my_venv\\lib\\site-packages (from ollama) (0.28.1)\n",
      "Requirement already satisfied: pydantic>=2.9 in c:\\users\\user\\desktop\\jupyter notebook\\my_venv\\lib\\site-packages (from ollama) (2.12.5)\n",
      "Requirement already satisfied: anyio in c:\\users\\user\\desktop\\jupyter notebook\\my_venv\\lib\\site-packages (from httpx>=0.27->ollama) (4.10.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\user\\desktop\\jupyter notebook\\my_venv\\lib\\site-packages (from httpx>=0.27->ollama) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\user\\desktop\\jupyter notebook\\my_venv\\lib\\site-packages (from httpx>=0.27->ollama) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\user\\desktop\\jupyter notebook\\my_venv\\lib\\site-packages (from httpx>=0.27->ollama) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\user\\desktop\\jupyter notebook\\my_venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.27->ollama) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\user\\desktop\\jupyter notebook\\my_venv\\lib\\site-packages (from pydantic>=2.9->ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\user\\desktop\\jupyter notebook\\my_venv\\lib\\site-packages (from pydantic>=2.9->ollama) (2.41.5)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in c:\\users\\user\\desktop\\jupyter notebook\\my_venv\\lib\\site-packages (from pydantic>=2.9->ollama) (4.14.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\user\\desktop\\jupyter notebook\\my_venv\\lib\\site-packages (from pydantic>=2.9->ollama) (0.4.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\user\\desktop\\jupyter notebook\\my_venv\\lib\\site-packages (from anyio->httpx>=0.27->ollama) (1.3.1)\n",
      "Downloading ollama-0.6.1-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: ollama\n",
      "Successfully installed ollama-0.6.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\User\\Desktop\\JUPYTER NOTEBOOK\\my_venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\User\\Desktop\\JUPYTER NOTEBOOK\\my_venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\User\\Desktop\\JUPYTER NOTEBOOK\\my_venv\\Lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5df9b344-f881-4233-a333-34586c84425f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: mediapipe 0.10.31\n",
      "Uninstalling mediapipe-0.10.31:\n",
      "  Successfully uninstalled mediapipe-0.10.31\n",
      "Collecting mediapipe==0.10.11\n",
      "  Downloading mediapipe-0.10.11-cp311-cp311-win_amd64.whl.metadata (9.8 kB)\n",
      "Collecting absl-py (from mediapipe==0.10.11)\n",
      "  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting attrs>=19.1.0 (from mediapipe==0.10.11)\n",
      "  Downloading attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting flatbuffers>=2.0 (from mediapipe==0.10.11)\n",
      "  Downloading flatbuffers-25.12.19-py2.py3-none-any.whl.metadata (1.0 kB)\n",
      "Collecting jax (from mediapipe==0.10.11)\n",
      "  Downloading jax-0.8.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting matplotlib (from mediapipe==0.10.11)\n",
      "  Downloading matplotlib-3.10.8-cp311-cp311-win_amd64.whl.metadata (52 kB)\n",
      "Collecting numpy (from mediapipe==0.10.11)\n",
      "  Downloading numpy-2.4.0-cp311-cp311-win_amd64.whl.metadata (6.6 kB)\n",
      "Collecting opencv-contrib-python (from mediapipe==0.10.11)\n",
      "  Downloading opencv_contrib_python-4.12.0.88-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Collecting protobuf<4,>=3.11 (from mediapipe==0.10.11)\n",
      "  Downloading protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\n",
      "Collecting sounddevice>=0.4.4 (from mediapipe==0.10.11)\n",
      "  Downloading sounddevice-0.5.3-py3-none-win_amd64.whl.metadata (1.6 kB)\n",
      "Collecting CFFI>=1.0 (from sounddevice>=0.4.4->mediapipe==0.10.11)\n",
      "  Downloading cffi-2.0.0-cp311-cp311-win_amd64.whl.metadata (2.6 kB)\n",
      "Collecting pycparser (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe==0.10.11)\n",
      "  Downloading pycparser-2.23-py3-none-any.whl.metadata (993 bytes)\n",
      "Collecting jaxlib<=0.8.2,>=0.8.2 (from jax->mediapipe==0.10.11)\n",
      "  Downloading jaxlib-0.8.2-cp311-cp311-win_amd64.whl.metadata (1.4 kB)\n",
      "Collecting ml_dtypes>=0.5.0 (from jax->mediapipe==0.10.11)\n",
      "  Downloading ml_dtypes-0.5.4-cp311-cp311-win_amd64.whl.metadata (9.2 kB)\n",
      "Collecting opt_einsum (from jax->mediapipe==0.10.11)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting scipy>=1.13 (from jax->mediapipe==0.10.11)\n",
      "  Downloading scipy-1.16.3-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib->mediapipe==0.10.11)\n",
      "  Downloading contourpy-1.3.3-cp311-cp311-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib->mediapipe==0.10.11)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib->mediapipe==0.10.11)\n",
      "  Downloading fonttools-4.61.1-cp311-cp311-win_amd64.whl.metadata (116 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib->mediapipe==0.10.11)\n",
      "  Downloading kiwisolver-1.4.9-cp311-cp311-win_amd64.whl.metadata (6.4 kB)\n",
      "Collecting packaging>=20.0 (from matplotlib->mediapipe==0.10.11)\n",
      "  Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting pillow>=8 (from matplotlib->mediapipe==0.10.11)\n",
      "  Downloading pillow-12.1.0-cp311-cp311-win_amd64.whl.metadata (9.0 kB)\n",
      "Collecting pyparsing>=3 (from matplotlib->mediapipe==0.10.11)\n",
      "  Downloading pyparsing-3.3.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting python-dateutil>=2.7 (from matplotlib->mediapipe==0.10.11)\n",
      "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting six>=1.5 (from python-dateutil>=2.7->matplotlib->mediapipe==0.10.11)\n",
      "  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting numpy (from mediapipe==0.10.11)\n",
      "  Downloading numpy-2.2.6-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "Downloading mediapipe-0.10.11-cp311-cp311-win_amd64.whl (50.8 MB)\n",
      "   ---------------------------------------- 0.0/50.8 MB ? eta -:--:--\n",
      "   - -------------------------------------- 1.8/50.8 MB 11.2 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 7.6/50.8 MB 29.4 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 12.8/50.8 MB 24.4 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 21.0/50.8 MB 27.6 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 35.7/50.8 MB 37.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 50.8/50.8 MB 43.7 MB/s  0:00:01\n",
      "Downloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
      "Downloading attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "Downloading flatbuffers-25.12.19-py2.py3-none-any.whl (26 kB)\n",
      "Downloading sounddevice-0.5.3-py3-none-win_amd64.whl (364 kB)\n",
      "Downloading cffi-2.0.0-cp311-cp311-win_amd64.whl (182 kB)\n",
      "Downloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Downloading jax-0.8.2-py3-none-any.whl (2.9 MB)\n",
      "   ---------------------------------------- 0.0/2.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.9/2.9 MB 85.9 MB/s  0:00:00\n",
      "Downloading jaxlib-0.8.2-cp311-cp311-win_amd64.whl (60.3 MB)\n",
      "   ---------------------------------------- 0.0/60.3 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 15.5/60.3 MB 74.9 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 30.9/60.3 MB 72.9 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 38.5/60.3 MB 61.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 45.9/60.3 MB 54.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 54.5/60.3 MB 51.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 60.3/60.3 MB 49.9 MB/s  0:00:01\n",
      "Downloading ml_dtypes-0.5.4-cp311-cp311-win_amd64.whl (210 kB)\n",
      "Downloading scipy-1.16.3-cp311-cp311-win_amd64.whl (38.7 MB)\n",
      "   ---------------------------------------- 0.0/38.7 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 7.6/38.7 MB 39.3 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 15.2/38.7 MB 36.8 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 22.5/38.7 MB 36.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 30.7/38.7 MB 37.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.0/38.7 MB 37.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 38.7/38.7 MB 37.3 MB/s  0:00:01\n",
      "Downloading matplotlib-3.10.8-cp311-cp311-win_amd64.whl (8.1 MB)\n",
      "   ---------------------------------------- 0.0/8.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 8.1/8.1 MB 38.6 MB/s  0:00:00\n",
      "Downloading contourpy-1.3.3-cp311-cp311-win_amd64.whl (225 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.61.1-cp311-cp311-win_amd64.whl (2.3 MB)\n",
      "   ---------------------------------------- 0.0/2.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.3/2.3 MB 44.0 MB/s  0:00:00\n",
      "Downloading kiwisolver-1.4.9-cp311-cp311-win_amd64.whl (73 kB)\n",
      "Downloading packaging-25.0-py3-none-any.whl (66 kB)\n",
      "Downloading pillow-12.1.0-cp311-cp311-win_amd64.whl (7.0 MB)\n",
      "   ---------------------------------------- 0.0/7.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 7.0/7.0 MB 39.4 MB/s  0:00:00\n",
      "Downloading pyparsing-3.3.1-py3-none-any.whl (121 kB)\n",
      "Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "Downloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
      "Downloading opencv_contrib_python-4.12.0.88-cp37-abi3-win_amd64.whl (45.3 MB)\n",
      "   ---------------------------------------- 0.0/45.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 8.4/45.3 MB 40.0 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 16.8/45.3 MB 40.7 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 24.9/45.3 MB 40.5 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 33.0/45.3 MB 40.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 41.7/45.3 MB 40.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 45.3/45.3 MB 40.6 MB/s  0:00:01\n",
      "Downloading numpy-2.2.6-cp311-cp311-win_amd64.whl (12.9 MB)\n",
      "   ---------------------------------------- 0.0/12.9 MB ? eta -:--:--\n",
      "   ------------------------- -------------- 8.4/12.9 MB 40.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.9/12.9 MB 40.5 MB/s  0:00:00\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading pycparser-2.23-py3-none-any.whl (118 kB)\n",
      "Installing collected packages: flatbuffers, six, pyparsing, pycparser, protobuf, pillow, packaging, opt_einsum, numpy, kiwisolver, fonttools, cycler, attrs, absl-py, scipy, python-dateutil, opencv-contrib-python, ml_dtypes, contourpy, CFFI, sounddevice, matplotlib, jaxlib, jax, mediapipe\n",
      "\n",
      "  Attempting uninstall: flatbuffers\n",
      "\n",
      "    Found existing installation: flatbuffers 25.12.19\n",
      "\n",
      "    Uninstalling flatbuffers-25.12.19:\n",
      "\n",
      "      Successfully uninstalled flatbuffers-25.12.19\n",
      "\n",
      "  Attempting uninstall: six\n",
      "\n",
      "    Found existing installation: six 1.17.0\n",
      "\n",
      "    Uninstalling six-1.17.0:\n",
      "\n",
      "   - --------------------------------------  1/25 [six]\n",
      "   - --------------------------------------  1/25 [six]\n",
      "   - --------------------------------------  1/25 [six]\n",
      "   - --------------------------------------  1/25 [six]\n",
      "   - --------------------------------------  1/25 [six]\n",
      "   - --------------------------------------  1/25 [six]\n",
      "   - --------------------------------------  1/25 [six]\n",
      "   - --------------------------------------  1/25 [six]\n",
      "   - --------------------------------------  1/25 [six]\n",
      "   - --------------------------------------  1/25 [six]\n",
      "   - --------------------------------------  1/25 [six]\n",
      "      Successfully uninstalled six-1.17.0\n",
      "   - --------------------------------------  1/25 [six]\n",
      "  Attempting uninstall: pyparsing\n",
      "   - --------------------------------------  1/25 [six]\n",
      "    Found existing installation: pyparsing 3.2.3\n",
      "   - --------------------------------------  1/25 [six]\n",
      "    Uninstalling pyparsing-3.2.3:\n",
      "   - --------------------------------------  1/25 [six]\n",
      "      Successfully uninstalled pyparsing-3.2.3\n",
      "   - --------------------------------------  1/25 [six]\n",
      "   --- ------------------------------------  2/25 [pyparsing]\n",
      "  Attempting uninstall: pycparser\n",
      "   --- ------------------------------------  2/25 [pyparsing]\n",
      "    Found existing installation: pycparser 2.23\n",
      "   --- ------------------------------------  2/25 [pyparsing]\n",
      "    Uninstalling pycparser-2.23:\n",
      "   --- ------------------------------------  2/25 [pyparsing]\n",
      "      Successfully uninstalled pycparser-2.23\n",
      "   --- ------------------------------------  2/25 [pyparsing]\n",
      "   ---- -----------------------------------  3/25 [pycparser]\n",
      "   ---- -----------------------------------  3/25 [pycparser]\n",
      "  Attempting uninstall: protobuf\n",
      "   ---- -----------------------------------  3/25 [pycparser]\n",
      "    Found existing installation: protobuf 6.33.2\n",
      "   ---- -----------------------------------  3/25 [pycparser]\n",
      "    Uninstalling protobuf-6.33.2:\n",
      "   ---- -----------------------------------  3/25 [pycparser]\n",
      "      Successfully uninstalled protobuf-6.33.2\n",
      "   ---- -----------------------------------  3/25 [pycparser]\n",
      "   ------ ---------------------------------  4/25 [protobuf]\n",
      "   ------ ---------------------------------  4/25 [protobuf]\n",
      "   ------ ---------------------------------  4/25 [protobuf]\n",
      "   ------ ---------------------------------  4/25 [protobuf]\n",
      "   ------ ---------------------------------  4/25 [protobuf]\n",
      "   ------ ---------------------------------  4/25 [protobuf]\n",
      "   ------ ---------------------------------  4/25 [protobuf]\n",
      "   ------ ---------------------------------  4/25 [protobuf]\n",
      "   ------ ---------------------------------  4/25 [protobuf]\n",
      "   ------ ---------------------------------  4/25 [protobuf]\n",
      "   ------ ---------------------------------  4/25 [protobuf]\n",
      "   ------ ---------------------------------  4/25 [protobuf]\n",
      "   ------ ---------------------------------  4/25 [protobuf]\n",
      "   ------ ---------------------------------  4/25 [protobuf]\n",
      "   ------ ---------------------------------  4/25 [protobuf]\n",
      "   ------ ---------------------------------  4/25 [protobuf]\n",
      "   ------ ---------------------------------  4/25 [protobuf]\n",
      "   ------ ---------------------------------  4/25 [protobuf]\n",
      "   ------ ---------------------------------  4/25 [protobuf]\n",
      "   ------ ---------------------------------  4/25 [protobuf]\n",
      "   ------ ---------------------------------  4/25 [protobuf]\n",
      "  Attempting uninstall: pillow\n",
      "   ------ ---------------------------------  4/25 [protobuf]\n",
      "    Found existing installation: pillow 11.3.0\n",
      "   ------ ---------------------------------  4/25 [protobuf]\n",
      "   -------- -------------------------------  5/25 [pillow]\n",
      "    Uninstalling pillow-11.3.0:\n",
      "   -------- -------------------------------  5/25 [pillow]\n",
      "      Successfully uninstalled pillow-11.3.0\n",
      "   -------- -------------------------------  5/25 [pillow]\n",
      "   -------- -------------------------------  5/25 [pillow]\n",
      "   -------- -------------------------------  5/25 [pillow]\n",
      "   -------- -------------------------------  5/25 [pillow]\n",
      "   -------- -------------------------------  5/25 [pillow]\n",
      "   -------- -------------------------------  5/25 [pillow]\n",
      "   -------- -------------------------------  5/25 [pillow]\n",
      "   -------- -------------------------------  5/25 [pillow]\n",
      "   -------- -------------------------------  5/25 [pillow]\n",
      "   -------- -------------------------------  5/25 [pillow]\n",
      "   -------- -------------------------------  5/25 [pillow]\n",
      "   -------- -------------------------------  5/25 [pillow]\n",
      "   -------- -------------------------------  5/25 [pillow]\n",
      "   -------- -------------------------------  5/25 [pillow]\n",
      "   -------- -------------------------------  5/25 [pillow]\n",
      "   -------- -------------------------------  5/25 [pillow]\n",
      "   -------- -------------------------------  5/25 [pillow]\n",
      "   -------- -------------------------------  5/25 [pillow]\n",
      "   -------- -------------------------------  5/25 [pillow]\n",
      "   -------- -------------------------------  5/25 [pillow]\n",
      "   -------- -------------------------------  5/25 [pillow]\n",
      "   -------- -------------------------------  5/25 [pillow]\n",
      "   -------- -------------------------------  5/25 [pillow]\n",
      "   -------- -------------------------------  5/25 [pillow]\n",
      "   -------- -------------------------------  5/25 [pillow]\n",
      "  Attempting uninstall: packaging\n",
      "   -------- -------------------------------  5/25 [pillow]\n",
      "    Found existing installation: packaging 25.0\n",
      "   -------- -------------------------------  5/25 [pillow]\n",
      "    Uninstalling packaging-25.0:\n",
      "   -------- -------------------------------  5/25 [pillow]\n",
      "      Successfully uninstalled packaging-25.0\n",
      "   -------- -------------------------------  5/25 [pillow]\n",
      "   --------- ------------------------------  6/25 [packaging]\n",
      "  Attempting uninstall: opt_einsum\n",
      "   --------- ------------------------------  6/25 [packaging]\n",
      "    Found existing installation: opt_einsum 3.4.0\n",
      "   --------- ------------------------------  6/25 [packaging]\n",
      "    Uninstalling opt_einsum-3.4.0:\n",
      "   --------- ------------------------------  6/25 [packaging]\n",
      "      Successfully uninstalled opt_einsum-3.4.0\n",
      "   --------- ------------------------------  6/25 [packaging]\n",
      "   ----------- ----------------------------  7/25 [opt_einsum]\n",
      "   ----------- ----------------------------  7/25 [opt_einsum]\n",
      "  Attempting uninstall: numpy\n",
      "   ----------- ----------------------------  7/25 [opt_einsum]\n",
      "    Found existing installation: numpy 1.26.4\n",
      "   ----------- ----------------------------  7/25 [opt_einsum]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "    Uninstalling numpy-1.26.4:\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "  Attempting uninstall: kiwisolver\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "    Found existing installation: kiwisolver 1.4.8\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "    Uninstalling kiwisolver-1.4.8:\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "      Successfully uninstalled kiwisolver-1.4.8\n",
      "   ------------ ---------------------------  8/25 [numpy]\n",
      "   -------------- -------------------------  9/25 [kiwisolver]\n",
      "   -------------- -------------------------  9/25 [kiwisolver]\n",
      "   -------------- -------------------------  9/25 [kiwisolver]\n",
      "   -------------- -------------------------  9/25 [kiwisolver]\n",
      "   -------------- -------------------------  9/25 [kiwisolver]\n",
      "   -------------- -------------------------  9/25 [kiwisolver]\n",
      "   -------------- -------------------------  9/25 [kiwisolver]\n",
      "   -------------- -------------------------  9/25 [kiwisolver]\n",
      "   -------------- -------------------------  9/25 [kiwisolver]\n",
      "   -------------- -------------------------  9/25 [kiwisolver]\n",
      "   -------------- -------------------------  9/25 [kiwisolver]\n",
      "   -------------- -------------------------  9/25 [kiwisolver]\n",
      "   -------------- -------------------------  9/25 [kiwisolver]\n",
      "   -------------- -------------------------  9/25 [kiwisolver]\n",
      "   -------------- -------------------------  9/25 [kiwisolver]\n",
      "   -------------- -------------------------  9/25 [kiwisolver]\n",
      "   -------------- -------------------------  9/25 [kiwisolver]\n",
      "  Attempting uninstall: fonttools\n",
      "   -------------- -------------------------  9/25 [kiwisolver]\n",
      "   ---------------- ----------------------- 10/25 [fonttools]\n",
      "    Found existing installation: fonttools 4.59.0\n",
      "   ---------------- ----------------------- 10/25 [fonttools]\n",
      "    Uninstalling fonttools-4.59.0:\n",
      "   ---------------- ----------------------- 10/25 [fonttools]\n",
      "      Successfully uninstalled fonttools-4.59.0\n",
      "   ---------------- ----------------------- 10/25 [fonttools]\n",
      "   ---------------- ----------------------- 10/25 [fonttools]\n",
      "   ---------------- ----------------------- 10/25 [fonttools]\n",
      "   ---------------- ----------------------- 10/25 [fonttools]\n",
      "   ---------------- ----------------------- 10/25 [fonttools]\n",
      "   ---------------- ----------------------- 10/25 [fonttools]\n",
      "   ---------------- ----------------------- 10/25 [fonttools]\n",
      "   ---------------- ----------------------- 10/25 [fonttools]\n",
      "   ---------------- ----------------------- 10/25 [fonttools]\n",
      "   ---------------- ----------------------- 10/25 [fonttools]\n",
      "   ---------------- ----------------------- 10/25 [fonttools]\n",
      "   ---------------- ----------------------- 10/25 [fonttools]\n",
      "   ---------------- ----------------------- 10/25 [fonttools]\n",
      "   ---------------- ----------------------- 10/25 [fonttools]\n",
      "   ---------------- ----------------------- 10/25 [fonttools]\n",
      "   ---------------- ----------------------- 10/25 [fonttools]\n",
      "   ---------------- ----------------------- 10/25 [fonttools]\n",
      "   ---------------- ----------------------- 10/25 [fonttools]\n",
      "   ---------------- ----------------------- 10/25 [fonttools]\n",
      "   ---------------- ----------------------- 10/25 [fonttools]\n",
      "   ---------------- ----------------------- 10/25 [fonttools]\n",
      "   ---------------- ----------------------- 10/25 [fonttools]\n",
      "   ---------------- ----------------------- 10/25 [fonttools]\n",
      "   ---------------- ----------------------- 10/25 [fonttools]\n",
      "   ---------------- ----------------------- 10/25 [fonttools]\n",
      "   ---------------- ----------------------- 10/25 [fonttools]\n",
      "   ---------------- ----------------------- 10/25 [fonttools]\n",
      "   ---------------- ----------------------- 10/25 [fonttools]\n",
      "   ---------------- ----------------------- 10/25 [fonttools]\n",
      "  Attempting uninstall: cycler\n",
      "   ---------------- ----------------------- 10/25 [fonttools]\n",
      "    Found existing installation: cycler 0.12.1\n",
      "   ---------------- ----------------------- 10/25 [fonttools]\n",
      "    Uninstalling cycler-0.12.1:\n",
      "   ---------------- ----------------------- 10/25 [fonttools]\n",
      "      Successfully uninstalled cycler-0.12.1\n",
      "   ---------------- ----------------------- 10/25 [fonttools]\n",
      "  Attempting uninstall: attrs\n",
      "   ---------------- ----------------------- 10/25 [fonttools]\n",
      "    Found existing installation: attrs 25.3.0\n",
      "   ---------------- ----------------------- 10/25 [fonttools]\n",
      "    Uninstalling attrs-25.3.0:\n",
      "   ---------------- ----------------------- 10/25 [fonttools]\n",
      "      Successfully uninstalled attrs-25.3.0\n",
      "   ---------------- ----------------------- 10/25 [fonttools]\n",
      "   ------------------- -------------------- 12/25 [attrs]\n",
      "   ------------------- -------------------- 12/25 [attrs]\n",
      "  Attempting uninstall: absl-py\n",
      "   ------------------- -------------------- 12/25 [attrs]\n",
      "    Found existing installation: absl-py 2.3.1\n",
      "   ------------------- -------------------- 12/25 [attrs]\n",
      "    Uninstalling absl-py-2.3.1:\n",
      "   ------------------- -------------------- 12/25 [attrs]\n",
      "      Successfully uninstalled absl-py-2.3.1\n",
      "   ------------------- -------------------- 12/25 [attrs]\n",
      "   -------------------- ------------------- 13/25 [absl-py]\n",
      "   -------------------- ------------------- 13/25 [absl-py]\n",
      "  Attempting uninstall: scipy\n",
      "   -------------------- ------------------- 13/25 [absl-py]\n",
      "    Found existing installation: scipy 1.15.3\n",
      "   -------------------- ------------------- 13/25 [absl-py]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "    Uninstalling scipy-1.15.3:\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "      Successfully uninstalled scipy-1.15.3\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "  Attempting uninstall: python-dateutil\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "    Found existing installation: python-dateutil 2.9.0.post0\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "    Uninstalling python-dateutil-2.9.0.post0:\n",
      "   ---------------------- ----------------- 14/25 [scipy]\n",
      "   ------------------------ --------------- 15/25 [python-dateutil]\n",
      "      Successfully uninstalled python-dateutil-2.9.0.post0\n",
      "   ------------------------ --------------- 15/25 [python-dateutil]\n",
      "   ------------------------ --------------- 15/25 [python-dateutil]\n",
      "  Attempting uninstall: opencv-contrib-python\n",
      "   ------------------------ --------------- 15/25 [python-dateutil]\n",
      "    Found existing installation: opencv-contrib-python 4.11.0.86\n",
      "   ------------------------ --------------- 15/25 [python-dateutil]\n",
      "    Uninstalling opencv-contrib-python-4.11.0.86:\n",
      "   ------------------------ --------------- 15/25 [python-dateutil]\n",
      "   ------------------------- -------------- 16/25 [opencv-contrib-python]\n",
      "      Successfully uninstalled opencv-contrib-python-4.11.0.86\n",
      "   ------------------------- -------------- 16/25 [opencv-contrib-python]\n",
      "   ------------------------- -------------- 16/25 [opencv-contrib-python]\n",
      "   ------------------------- -------------- 16/25 [opencv-contrib-python]\n",
      "   ------------------------- -------------- 16/25 [opencv-contrib-python]\n",
      "   ------------------------- -------------- 16/25 [opencv-contrib-python]\n",
      "   ------------------------- -------------- 16/25 [opencv-contrib-python]\n",
      "   ------------------------- -------------- 16/25 [opencv-contrib-python]\n",
      "   ------------------------- -------------- 16/25 [opencv-contrib-python]\n",
      "   ------------------------- -------------- 16/25 [opencv-contrib-python]\n",
      "   ------------------------- -------------- 16/25 [opencv-contrib-python]\n",
      "   ------------------------- -------------- 16/25 [opencv-contrib-python]\n",
      "   ------------------------- -------------- 16/25 [opencv-contrib-python]\n",
      "   ------------------------- -------------- 16/25 [opencv-contrib-python]\n",
      "   ------------------------- -------------- 16/25 [opencv-contrib-python]\n",
      "   ------------------------- -------------- 16/25 [opencv-contrib-python]\n",
      "   ------------------------- -------------- 16/25 [opencv-contrib-python]\n",
      "   ------------------------- -------------- 16/25 [opencv-contrib-python]\n",
      "   ------------------------- -------------- 16/25 [opencv-contrib-python]\n",
      "   ------------------------- -------------- 16/25 [opencv-contrib-python]\n",
      "   ------------------------- -------------- 16/25 [opencv-contrib-python]\n",
      "   ------------------------- -------------- 16/25 [opencv-contrib-python]\n",
      "   ------------------------- -------------- 16/25 [opencv-contrib-python]\n",
      "   ------------------------- -------------- 16/25 [opencv-contrib-python]\n",
      "   ------------------------- -------------- 16/25 [opencv-contrib-python]\n",
      "   ------------------------- -------------- 16/25 [opencv-contrib-python]\n",
      "   ------------------------- -------------- 16/25 [opencv-contrib-python]\n",
      "  Attempting uninstall: ml_dtypes\n",
      "   ------------------------- -------------- 16/25 [opencv-contrib-python]\n",
      "    Found existing installation: ml_dtypes 0.5.3\n",
      "   ------------------------- -------------- 16/25 [opencv-contrib-python]\n",
      "    Uninstalling ml_dtypes-0.5.3:\n",
      "   ------------------------- -------------- 16/25 [opencv-contrib-python]\n",
      "      Successfully uninstalled ml_dtypes-0.5.3\n",
      "   ------------------------- -------------- 16/25 [opencv-contrib-python]\n",
      "   --------------------------- ------------ 17/25 [ml_dtypes]\n",
      "   --------------------------- ------------ 17/25 [ml_dtypes]\n",
      "   --------------------------- ------------ 17/25 [ml_dtypes]\n",
      "   --------------------------- ------------ 17/25 [ml_dtypes]\n",
      "   --------------------------- ------------ 17/25 [ml_dtypes]\n",
      "   --------------------------- ------------ 17/25 [ml_dtypes]\n",
      "   --------------------------- ------------ 17/25 [ml_dtypes]\n",
      "   --------------------------- ------------ 17/25 [ml_dtypes]\n",
      "   --------------------------- ------------ 17/25 [ml_dtypes]\n",
      "   --------------------------- ------------ 17/25 [ml_dtypes]\n",
      "   --------------------------- ------------ 17/25 [ml_dtypes]\n",
      "   --------------------------- ------------ 17/25 [ml_dtypes]\n",
      "   --------------------------- ------------ 17/25 [ml_dtypes]\n",
      "   --------------------------- ------------ 17/25 [ml_dtypes]\n",
      "   --------------------------- ------------ 17/25 [ml_dtypes]\n",
      "   --------------------------- ------------ 17/25 [ml_dtypes]\n",
      "   --------------------------- ------------ 17/25 [ml_dtypes]\n",
      "   --------------------------- ------------ 17/25 [ml_dtypes]\n",
      "  Attempting uninstall: contourpy\n",
      "   --------------------------- ------------ 17/25 [ml_dtypes]\n",
      "    Found existing installation: contourpy 1.3.2\n",
      "   --------------------------- ------------ 17/25 [ml_dtypes]\n",
      "    Uninstalling contourpy-1.3.2:\n",
      "   --------------------------- ------------ 17/25 [ml_dtypes]\n",
      "      Successfully uninstalled contourpy-1.3.2\n",
      "   --------------------------- ------------ 17/25 [ml_dtypes]\n",
      "   ---------------------------- ----------- 18/25 [contourpy]\n",
      "  Attempting uninstall: CFFI\n",
      "   ---------------------------- ----------- 18/25 [contourpy]\n",
      "    Found existing installation: cffi 2.0.0\n",
      "   ---------------------------- ----------- 18/25 [contourpy]\n",
      "   ------------------------------ --------- 19/25 [CFFI]\n",
      "    Uninstalling cffi-2.0.0:\n",
      "   ------------------------------ --------- 19/25 [CFFI]\n",
      "   ------------------------------ --------- 19/25 [CFFI]\n",
      "   ------------------------------ --------- 19/25 [CFFI]\n",
      "   ------------------------------ --------- 19/25 [CFFI]\n",
      "   ------------------------------ --------- 19/25 [CFFI]\n",
      "   ------------------------------ --------- 19/25 [CFFI]\n",
      "   ------------------------------ --------- 19/25 [CFFI]\n",
      "   ------------------------------ --------- 19/25 [CFFI]\n",
      "   ------------------------------ --------- 19/25 [CFFI]\n",
      "   ------------------------------ --------- 19/25 [CFFI]\n",
      "      Successfully uninstalled cffi-2.0.0\n",
      "   ------------------------------ --------- 19/25 [CFFI]\n",
      "   ------------------------------ --------- 19/25 [CFFI]\n",
      "   ------------------------------ --------- 19/25 [CFFI]\n",
      "   ------------------------------ --------- 19/25 [CFFI]\n",
      "   ------------------------------ --------- 19/25 [CFFI]\n",
      "   ------------------------------ --------- 19/25 [CFFI]\n",
      "   ------------------------------ --------- 19/25 [CFFI]\n",
      "   ------------------------------ --------- 19/25 [CFFI]\n",
      "   ------------------------------ --------- 19/25 [CFFI]\n",
      "   ------------------------------ --------- 19/25 [CFFI]\n",
      "   ------------------------------ --------- 19/25 [CFFI]\n",
      "   ------------------------------ --------- 19/25 [CFFI]\n",
      "   ------------------------------ --------- 19/25 [CFFI]\n",
      "   ------------------------------ --------- 19/25 [CFFI]\n",
      "   ------------------------------ --------- 19/25 [CFFI]\n",
      "   ------------------------------ --------- 19/25 [CFFI]\n",
      "   ------------------------------ --------- 19/25 [CFFI]\n",
      "   ------------------------------ --------- 19/25 [CFFI]\n",
      "   ------------------------------ --------- 19/25 [CFFI]\n",
      "   ------------------------------ --------- 19/25 [CFFI]\n",
      "  Attempting uninstall: sounddevice\n",
      "   ------------------------------ --------- 19/25 [CFFI]\n",
      "    Found existing installation: sounddevice 0.5.3\n",
      "   ------------------------------ --------- 19/25 [CFFI]\n",
      "    Uninstalling sounddevice-0.5.3:\n",
      "   ------------------------------ --------- 19/25 [CFFI]\n",
      "   -------------------------------- ------- 20/25 [sounddevice]\n",
      "   -------------------------------- ------- 20/25 [sounddevice]\n",
      "   -------------------------------- ------- 20/25 [sounddevice]\n",
      "   -------------------------------- ------- 20/25 [sounddevice]\n",
      "   -------------------------------- ------- 20/25 [sounddevice]\n",
      "   -------------------------------- ------- 20/25 [sounddevice]\n",
      "   -------------------------------- ------- 20/25 [sounddevice]\n",
      "   -------------------------------- ------- 20/25 [sounddevice]\n",
      "   -------------------------------- ------- 20/25 [sounddevice]\n",
      "   -------------------------------- ------- 20/25 [sounddevice]\n",
      "      Successfully uninstalled sounddevice-0.5.3\n",
      "   -------------------------------- ------- 20/25 [sounddevice]\n",
      "   -------------------------------- ------- 20/25 [sounddevice]\n",
      "   -------------------------------- ------- 20/25 [sounddevice]\n",
      "   -------------------------------- ------- 20/25 [sounddevice]\n",
      "   -------------------------------- ------- 20/25 [sounddevice]\n",
      "   -------------------------------- ------- 20/25 [sounddevice]\n",
      "   -------------------------------- ------- 20/25 [sounddevice]\n",
      "   -------------------------------- ------- 20/25 [sounddevice]\n",
      "   -------------------------------- ------- 20/25 [sounddevice]\n",
      "   -------------------------------- ------- 20/25 [sounddevice]\n",
      "   -------------------------------- ------- 20/25 [sounddevice]\n",
      "   -------------------------------- ------- 20/25 [sounddevice]\n",
      "   -------------------------------- ------- 20/25 [sounddevice]\n",
      "   -------------------------------- ------- 20/25 [sounddevice]\n",
      "   -------------------------------- ------- 20/25 [sounddevice]\n",
      "   -------------------------------- ------- 20/25 [sounddevice]\n",
      "   -------------------------------- ------- 20/25 [sounddevice]\n",
      "   -------------------------------- ------- 20/25 [sounddevice]\n",
      "   -------------------------------- ------- 20/25 [sounddevice]\n",
      "  Attempting uninstall: matplotlib\n",
      "   -------------------------------- ------- 20/25 [sounddevice]\n",
      "    Found existing installation: matplotlib 3.10.5\n",
      "   -------------------------------- ------- 20/25 [sounddevice]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "    Uninstalling matplotlib-3.10.5:\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "   --------------------------------- ------ 21/25 [matplotlib]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\User\\Desktop\\JUPYTER NOTEBOOK\\my_venv\\Lib\\site-packages\\google\\~.pb'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\User\\Desktop\\JUPYTER NOTEBOOK\\my_venv\\Lib\\site-packages\\~il'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\User\\Desktop\\JUPYTER NOTEBOOK\\my_venv\\Lib\\site-packages\\~=mpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\User\\Desktop\\JUPYTER NOTEBOOK\\my_venv\\Lib\\site-packages\\~%mpy'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\User\\Desktop\\JUPYTER NOTEBOOK\\my_venv\\Lib\\site-packages\\~iwisolver'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\User\\Desktop\\JUPYTER NOTEBOOK\\my_venv\\Lib\\site-packages\\~-ipy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\User\\Desktop\\JUPYTER NOTEBOOK\\my_venv\\Lib\\site-packages\\~-ipy'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\User\\AppData\\Local\\Temp\\pip-uninstall-70s4qh4k'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\User\\Desktop\\JUPYTER NOTEBOOK\\my_venv\\Lib\\site-packages\\~l_dtypes'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\User\\AppData\\Local\\Temp\\pip-uninstall-045mpuj8'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\User\\Desktop\\JUPYTER NOTEBOOK\\my_venv\\Lib\\site-packages\\~-ounddevice_data'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'c:\\\\users\\\\user\\\\desktop\\\\jupyter notebook\\\\my_venv\\\\lib\\\\site-packages\\\\matplotlib\\\\backends\\\\_backend_agg.cp311-win_amd64.pyd'\n",
      "Check the permissions.\n",
      "\n",
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y mediapipe\n",
    "!pip install mediapipe==0.10.11 --force-reinstall --no-cache-dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d30c25af-1022-4ac6-bd1a-6b74899aeb11",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning in: C:\\Users\\User\\Desktop\\JUPYTER NOTEBOOK\\TalkSign\\videos_msasl\n",
      "\n",
      " Processing folder: /j\n",
      "    Renamed: 1.avi -> j_1.avi\n",
      "    Renamed: 10.avi -> j_10.avi\n",
      "    Renamed: 100.avi -> j_100.avi\n",
      "    Renamed: 101.avi -> j_101.avi\n",
      "    Renamed: 102.avi -> j_102.avi\n",
      "    Renamed: 103.avi -> j_103.avi\n",
      "    Renamed: 104.avi -> j_104.avi\n",
      "    Renamed: 105.avi -> j_105.avi\n",
      "    Renamed: 106.avi -> j_106.avi\n",
      "    Renamed: 107.avi -> j_107.avi\n",
      "    Renamed: 108.avi -> j_108.avi\n",
      "    Renamed: 109.avi -> j_109.avi\n",
      "    Renamed: 11.avi -> j_11.avi\n",
      "    Renamed: 110.avi -> j_110.avi\n",
      "    Renamed: 111.avi -> j_111.avi\n",
      "    Renamed: 112.avi -> j_112.avi\n",
      "    Renamed: 113.avi -> j_113.avi\n",
      "    Renamed: 114.avi -> j_114.avi\n",
      "    Renamed: 115.avi -> j_115.avi\n",
      "    Renamed: 116.avi -> j_116.avi\n",
      "    Renamed: 117.avi -> j_117.avi\n",
      "    Renamed: 118.avi -> j_118.avi\n",
      "    Renamed: 119.avi -> j_119.avi\n",
      "    Renamed: 12.avi -> j_12.avi\n",
      "    Renamed: 120.avi -> j_120.avi\n",
      "    Renamed: 121.avi -> j_121.avi\n",
      "    Renamed: 122.avi -> j_122.avi\n",
      "    Renamed: 123.avi -> j_123.avi\n",
      "    Renamed: 124.avi -> j_124.avi\n",
      "    Renamed: 125.avi -> j_125.avi\n",
      "    Renamed: 126.avi -> j_126.avi\n",
      "    Renamed: 127.avi -> j_127.avi\n",
      "    Renamed: 128.avi -> j_128.avi\n",
      "    Renamed: 129.avi -> j_129.avi\n",
      "    Renamed: 13.avi -> j_13.avi\n",
      "    Renamed: 130.avi -> j_130.avi\n",
      "    Renamed: 131.avi -> j_131.avi\n",
      "    Renamed: 132.avi -> j_132.avi\n",
      "    Renamed: 133.avi -> j_133.avi\n",
      "    Renamed: 134.avi -> j_134.avi\n",
      "    Renamed: 135.avi -> j_135.avi\n",
      "    Renamed: 136.avi -> j_136.avi\n",
      "    Renamed: 137.avi -> j_137.avi\n",
      "    Renamed: 138.avi -> j_138.avi\n",
      "    Renamed: 139.avi -> j_139.avi\n",
      "    Renamed: 14.avi -> j_14.avi\n",
      "    Renamed: 140.avi -> j_140.avi\n",
      "    Renamed: 141.avi -> j_141.avi\n",
      "    Renamed: 142.avi -> j_142.avi\n",
      "    Renamed: 143.avi -> j_143.avi\n",
      "    Renamed: 144.avi -> j_144.avi\n",
      "    Renamed: 145.avi -> j_145.avi\n",
      "    Renamed: 146.avi -> j_146.avi\n",
      "    Renamed: 147.avi -> j_147.avi\n",
      "    Renamed: 148.avi -> j_148.avi\n",
      "    Renamed: 149.avi -> j_149.avi\n",
      "    Renamed: 15.avi -> j_15.avi\n",
      "    Renamed: 150.avi -> j_150.avi\n",
      "    Renamed: 151.avi -> j_151.avi\n",
      "    Renamed: 152.avi -> j_152.avi\n",
      "    Renamed: 153.avi -> j_153.avi\n",
      "    Renamed: 154.avi -> j_154.avi\n",
      "    Renamed: 155.avi -> j_155.avi\n",
      "    Renamed: 156.avi -> j_156.avi\n",
      "    Renamed: 157.avi -> j_157.avi\n",
      "    Renamed: 158.avi -> j_158.avi\n",
      "    Renamed: 159.avi -> j_159.avi\n",
      "    Renamed: 16.avi -> j_16.avi\n",
      "    Renamed: 160.avi -> j_160.avi\n",
      "    Renamed: 161.avi -> j_161.avi\n",
      "    Renamed: 162.avi -> j_162.avi\n",
      "    Renamed: 163.avi -> j_163.avi\n",
      "    Renamed: 164.avi -> j_164.avi\n",
      "    Renamed: 165.avi -> j_165.avi\n",
      "    Renamed: 166.avi -> j_166.avi\n",
      "    Renamed: 167.avi -> j_167.avi\n",
      "    Renamed: 168.avi -> j_168.avi\n",
      "    Renamed: 169.avi -> j_169.avi\n",
      "    Renamed: 17.avi -> j_17.avi\n",
      "    Renamed: 170.avi -> j_170.avi\n",
      "    Renamed: 171.avi -> j_171.avi\n",
      "    Renamed: 172.avi -> j_172.avi\n",
      "    Renamed: 173.avi -> j_173.avi\n",
      "    Renamed: 174.avi -> j_174.avi\n",
      "    Renamed: 175.avi -> j_175.avi\n",
      "    Renamed: 176.avi -> j_176.avi\n",
      "    Renamed: 177.avi -> j_177.avi\n",
      "    Renamed: 178.avi -> j_178.avi\n",
      "    Renamed: 179.avi -> j_179.avi\n",
      "    Renamed: 18.avi -> j_18.avi\n",
      "    Renamed: 180.avi -> j_180.avi\n",
      "    Renamed: 181.avi -> j_181.avi\n",
      "    Renamed: 182.avi -> j_182.avi\n",
      "    Renamed: 183.avi -> j_183.avi\n",
      "    Renamed: 184.avi -> j_184.avi\n",
      "    Renamed: 185.avi -> j_185.avi\n",
      "    Renamed: 186.avi -> j_186.avi\n",
      "    Renamed: 187.avi -> j_187.avi\n",
      "    Renamed: 188.avi -> j_188.avi\n",
      "    Renamed: 189.avi -> j_189.avi\n",
      "    Renamed: 19.avi -> j_19.avi\n",
      "    Renamed: 190.avi -> j_190.avi\n",
      "    Renamed: 191.avi -> j_191.avi\n",
      "    Renamed: 192.avi -> j_192.avi\n",
      "    Renamed: 193.avi -> j_193.avi\n",
      "    Renamed: 194.avi -> j_194.avi\n",
      "    Renamed: 195.avi -> j_195.avi\n",
      "    Renamed: 196.avi -> j_196.avi\n",
      "    Renamed: 197.avi -> j_197.avi\n",
      "    Renamed: 198.avi -> j_198.avi\n",
      "    Renamed: 199.avi -> j_199.avi\n",
      "    Renamed: 2.avi -> j_2.avi\n",
      "    Renamed: 20.avi -> j_20.avi\n",
      "    Renamed: 200.avi -> j_200.avi\n",
      "    Renamed: 201.avi -> j_201.avi\n",
      "    Renamed: 202.avi -> j_202.avi\n",
      "    Renamed: 203.avi -> j_203.avi\n",
      "    Renamed: 204.avi -> j_204.avi\n",
      "    Renamed: 205.avi -> j_205.avi\n",
      "    Renamed: 206.avi -> j_206.avi\n",
      "    Renamed: 207.avi -> j_207.avi\n",
      "    Renamed: 208.avi -> j_208.avi\n",
      "    Renamed: 209.avi -> j_209.avi\n",
      "    Renamed: 21.avi -> j_21.avi\n",
      "    Renamed: 210.avi -> j_210.avi\n",
      "    Renamed: 211.avi -> j_211.avi\n",
      "    Renamed: 212.avi -> j_212.avi\n",
      "    Renamed: 213.avi -> j_213.avi\n",
      "    Renamed: 214.avi -> j_214.avi\n",
      "    Renamed: 215.avi -> j_215.avi\n",
      "    Renamed: 216.avi -> j_216.avi\n",
      "    Renamed: 217.avi -> j_217.avi\n",
      "    Renamed: 218.avi -> j_218.avi\n",
      "    Renamed: 219.avi -> j_219.avi\n",
      "    Renamed: 22.avi -> j_22.avi\n",
      "    Renamed: 220.avi -> j_220.avi\n",
      "    Renamed: 221.avi -> j_221.avi\n",
      "    Renamed: 222.avi -> j_222.avi\n",
      "    Renamed: 223.avi -> j_223.avi\n",
      "    Renamed: 224.avi -> j_224.avi\n",
      "    Renamed: 225.avi -> j_225.avi\n",
      "    Renamed: 226.avi -> j_226.avi\n",
      "    Renamed: 227.avi -> j_227.avi\n",
      "    Renamed: 228.avi -> j_228.avi\n",
      "    Renamed: 229.avi -> j_229.avi\n",
      "    Renamed: 23.avi -> j_23.avi\n",
      "    Renamed: 230.avi -> j_230.avi\n",
      "    Renamed: 231.avi -> j_231.avi\n",
      "    Renamed: 232.avi -> j_232.avi\n",
      "    Renamed: 233.avi -> j_233.avi\n",
      "    Renamed: 234.avi -> j_234.avi\n",
      "    Renamed: 235.avi -> j_235.avi\n",
      "    Renamed: 236.avi -> j_236.avi\n",
      "    Renamed: 237.avi -> j_237.avi\n",
      "    Renamed: 238.avi -> j_238.avi\n",
      "    Renamed: 24.avi -> j_24.avi\n",
      "    Renamed: 25.avi -> j_25.avi\n",
      "    Renamed: 26.avi -> j_26.avi\n",
      "    Renamed: 27.avi -> j_27.avi\n",
      "    Renamed: 28.avi -> j_28.avi\n",
      "    Renamed: 29.avi -> j_29.avi\n",
      "    Renamed: 3.avi -> j_3.avi\n",
      "    Renamed: 30.avi -> j_30.avi\n",
      "    Renamed: 31.avi -> j_31.avi\n",
      "    Renamed: 32.avi -> j_32.avi\n",
      "    Renamed: 33.avi -> j_33.avi\n",
      "    Renamed: 34.avi -> j_34.avi\n",
      "    Renamed: 35.avi -> j_35.avi\n",
      "    Renamed: 36.avi -> j_36.avi\n",
      "    Renamed: 37.avi -> j_37.avi\n",
      "    Renamed: 38.avi -> j_38.avi\n",
      "    Renamed: 39.avi -> j_39.avi\n",
      "    Renamed: 4.avi -> j_4.avi\n",
      "    Renamed: 40.avi -> j_40.avi\n",
      "    Renamed: 41.avi -> j_41.avi\n",
      "    Renamed: 42.avi -> j_42.avi\n",
      "    Renamed: 43.avi -> j_43.avi\n",
      "    Renamed: 44.avi -> j_44.avi\n",
      "    Renamed: 45.avi -> j_45.avi\n",
      "    Renamed: 46.avi -> j_46.avi\n",
      "    Renamed: 47.avi -> j_47.avi\n",
      "    Renamed: 48.avi -> j_48.avi\n",
      "    Renamed: 49.avi -> j_49.avi\n",
      "    Renamed: 5.avi -> j_5.avi\n",
      "    Renamed: 50.avi -> j_50.avi\n",
      "    Renamed: 51.avi -> j_51.avi\n",
      "    Renamed: 52.avi -> j_52.avi\n",
      "    Renamed: 53.avi -> j_53.avi\n",
      "    Renamed: 54.avi -> j_54.avi\n",
      "    Renamed: 55.avi -> j_55.avi\n",
      "    Renamed: 56.avi -> j_56.avi\n",
      "    Renamed: 57.avi -> j_57.avi\n",
      "    Renamed: 58.avi -> j_58.avi\n",
      "    Renamed: 59.avi -> j_59.avi\n",
      "    Renamed: 6.avi -> j_6.avi\n",
      "    Renamed: 60.avi -> j_60.avi\n",
      "    Renamed: 61.avi -> j_61.avi\n",
      "    Renamed: 62.avi -> j_62.avi\n",
      "    Renamed: 63.avi -> j_63.avi\n",
      "    Renamed: 64.avi -> j_64.avi\n",
      "    Renamed: 65.avi -> j_65.avi\n",
      "    Renamed: 66.avi -> j_66.avi\n",
      "    Renamed: 67.avi -> j_67.avi\n",
      "    Renamed: 68.avi -> j_68.avi\n",
      "    Renamed: 69.avi -> j_69.avi\n",
      "    Renamed: 7.avi -> j_7.avi\n",
      "    Renamed: 70.avi -> j_70.avi\n",
      "    Renamed: 71.avi -> j_71.avi\n",
      "    Renamed: 72.avi -> j_72.avi\n",
      "    Renamed: 73.avi -> j_73.avi\n",
      "    Renamed: 74.avi -> j_74.avi\n",
      "    Renamed: 75.avi -> j_75.avi\n",
      "    Renamed: 76.avi -> j_76.avi\n",
      "    Renamed: 77.avi -> j_77.avi\n",
      "    Renamed: 78.avi -> j_78.avi\n",
      "    Renamed: 79.avi -> j_79.avi\n",
      "    Renamed: 8.avi -> j_8.avi\n",
      "    Renamed: 80.avi -> j_80.avi\n",
      "    Renamed: 81.avi -> j_81.avi\n",
      "    Renamed: 82.avi -> j_82.avi\n",
      "    Renamed: 83.avi -> j_83.avi\n",
      "    Renamed: 84.avi -> j_84.avi\n",
      "    Renamed: 85.avi -> j_85.avi\n",
      "    Renamed: 86.avi -> j_86.avi\n",
      "    Renamed: 87.avi -> j_87.avi\n",
      "    Renamed: 88.avi -> j_88.avi\n",
      "    Renamed: 89.avi -> j_89.avi\n",
      "    Renamed: 9.avi -> j_9.avi\n",
      "    Renamed: 90.avi -> j_90.avi\n",
      "    Renamed: 91.avi -> j_91.avi\n",
      "    Renamed: 92.avi -> j_92.avi\n",
      "    Renamed: 93.avi -> j_93.avi\n",
      "    Renamed: 94.avi -> j_94.avi\n",
      "    Renamed: 95.avi -> j_95.avi\n",
      "    Renamed: 96.avi -> j_96.avi\n",
      "    Renamed: 97.avi -> j_97.avi\n",
      "    Renamed: 98.avi -> j_98.avi\n",
      "    Renamed: 99.avi -> j_99.avi\n",
      "   --> Done. 238 files renamed.\n",
      "\n",
      " Processing folder: /z\n",
      "    Renamed: 1.avi -> z_1.avi\n",
      "    Renamed: 10.avi -> z_10.avi\n",
      "    Renamed: 100.avi -> z_100.avi\n",
      "    Renamed: 101.avi -> z_101.avi\n",
      "    Renamed: 102.avi -> z_102.avi\n",
      "    Renamed: 103.avi -> z_103.avi\n",
      "    Renamed: 104.avi -> z_104.avi\n",
      "    Renamed: 105.avi -> z_105.avi\n",
      "    Renamed: 106.avi -> z_106.avi\n",
      "    Renamed: 107.avi -> z_107.avi\n",
      "    Renamed: 108.avi -> z_108.avi\n",
      "    Renamed: 109.avi -> z_109.avi\n",
      "    Renamed: 11.avi -> z_11.avi\n",
      "    Renamed: 110.avi -> z_110.avi\n",
      "    Renamed: 111.avi -> z_111.avi\n",
      "    Renamed: 112.avi -> z_112.avi\n",
      "    Renamed: 113.avi -> z_113.avi\n",
      "    Renamed: 114.avi -> z_114.avi\n",
      "    Renamed: 115.avi -> z_115.avi\n",
      "    Renamed: 116.avi -> z_116.avi\n",
      "    Renamed: 117.avi -> z_117.avi\n",
      "    Renamed: 118.avi -> z_118.avi\n",
      "    Renamed: 119.avi -> z_119.avi\n",
      "    Renamed: 12.avi -> z_12.avi\n",
      "    Renamed: 120.avi -> z_120.avi\n",
      "    Renamed: 121.avi -> z_121.avi\n",
      "    Renamed: 122.avi -> z_122.avi\n",
      "    Renamed: 123.avi -> z_123.avi\n",
      "    Renamed: 124.avi -> z_124.avi\n",
      "    Renamed: 125.avi -> z_125.avi\n",
      "    Renamed: 126.avi -> z_126.avi\n",
      "    Renamed: 127.avi -> z_127.avi\n",
      "    Renamed: 128.avi -> z_128.avi\n",
      "    Renamed: 129.avi -> z_129.avi\n",
      "    Renamed: 13.avi -> z_13.avi\n",
      "    Renamed: 130.avi -> z_130.avi\n",
      "    Renamed: 131.avi -> z_131.avi\n",
      "    Renamed: 132.avi -> z_132.avi\n",
      "    Renamed: 133.avi -> z_133.avi\n",
      "    Renamed: 134.avi -> z_134.avi\n",
      "    Renamed: 135.avi -> z_135.avi\n",
      "    Renamed: 136.avi -> z_136.avi\n",
      "    Renamed: 137.avi -> z_137.avi\n",
      "    Renamed: 138.avi -> z_138.avi\n",
      "    Renamed: 139.avi -> z_139.avi\n",
      "    Renamed: 14.avi -> z_14.avi\n",
      "    Renamed: 140.avi -> z_140.avi\n",
      "    Renamed: 141.avi -> z_141.avi\n",
      "    Renamed: 142.avi -> z_142.avi\n",
      "    Renamed: 143.avi -> z_143.avi\n",
      "    Renamed: 144.avi -> z_144.avi\n",
      "    Renamed: 145.avi -> z_145.avi\n",
      "    Renamed: 146.avi -> z_146.avi\n",
      "    Renamed: 147.avi -> z_147.avi\n",
      "    Renamed: 148.avi -> z_148.avi\n",
      "    Renamed: 149.avi -> z_149.avi\n",
      "    Renamed: 15.avi -> z_15.avi\n",
      "    Renamed: 150.avi -> z_150.avi\n",
      "    Renamed: 151.avi -> z_151.avi\n",
      "    Renamed: 152.avi -> z_152.avi\n",
      "    Renamed: 153.avi -> z_153.avi\n",
      "    Renamed: 154.avi -> z_154.avi\n",
      "    Renamed: 155.avi -> z_155.avi\n",
      "    Renamed: 156.avi -> z_156.avi\n",
      "    Renamed: 157.avi -> z_157.avi\n",
      "    Renamed: 158.avi -> z_158.avi\n",
      "    Renamed: 159.avi -> z_159.avi\n",
      "    Renamed: 16.avi -> z_16.avi\n",
      "    Renamed: 160.avi -> z_160.avi\n",
      "    Renamed: 161.avi -> z_161.avi\n",
      "    Renamed: 162.avi -> z_162.avi\n",
      "    Renamed: 163.avi -> z_163.avi\n",
      "    Renamed: 164.avi -> z_164.avi\n",
      "    Renamed: 165.avi -> z_165.avi\n",
      "    Renamed: 166.avi -> z_166.avi\n",
      "    Renamed: 167.avi -> z_167.avi\n",
      "    Renamed: 168.avi -> z_168.avi\n",
      "    Renamed: 169.avi -> z_169.avi\n",
      "    Renamed: 17.avi -> z_17.avi\n",
      "    Renamed: 170.avi -> z_170.avi\n",
      "    Renamed: 171.avi -> z_171.avi\n",
      "    Renamed: 172.avi -> z_172.avi\n",
      "    Renamed: 173.avi -> z_173.avi\n",
      "    Renamed: 174.avi -> z_174.avi\n",
      "    Renamed: 175.avi -> z_175.avi\n",
      "    Renamed: 176.avi -> z_176.avi\n",
      "    Renamed: 177.avi -> z_177.avi\n",
      "    Renamed: 178.avi -> z_178.avi\n",
      "    Renamed: 179.avi -> z_179.avi\n",
      "    Renamed: 18.avi -> z_18.avi\n",
      "    Renamed: 180.avi -> z_180.avi\n",
      "    Renamed: 181.avi -> z_181.avi\n",
      "    Renamed: 182.avi -> z_182.avi\n",
      "    Renamed: 183.avi -> z_183.avi\n",
      "    Renamed: 184.avi -> z_184.avi\n",
      "    Renamed: 185.avi -> z_185.avi\n",
      "    Renamed: 186.avi -> z_186.avi\n",
      "    Renamed: 187.avi -> z_187.avi\n",
      "    Renamed: 188.avi -> z_188.avi\n",
      "    Renamed: 189.avi -> z_189.avi\n",
      "    Renamed: 19.avi -> z_19.avi\n",
      "    Renamed: 190.avi -> z_190.avi\n",
      "    Renamed: 191.avi -> z_191.avi\n",
      "    Renamed: 192.avi -> z_192.avi\n",
      "    Renamed: 193.avi -> z_193.avi\n",
      "    Renamed: 194.avi -> z_194.avi\n",
      "    Renamed: 195.avi -> z_195.avi\n",
      "    Renamed: 196.avi -> z_196.avi\n",
      "    Renamed: 197.avi -> z_197.avi\n",
      "    Renamed: 198.avi -> z_198.avi\n",
      "    Renamed: 199.avi -> z_199.avi\n",
      "    Renamed: 2.avi -> z_2.avi\n",
      "    Renamed: 20.avi -> z_20.avi\n",
      "    Renamed: 200.avi -> z_200.avi\n",
      "    Renamed: 201.avi -> z_201.avi\n",
      "    Renamed: 202.avi -> z_202.avi\n",
      "    Renamed: 203.avi -> z_203.avi\n",
      "    Renamed: 204.avi -> z_204.avi\n",
      "    Renamed: 205.avi -> z_205.avi\n",
      "    Renamed: 206.avi -> z_206.avi\n",
      "    Renamed: 207.avi -> z_207.avi\n",
      "    Renamed: 208.avi -> z_208.avi\n",
      "    Renamed: 209.avi -> z_209.avi\n",
      "    Renamed: 21.avi -> z_21.avi\n",
      "    Renamed: 210.avi -> z_210.avi\n",
      "    Renamed: 211.avi -> z_211.avi\n",
      "    Renamed: 212.avi -> z_212.avi\n",
      "    Renamed: 213.avi -> z_213.avi\n",
      "    Renamed: 214.avi -> z_214.avi\n",
      "    Renamed: 215.avi -> z_215.avi\n",
      "    Renamed: 216.avi -> z_216.avi\n",
      "    Renamed: 217.avi -> z_217.avi\n",
      "    Renamed: 218.avi -> z_218.avi\n",
      "    Renamed: 219.avi -> z_219.avi\n",
      "    Renamed: 22.avi -> z_22.avi\n",
      "    Renamed: 220.avi -> z_220.avi\n",
      "    Renamed: 221.avi -> z_221.avi\n",
      "    Renamed: 222.avi -> z_222.avi\n",
      "    Renamed: 223.avi -> z_223.avi\n",
      "    Renamed: 224.avi -> z_224.avi\n",
      "    Renamed: 225.avi -> z_225.avi\n",
      "    Renamed: 226.avi -> z_226.avi\n",
      "    Renamed: 227.avi -> z_227.avi\n",
      "    Renamed: 228.avi -> z_228.avi\n",
      "    Renamed: 229.avi -> z_229.avi\n",
      "    Renamed: 23.avi -> z_23.avi\n",
      "    Renamed: 230.avi -> z_230.avi\n",
      "    Renamed: 231.avi -> z_231.avi\n",
      "    Renamed: 232.avi -> z_232.avi\n",
      "    Renamed: 233.avi -> z_233.avi\n",
      "    Renamed: 234.avi -> z_234.avi\n",
      "    Renamed: 235.avi -> z_235.avi\n",
      "    Renamed: 236.avi -> z_236.avi\n",
      "    Renamed: 237.avi -> z_237.avi\n",
      "    Renamed: 238.avi -> z_238.avi\n",
      "    Renamed: 239.avi -> z_239.avi\n",
      "    Renamed: 24.avi -> z_24.avi\n",
      "    Renamed: 240.avi -> z_240.avi\n",
      "    Renamed: 241.avi -> z_241.avi\n",
      "    Renamed: 242.avi -> z_242.avi\n",
      "    Renamed: 243.avi -> z_243.avi\n",
      "    Renamed: 244.avi -> z_244.avi\n",
      "    Renamed: 245.avi -> z_245.avi\n",
      "    Renamed: 246.avi -> z_246.avi\n",
      "    Renamed: 247.avi -> z_247.avi\n",
      "    Renamed: 248.avi -> z_248.avi\n",
      "    Renamed: 249.avi -> z_249.avi\n",
      "    Renamed: 25.avi -> z_25.avi\n",
      "    Renamed: 250.avi -> z_250.avi\n",
      "    Renamed: 251.avi -> z_251.avi\n",
      "    Renamed: 252.avi -> z_252.avi\n",
      "    Renamed: 253.avi -> z_253.avi\n",
      "    Renamed: 254.avi -> z_254.avi\n",
      "    Renamed: 255.avi -> z_255.avi\n",
      "    Renamed: 256.avi -> z_256.avi\n",
      "    Renamed: 257.avi -> z_257.avi\n",
      "    Renamed: 258.avi -> z_258.avi\n",
      "    Renamed: 259.avi -> z_259.avi\n",
      "    Renamed: 26.avi -> z_26.avi\n",
      "    Renamed: 260.avi -> z_260.avi\n",
      "    Renamed: 261.avi -> z_261.avi\n",
      "    Renamed: 262.avi -> z_262.avi\n",
      "    Renamed: 263.avi -> z_263.avi\n",
      "    Renamed: 264.avi -> z_264.avi\n",
      "    Renamed: 265.avi -> z_265.avi\n",
      "    Renamed: 266.avi -> z_266.avi\n",
      "    Renamed: 267.avi -> z_267.avi\n",
      "    Renamed: 268.avi -> z_268.avi\n",
      "    Renamed: 269.avi -> z_269.avi\n",
      "    Renamed: 27.avi -> z_27.avi\n",
      "    Renamed: 270.avi -> z_270.avi\n",
      "    Renamed: 271.avi -> z_271.avi\n",
      "    Renamed: 272.avi -> z_272.avi\n",
      "    Renamed: 273.avi -> z_273.avi\n",
      "    Renamed: 274.avi -> z_274.avi\n",
      "    Renamed: 275.avi -> z_275.avi\n",
      "    Renamed: 276.avi -> z_276.avi\n",
      "    Renamed: 277.avi -> z_277.avi\n",
      "    Renamed: 278.avi -> z_278.avi\n",
      "    Renamed: 279.avi -> z_279.avi\n",
      "    Renamed: 28.avi -> z_28.avi\n",
      "    Renamed: 280.avi -> z_280.avi\n",
      "    Renamed: 281.avi -> z_281.avi\n",
      "    Renamed: 282.avi -> z_282.avi\n",
      "    Renamed: 283.avi -> z_283.avi\n",
      "    Renamed: 284.avi -> z_284.avi\n",
      "    Renamed: 285.avi -> z_285.avi\n",
      "    Renamed: 286.avi -> z_286.avi\n",
      "    Renamed: 287.avi -> z_287.avi\n",
      "    Renamed: 288.avi -> z_288.avi\n",
      "    Renamed: 289.avi -> z_289.avi\n",
      "    Renamed: 29.avi -> z_29.avi\n",
      "    Renamed: 290.avi -> z_290.avi\n",
      "    Renamed: 291.avi -> z_291.avi\n",
      "    Renamed: 292.avi -> z_292.avi\n",
      "    Renamed: 293.avi -> z_293.avi\n",
      "    Renamed: 294.avi -> z_294.avi\n",
      "    Renamed: 295.avi -> z_295.avi\n",
      "    Renamed: 296.avi -> z_296.avi\n",
      "    Renamed: 297.avi -> z_297.avi\n",
      "    Renamed: 298.avi -> z_298.avi\n",
      "    Renamed: 299.avi -> z_299.avi\n",
      "    Renamed: 3.avi -> z_3.avi\n",
      "    Renamed: 30.avi -> z_30.avi\n",
      "    Renamed: 300.avi -> z_300.avi\n",
      "    Renamed: 301.avi -> z_301.avi\n",
      "    Renamed: 302.avi -> z_302.avi\n",
      "    Renamed: 303.avi -> z_303.avi\n",
      "    Renamed: 304.avi -> z_304.avi\n",
      "    Renamed: 305.avi -> z_305.avi\n",
      "    Renamed: 306.avi -> z_306.avi\n",
      "    Renamed: 307.avi -> z_307.avi\n",
      "    Renamed: 308.avi -> z_308.avi\n",
      "    Renamed: 309.avi -> z_309.avi\n",
      "    Renamed: 31.avi -> z_31.avi\n",
      "    Renamed: 310.avi -> z_310.avi\n",
      "    Renamed: 311.avi -> z_311.avi\n",
      "    Renamed: 32.avi -> z_32.avi\n",
      "    Renamed: 33.avi -> z_33.avi\n",
      "    Renamed: 34.avi -> z_34.avi\n",
      "    Renamed: 35.avi -> z_35.avi\n",
      "    Renamed: 36.avi -> z_36.avi\n",
      "    Renamed: 37.avi -> z_37.avi\n",
      "    Renamed: 38.avi -> z_38.avi\n",
      "    Renamed: 39.avi -> z_39.avi\n",
      "    Renamed: 4.avi -> z_4.avi\n",
      "    Renamed: 40.avi -> z_40.avi\n",
      "    Renamed: 41.avi -> z_41.avi\n",
      "    Renamed: 42.avi -> z_42.avi\n",
      "    Renamed: 43.avi -> z_43.avi\n",
      "    Renamed: 44.avi -> z_44.avi\n",
      "    Renamed: 45.avi -> z_45.avi\n",
      "    Renamed: 46.avi -> z_46.avi\n",
      "    Renamed: 47.avi -> z_47.avi\n",
      "    Renamed: 48.avi -> z_48.avi\n",
      "    Renamed: 49.avi -> z_49.avi\n",
      "    Renamed: 5.avi -> z_5.avi\n",
      "    Renamed: 50.avi -> z_50.avi\n",
      "    Renamed: 51.avi -> z_51.avi\n",
      "    Renamed: 52.avi -> z_52.avi\n",
      "    Renamed: 53.avi -> z_53.avi\n",
      "    Renamed: 54.avi -> z_54.avi\n",
      "    Renamed: 55.avi -> z_55.avi\n",
      "    Renamed: 56.avi -> z_56.avi\n",
      "    Renamed: 57.avi -> z_57.avi\n",
      "    Renamed: 58.avi -> z_58.avi\n",
      "    Renamed: 59.avi -> z_59.avi\n",
      "    Renamed: 6.avi -> z_6.avi\n",
      "    Renamed: 60.avi -> z_60.avi\n",
      "    Renamed: 61.avi -> z_61.avi\n",
      "    Renamed: 62.avi -> z_62.avi\n",
      "    Renamed: 63.avi -> z_63.avi\n",
      "    Renamed: 64.avi -> z_64.avi\n",
      "    Renamed: 65.avi -> z_65.avi\n",
      "    Renamed: 66.avi -> z_66.avi\n",
      "    Renamed: 67.avi -> z_67.avi\n",
      "    Renamed: 68.avi -> z_68.avi\n",
      "    Renamed: 69.avi -> z_69.avi\n",
      "    Renamed: 7.avi -> z_7.avi\n",
      "    Renamed: 70.avi -> z_70.avi\n",
      "    Renamed: 71.avi -> z_71.avi\n",
      "    Renamed: 72.avi -> z_72.avi\n",
      "    Renamed: 73.avi -> z_73.avi\n",
      "    Renamed: 74.avi -> z_74.avi\n",
      "    Renamed: 75.avi -> z_75.avi\n",
      "    Renamed: 76.avi -> z_76.avi\n",
      "    Renamed: 77.avi -> z_77.avi\n",
      "    Renamed: 78.avi -> z_78.avi\n",
      "    Renamed: 79.avi -> z_79.avi\n",
      "    Renamed: 8.avi -> z_8.avi\n",
      "    Renamed: 80.avi -> z_80.avi\n",
      "    Renamed: 81.avi -> z_81.avi\n",
      "    Renamed: 82.avi -> z_82.avi\n",
      "    Renamed: 83.avi -> z_83.avi\n",
      "    Renamed: 84.avi -> z_84.avi\n",
      "    Renamed: 85.avi -> z_85.avi\n",
      "    Renamed: 86.avi -> z_86.avi\n",
      "    Renamed: 87.avi -> z_87.avi\n",
      "    Renamed: 88.avi -> z_88.avi\n",
      "    Renamed: 89.avi -> z_89.avi\n",
      "    Renamed: 9.avi -> z_9.avi\n",
      "    Renamed: 90.avi -> z_90.avi\n",
      "    Renamed: 91.avi -> z_91.avi\n",
      "    Renamed: 92.avi -> z_92.avi\n",
      "    Renamed: 93.avi -> z_93.avi\n",
      "    Renamed: 94.avi -> z_94.avi\n",
      "    Renamed: 95.avi -> z_95.avi\n",
      "    Renamed: 96.avi -> z_96.avi\n",
      "    Renamed: 97.avi -> z_97.avi\n",
      "    Renamed: 98.avi -> z_98.avi\n",
      "    Renamed: 99.avi -> z_99.avi\n",
      "   --> Done. 311 files renamed.\n",
      "\n",
      "All tasks completed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 1. Define where the videos are relative to this notebook\n",
    "base_folder = \"videos_msasl\"\n",
    "\n",
    "# 2. Define the subfolders and what prefix to add to each\n",
    "target_map = {\n",
    "    'j': 'j_',\n",
    "    'z': 'z_'\n",
    "}\n",
    "\n",
    "# Video extensions to look for\n",
    "video_extensions = ('.mp4', '.mkv', '.avi', '.mov', '.flv', '.wmv')\n",
    "\n",
    "# In Jupyter, os.getcwd() is the folder where this .ipynb file is located\n",
    "current_directory = os.getcwd()\n",
    "full_base_path = os.path.join(current_directory, base_folder)\n",
    "\n",
    "# Check if the main folder exists first\n",
    "if not os.path.exists(full_base_path):\n",
    "    print(f\" Error: Could not find the folder '{base_folder}' in this directory.\")\n",
    "    print(f\"Current directory is: {current_directory}\")\n",
    "else:\n",
    "    print(f\"Scanning in: {full_base_path}\\n\")\n",
    "\n",
    "    # Loop through the specific folders defined in target_map\n",
    "    for subfolder, prefix in target_map.items():\n",
    "        \n",
    "        folder_path = os.path.join(full_base_path, subfolder)\n",
    "        \n",
    "        if os.path.exists(folder_path):\n",
    "            print(f\" Processing folder: /{subfolder}\")\n",
    "            count = 0\n",
    "            \n",
    "            for filename in os.listdir(folder_path):\n",
    "                if filename.lower().endswith(video_extensions):\n",
    "                    \n",
    "                    # Avoid double renaming\n",
    "                    if not filename.startswith(prefix):\n",
    "                        old_file_path = os.path.join(folder_path, filename)\n",
    "                        new_filename = f\"{prefix}{filename}\"\n",
    "                        new_file_path = os.path.join(folder_path, new_filename)\n",
    "                        \n",
    "                        try:\n",
    "                            os.rename(old_file_path, new_file_path)\n",
    "                            print(f\"    Renamed: {filename} -> {new_filename}\")\n",
    "                            count += 1\n",
    "                        except Exception as e:\n",
    "                            print(f\"    Error renaming {filename}: {e}\")\n",
    "            \n",
    "            print(f\"   --> Done. {count} files renamed.\\n\")\n",
    "        else:\n",
    "            print(f\" Warning: Folder not found: {base_folder}/{subfolder}\")\n",
    "\n",
    "    print(\"All tasks completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f6983ac-9c32-45dc-b5d4-a7d8470a7807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MediaPipe Version: 0.10.21\n",
      "TensorFlow Version: 2.19.1\n",
      "Keras Version: 3.13.0\n"
     ]
    }
   ],
   "source": [
    "import mediapipe as mp\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "print(f\"MediaPipe Version: {mp.__version__}\")\n",
    "print(f\"TensorFlow Version: {tf.__version__}\")\n",
    "print(f\"Keras Version: {keras.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2dfd8e1b-802a-48ef-9260-415dc352ec8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading asl_alphabet_model.h5...\n",
      "Labels loaded: 24\n",
      "\n",
      "--- SYSTEM READY ---\n",
      "Press Q to Quit | C to Clear | B to Backspace\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import os\n",
    "import time\n",
    "from collections import deque\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "MODEL_PATH = \"asl_alphabet_model.h5\"  # Or .keras if you retrained\n",
    "LABEL_PATH = \"alphabet_labels.npy\"\n",
    "\n",
    "# --- 1. FEATURE EXTRACTOR (80 Features) ---\n",
    "def extract_features(kp_flat):\n",
    "    # Reshape (21 points, 3 dims)\n",
    "    landmarks = kp_flat.reshape(21, 3)\n",
    "    \n",
    "    # Normalize to Wrist\n",
    "    wrist = landmarks[0]\n",
    "    landmarks = landmarks - wrist\n",
    "    \n",
    "    # Scale Normalization\n",
    "    scale = np.linalg.norm(landmarks[12]) + 1e-6\n",
    "    landmarks = landmarks / scale\n",
    "    \n",
    "    flat_coords = landmarks.flatten() # 63 features\n",
    "    \n",
    "    # Distances\n",
    "    dists = []\n",
    "    tips = [4, 8, 12, 16, 20]\n",
    "    for i in range(1, 5): dists.append(np.linalg.norm(landmarks[tips[0]] - landmarks[tips[i]]))\n",
    "    for i in range(4): dists.append(np.linalg.norm(landmarks[tips[i]] - landmarks[tips[i+1]]))\n",
    "    for i in range(5): dists.append(np.linalg.norm(landmarks[tips[i]]))\n",
    "    \n",
    "    # Angles\n",
    "    angles = []\n",
    "    bases = [2, 5, 9, 13, 17]\n",
    "    vecs = [landmarks[tips[i]] - landmarks[bases[i]] for i in range(5)]\n",
    "    for i in range(4):\n",
    "        v1, v2 = vecs[i], vecs[i+1]\n",
    "        c = np.dot(v1, v2)/(np.linalg.norm(v1)*np.linalg.norm(v2)+1e-6)\n",
    "        angles.append(np.arccos(np.clip(c, -1, 1)))\n",
    "        \n",
    "    return np.concatenate([flat_coords, np.array(dists), np.array(angles)])\n",
    "\n",
    "# --- 2. LOAD MODEL ---\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    print(f\"CRITICAL ERROR: Model file '{MODEL_PATH}' not found.\")\n",
    "    print(\"Did you retrain and save the model?\")\n",
    "    exit()\n",
    "\n",
    "print(f\"Loading {MODEL_PATH}...\")\n",
    "try:\n",
    "    # Try generic load first\n",
    "    model = tf.keras.models.load_model(MODEL_PATH)\n",
    "except:\n",
    "    print(\"TF Load failed, trying Keras 3 native load...\")\n",
    "    try:\n",
    "        model = keras.saving.load_model(MODEL_PATH)\n",
    "    except Exception as e:\n",
    "        print(f\"FAILED to load model: {e}\")\n",
    "        exit()\n",
    "\n",
    "try:\n",
    "    labels = np.load(LABEL_PATH)\n",
    "    print(f\"Labels loaded: {len(labels)}\")\n",
    "except:\n",
    "    print(\"Labels missing, using default A-Z.\")\n",
    "    labels = np.array(list(\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"))\n",
    "\n",
    "# --- 3. SETUP MEDIAPIPE ---\n",
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "holistic = mp_holistic.Holistic(\n",
    "    static_image_mode=False,\n",
    "    model_complexity=1,\n",
    "    min_detection_confidence=0.7,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "buffer = deque(maxlen=5)\n",
    "last_time = 0\n",
    "word = \"\"\n",
    "\n",
    "print(\"\\n--- SYSTEM READY ---\")\n",
    "print(\"Press Q to Quit | C to Clear | B to Backspace\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret: break\n",
    "    \n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    res = holistic.process(rgb)\n",
    "    \n",
    "    kp_flat = None\n",
    "    \n",
    "    # Draw & Extract\n",
    "    if res.right_hand_landmarks:\n",
    "        mp_drawing.draw_landmarks(frame, res.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "        kp = np.array([[lm.x, lm.y, lm.z] for lm in res.right_hand_landmarks.landmark])\n",
    "        kp_flat = kp.flatten()\n",
    "        \n",
    "    elif res.left_hand_landmarks:\n",
    "        mp_drawing.draw_landmarks(frame, res.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "        kp = np.array([[lm.x, lm.y, lm.z] for lm in res.left_hand_landmarks.landmark])\n",
    "        kp[:, 0] = -kp[:, 0] # Mirror\n",
    "        kp_flat = kp.flatten()\n",
    "    else:\n",
    "        buffer.append((None, 0.0))\n",
    "\n",
    "    txt = \"Waiting...\"\n",
    "    \n",
    "    if kp_flat is not None:\n",
    "        # Predict\n",
    "        feats = extract_features(kp_flat)\n",
    "        \n",
    "        # Keras 3 / TF 2.20 prediction call\n",
    "        preds = model.predict(feats[np.newaxis], verbose=0)[0]\n",
    "        idx = np.argmax(preds)\n",
    "        prob = np.max(preds)\n",
    "        \n",
    "        buffer.append((idx, prob))\n",
    "        txt = f\"Scan: {labels[idx]} ({prob:.2f})\"\n",
    "\n",
    "    # Confirm Logic\n",
    "    if time.time() - last_time > 1.5:\n",
    "        valid = [x for x in buffer if x[0] is not None]\n",
    "        if len(valid) >= 4:\n",
    "            indices = [x[0] for x in valid]\n",
    "            candidate = max(set(indices), key=indices.count)\n",
    "            avg = np.mean([x[1] for x in valid if x[0] == candidate])\n",
    "            \n",
    "            if avg > 0.85:\n",
    "                l = str(labels[candidate])\n",
    "                if l == \"space\": word += \" \"\n",
    "                elif l == \"del\": word = word[:-1]\n",
    "                elif l == \"nothing\": pass\n",
    "                else: word += l\n",
    "                last_time = time.time()\n",
    "                buffer.clear()\n",
    "                cv2.rectangle(frame, (0,0), (640,480), (0,255,0), 5)\n",
    "\n",
    "    # UI\n",
    "    cv2.putText(frame, txt, (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)\n",
    "    cv2.putText(frame, word, (20, 450), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
    "    \n",
    "    cv2.imshow(\"ASL Pro (Friend's Stack)\", frame)\n",
    "    \n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'): break\n",
    "    elif key == ord('b'): word = word[:-1]\n",
    "    elif key == ord('c'): word = \"\"\n",
    "\n",
    "cap.release()\n",
    "holistic.close()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ea946a3-42cf-4083-97f7-0b29b2b100c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n",
      "Starting video loop...\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "MODEL_PATH = \"word_model.h5\"\n",
    "SEQ_LEN = 30\n",
    "NUM_LANDMARKS = 75\n",
    "THRESHOLD = 0.85\n",
    "STABILITY_FRAMES = 5\n",
    "last_valid_left = [0.0] * 63\n",
    "last_valid_right = [0.0] * 63\n",
    "\n",
    "TARGET_GLOSSES = [\n",
    "    \"me\", \"you\", \"we\", \"they\", \"she\",\n",
    "    \"who\", \"what\", \"yes\", \"no\", \"fine\", \"help\", \"meet\", \"good\",\n",
    "    \"want\", \"have\", \"like\", \"need\", \"go\", \"walk\", \n",
    "    \"play\", \"work\", \"learn\", \"eat\", \"drink\", \"finish\",\n",
    "    \"book\", \"family\", \"school\", \"computer\", \"deaf\"\n",
    "]\n",
    "\n",
    "# --- LOAD RESOURCES ---\n",
    "try:\n",
    "    model = tf.keras.models.load_model(MODEL_PATH)\n",
    "    print(\"Model loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")\n",
    "    exit()\n",
    "\n",
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils \n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "\n",
    "# --- HELPER FUNCTIONS ---\n",
    "def extract_landmarks_smart(results):\n",
    "    global last_valid_left, last_valid_right\n",
    "    vec = []\n",
    "    \n",
    "    # Pose (Always keep fresh)\n",
    "    if results.pose_landmarks:\n",
    "        for lm in results.pose_landmarks.landmark:\n",
    "            vec.extend([lm.x, lm.y, lm.z])\n",
    "    else:\n",
    "        vec.extend([0.0] * 99)\n",
    "        \n",
    "    # --- LEFT HAND (With Memory) ---\n",
    "    if results.left_hand_landmarks:\n",
    "        temp = []\n",
    "        for lm in results.left_hand_landmarks.landmark:\n",
    "            temp.extend([lm.x, lm.y, lm.z])\n",
    "        vec.extend(temp)\n",
    "        last_valid_left = temp # Update memory\n",
    "    else:\n",
    "        # If missing, use the memory (Ghost Hand)\n",
    "        vec.extend(last_valid_left)\n",
    "\n",
    "    # --- RIGHT HAND (With Memory) ---\n",
    "    if results.right_hand_landmarks:\n",
    "        temp = []\n",
    "        for lm in results.right_hand_landmarks.landmark:\n",
    "            temp.extend([lm.x, lm.y, lm.z])\n",
    "        vec.extend(temp)\n",
    "        last_valid_right = temp # Update memory\n",
    "    else:\n",
    "        vec.extend(last_valid_right)\n",
    "        \n",
    "    return vec\n",
    "\n",
    "def pre_process_landmarks(data):\n",
    "    df = pd.DataFrame(data)\n",
    "    df = df.replace(0.0, np.nan)\n",
    "    df = df.interpolate(method='linear', axis=0, limit_direction='both')\n",
    "    df = df.fillna(0.0)\n",
    "    data = df.values.astype(np.float32)\n",
    "    frames = data.reshape(-1, NUM_LANDMARKS, 3)\n",
    "    for i in range(frames.shape[0]):\n",
    "        frame = frames[i]\n",
    "        left = frame[11]\n",
    "        right = frame[12]\n",
    "        center = (left + right) / 2.0\n",
    "        width = np.linalg.norm(left - right) + 1e-6\n",
    "        frame = (frame - center) / (width / 2.0)\n",
    "        frames[i] = frame\n",
    "    return frames.reshape(-1, NUM_LANDMARKS * 3)\n",
    "\n",
    "def resize_sequence(sequence):\n",
    "    norm_seq = pre_process_landmarks(sequence)\n",
    "    res = np.zeros((SEQ_LEN, norm_seq.shape[1]))\n",
    "    for j in range(norm_seq.shape[1]):\n",
    "        res[:, j] = np.interp(\n",
    "            np.linspace(0, len(norm_seq)-1, SEQ_LEN),\n",
    "            np.arange(len(norm_seq)),\n",
    "            norm_seq[:, j]\n",
    "        )\n",
    "    return res\n",
    "\n",
    "# --- MAIN LOOP ---\n",
    "cap = cv2.VideoCapture(0)\n",
    "sequence_buffer = []\n",
    "prediction_history = []\n",
    "current_word = \"\"\n",
    "sentence = []\n",
    "\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    print(\"Starting video loop...\")\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret: \n",
    "            print(\"Ignoring empty camera frame.\")\n",
    "            continue\n",
    "        \n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = holistic.process(image)\n",
    "        \n",
    "        # --- DRAWING THE SKELETON ---\n",
    "        # Draw Pose (Body)\n",
    "        mp_drawing.draw_landmarks(\n",
    "            frame, \n",
    "            results.pose_landmarks, \n",
    "            mp_holistic.POSE_CONNECTIONS,\n",
    "            landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style()\n",
    "        )\n",
    "        \n",
    "        # Draw Left Hand\n",
    "        mp_drawing.draw_landmarks(\n",
    "            frame, \n",
    "            results.left_hand_landmarks, \n",
    "            mp_holistic.HAND_CONNECTIONS,\n",
    "            # Custom Style: Green dots for hands\n",
    "            mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2),\n",
    "            mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2)\n",
    "        )\n",
    "        \n",
    "        # Draw Right Hand\n",
    "        mp_drawing.draw_landmarks(\n",
    "            frame, \n",
    "            results.right_hand_landmarks, \n",
    "            mp_holistic.HAND_CONNECTIONS,\n",
    "            mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2),\n",
    "            mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2)\n",
    "        )\n",
    "\n",
    "        # --- LOGIC ---\n",
    "        hands_visible = (results.left_hand_landmarks is not None) or (results.right_hand_landmarks is not None)\n",
    "        \n",
    "        if not hands_visible:\n",
    "            sequence_buffer = [] \n",
    "            prediction_history = []\n",
    "            display_msg = \"Waiting for hands...\"\n",
    "            status_color = (0, 0, 255) # Red\n",
    "        else:\n",
    "            display_msg = \"Tracking...\"\n",
    "            status_color = (0, 255, 0) # Green\n",
    "            \n",
    "            # --- FIX IS HERE: Use the correct function name ---\n",
    "            landmarks = extract_landmarks_smart(results) \n",
    "            \n",
    "            sequence_buffer.append(landmarks)\n",
    "            if len(sequence_buffer) > 45: sequence_buffer.pop(0)\n",
    "                \n",
    "            if len(sequence_buffer) >= 30:\n",
    "                input_data = resize_sequence(np.array(sequence_buffer))\n",
    "                input_data = np.expand_dims(input_data, axis=0)\n",
    "                \n",
    "                res = model.predict(input_data, verbose=0)\n",
    "                conf = np.max(res)\n",
    "                idx = np.argmax(res)\n",
    "                \n",
    "                if conf > THRESHOLD:\n",
    "                    candidate = TARGET_GLOSSES[idx]\n",
    "                    prediction_history.append(candidate)\n",
    "                    if len(prediction_history) > STABILITY_FRAMES:\n",
    "                        prediction_history = prediction_history[-STABILITY_FRAMES:]\n",
    "                    \n",
    "                    if len(prediction_history) == STABILITY_FRAMES:\n",
    "                        if len(set(prediction_history)) == 1:\n",
    "                            stable_word = prediction_history[0]\n",
    "                            if stable_word != current_word:\n",
    "                                current_word = stable_word\n",
    "                                sentence.append(current_word)\n",
    "                                if len(sentence) > 5: sentence = sentence[-5:]\n",
    "                else:\n",
    "                    prediction_history.append(\"...\")\n",
    "\n",
    "        # --- UI OVERLAY ---\n",
    "        cv2.rectangle(frame, (0, 0), (640, 80), (245, 117, 16), -1)\n",
    "        cv2.putText(frame, f\"STATUS: {display_msg}\", (400, 30), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, status_color, 1)\n",
    "        cv2.putText(frame, f\"WORD: {current_word}\", (10, 30), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "        cv2.putText(frame, f\"SEN: {' '.join(sentence)}\", (10, 70), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)\n",
    "\n",
    "        cv2.imshow('TalkSign Live Test', frame)\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1e5c4e9-975f-4663-8a7f-d2e56610f053",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models...\n",
      "Word Model loaded: best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alphabet Model loaded: asl_alphabet_model.h5\n",
      "Starting Camera...\n",
      "SPACEBAR to toggle modes | Q to Quit\n",
      "Switched Mode: True\n",
      "Switched Mode: False\n",
      "Switched Mode: True\n",
      "Switched Mode: False\n",
      "Switched Mode: True\n",
      "Switched Mode: False\n",
      "Switched Mode: True\n",
      "Switched Mode: False\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "WORD_MODEL_PATH = \"best_model.h5\"\n",
    "ALPHA_MODEL_PATH = \"asl_alphabet_model.h5\" # Or .keras if you are using the new format\n",
    "SPELLING_MODE = False  # Start in Word Mode\n",
    "MODE_SWITCH_COOLDOWN = 1.0\n",
    "last_switch_time = 0\n",
    "\n",
    "# Tuning Parameters\n",
    "WORD_THRESHOLD = 0.85\n",
    "ALPHA_THRESHOLD = 0.90\n",
    "VELOCITY_THRESHOLD = 0.02\n",
    "STABILITY_FRAMES = 5\n",
    "WORD_COOLDOWN = 2.0 \n",
    "\n",
    "WORD_CLASSES = [\n",
    "    \"me\", \"you\", \"we\", \"they\", \"she\",\n",
    "    \"who\", \"what\", \"yes\", \"no\", \"fine\", \"help\", \"meet\", \"good\",\n",
    "    \"want\", \"have\", \"like\", \"need\", \"go\", \"walk\", \n",
    "    \"play\", \"work\", \"learn\", \"eat\", \"drink\", \"finish\",\n",
    "    \"book\", \"family\", \"school\", \"computer\", \"deaf\"\n",
    "]\n",
    "\n",
    "ALPHABET_CLASSES = list(\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\")\n",
    "\n",
    "# --- LOAD RESOURCES ---\n",
    "print(\"Loading models...\")\n",
    "try:\n",
    "    word_model = tf.keras.models.load_model(WORD_MODEL_PATH)\n",
    "    print(f\"Word Model loaded: {WORD_MODEL_PATH}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading Word Model: {e}\")\n",
    "\n",
    "try:\n",
    "    # Try standard load first, fallback to Keras 3 if needed\n",
    "    try:\n",
    "        alpha_model = tf.keras.models.load_model(ALPHA_MODEL_PATH)\n",
    "    except:\n",
    "        import keras\n",
    "        alpha_model = keras.saving.load_model(ALPHA_MODEL_PATH)\n",
    "    print(f\"Alphabet Model loaded: {ALPHA_MODEL_PATH}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading Alphabet Model: {e}\")\n",
    "\n",
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# --- HELPER FUNCTIONS ---\n",
    "\n",
    "def extract_body_landmarks(results):\n",
    "    \"\"\" Extracts 225 landmarks (Pose+Left+Right) for the WORD model. \"\"\"\n",
    "    vec = []\n",
    "    if results.pose_landmarks:\n",
    "        for lm in results.pose_landmarks.landmark:\n",
    "            vec.extend([lm.x, lm.y, lm.z])\n",
    "    else: vec.extend([0.0]*99)\n",
    "    if results.left_hand_landmarks:\n",
    "        for lm in results.left_hand_landmarks.landmark:\n",
    "            vec.extend([lm.x, lm.y, lm.z])\n",
    "    else: vec.extend([0.0]*63)\n",
    "    if results.right_hand_landmarks:\n",
    "        for lm in results.right_hand_landmarks.landmark:\n",
    "            vec.extend([lm.x, lm.y, lm.z])\n",
    "    else: vec.extend([0.0]*63)\n",
    "    return vec\n",
    "\n",
    "def pre_process_word_input(data):\n",
    "    \"\"\" Resizes sequence to 30 frames for the WORD model. \"\"\"\n",
    "    df = pd.DataFrame(data)\n",
    "    df = df.replace(0.0, np.nan)\n",
    "    df = df.interpolate(method='linear', axis=0, limit_direction='both')\n",
    "    df = df.fillna(0.0)\n",
    "    data = df.values.astype(np.float32)\n",
    "    frames = data.reshape(-1, 75, 3)\n",
    "    for i in range(frames.shape[0]):\n",
    "        frame = frames[i]\n",
    "        left = frame[11]\n",
    "        right = frame[12]\n",
    "        center = (left + right) / 2.0\n",
    "        width = np.linalg.norm(left - right) + 1e-6\n",
    "        frame = (frame - center) / (width / 2.0)\n",
    "        frames[i] = frame\n",
    "    norm_seq = frames.reshape(-1, 225)\n",
    "    res = np.zeros((30, 225))\n",
    "    for j in range(225):\n",
    "        res[:, j] = np.interp(np.linspace(0, len(norm_seq)-1, 30), np.arange(len(norm_seq)), norm_seq[:, j])\n",
    "    return np.expand_dims(res, axis=0)\n",
    "\n",
    "def extract_hand_for_alphabet(hand_landmarks):\n",
    "    \"\"\" \n",
    "    UPDATED: Extracts 80 Features (Coords + Distances + Angles) \n",
    "    Matches your new Alphabet Model training logic.\n",
    "    \"\"\"\n",
    "    if not hand_landmarks: return None\n",
    "    \n",
    "    # 1. Convert to NumPy (21, 3)\n",
    "    landmarks = np.array([[lm.x, lm.y, lm.z] for lm in hand_landmarks.landmark])\n",
    "    \n",
    "    # 2. Normalize to Wrist\n",
    "    wrist = landmarks[0]\n",
    "    landmarks = landmarks - wrist\n",
    "    \n",
    "    # 3. Scale Normalization\n",
    "    scale = np.linalg.norm(landmarks[12]) + 1e-6\n",
    "    landmarks = landmarks / scale\n",
    "    \n",
    "    flat_coords = landmarks.flatten() # 63 features\n",
    "    \n",
    "    # 4. Calculate Distances (13 features)\n",
    "    distances = []\n",
    "    tips = [4, 8, 12, 16, 20] # Thumb, Index, Middle, Ring, Pinky Tips\n",
    "    \n",
    "    # A. Thumb to others\n",
    "    for i in range(1, 5):\n",
    "        d = np.linalg.norm(landmarks[tips[0]] - landmarks[tips[i]])\n",
    "        distances.append(d)\n",
    "    # B. Adjacent tips\n",
    "    for i in range(4):\n",
    "        d = np.linalg.norm(landmarks[tips[i]] - landmarks[tips[i+1]])\n",
    "        distances.append(d)\n",
    "    # C. Wrist to tips\n",
    "    for i in range(5):\n",
    "        d = np.linalg.norm(landmarks[tips[i]]) \n",
    "        distances.append(d)\n",
    "        \n",
    "    # 5. Calculate Angles (4 features)\n",
    "    vectors = []\n",
    "    finger_bases = [2, 5, 9, 13, 17] # Proximal joints\n",
    "    for i in range(5):\n",
    "        vec = landmarks[tips[i]] - landmarks[finger_bases[i]]\n",
    "        vectors.append(vec)\n",
    "        \n",
    "    angles = []\n",
    "    for i in range(4):\n",
    "        v1 = vectors[i]\n",
    "        v2 = vectors[i+1]\n",
    "        cosine = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2) + 1e-6)\n",
    "        angle = np.arccos(np.clip(cosine, -1.0, 1.0))\n",
    "        angles.append(angle)\n",
    "    \n",
    "    # Total: 63 + 13 + 4 = 80 Features\n",
    "    features = np.concatenate([flat_coords, np.array(distances), np.array(angles)])\n",
    "    return features.reshape(1, -1)\n",
    "\n",
    "# --- MAIN LOOP ---\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Buffers\n",
    "sequence_buffer = []\n",
    "prediction_history = []\n",
    "sentence = []\n",
    "current_display_text = \"\"\n",
    "prev_wrist_pos = None\n",
    "\n",
    "print(\"Starting Camera...\")\n",
    "print(\"SPACEBAR to toggle modes | Q to Quit\")\n",
    "\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret: break\n",
    "        \n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = holistic.process(image)\n",
    "        \n",
    "        # --- UI VISUALS ---\n",
    "        # ORANGE = WORD MODE (Default)\n",
    "        # PURPLE = SPELLING MODE\n",
    "        border_color = (255, 0, 255) if SPELLING_MODE else (0, 165, 255) \n",
    "        cv2.rectangle(frame, (0, 0), (640, 60), border_color, -1)\n",
    "        \n",
    "        mode_label = \"MODE: FINGERSPELLING (Letters)\" if SPELLING_MODE else \"MODE: SIGNING (Words)\"\n",
    "        cv2.putText(frame, mode_label, (10, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "        \n",
    "        active_hand = results.right_hand_landmarks if results.right_hand_landmarks else results.left_hand_landmarks\n",
    "        \n",
    "        # Draw Landmarks\n",
    "        if results.right_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(frame, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "        if results.left_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(frame, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "        \n",
    "        # ---------------------------------------------------------\n",
    "        # LOGIC BRANCH\n",
    "        # ---------------------------------------------------------\n",
    "        if active_hand:\n",
    "            # Calculate Velocity\n",
    "            curr_wrist = np.array([active_hand.landmark[0].x, active_hand.landmark[0].y])\n",
    "            velocity = 0.0\n",
    "            if prev_wrist_pos is not None:\n",
    "                velocity = np.linalg.norm(curr_wrist - prev_wrist_pos)\n",
    "            prev_wrist_pos = curr_wrist\n",
    "\n",
    "            # --- BRANCH 1: SPELLING MODE ---\n",
    "            if SPELLING_MODE:\n",
    "                # In spelling mode, we ONLY look for static letters (Low Velocity)\n",
    "                if velocity < VELOCITY_THRESHOLD:\n",
    "                    # UPDATED FUNCTION CALL\n",
    "                    hand_input = extract_hand_for_alphabet(active_hand)\n",
    "                    \n",
    "                    if hand_input is not None:\n",
    "                        pred = alpha_model.predict(hand_input, verbose=0)\n",
    "                        if np.max(pred) > ALPHA_THRESHOLD:\n",
    "                            candidate = ALPHABET_CLASSES[np.argmax(pred)]\n",
    "                            prediction_history.append(candidate)\n",
    "                        else:\n",
    "                            prediction_history.append(\"...\")\n",
    "                else:\n",
    "                    prediction_history.append(\"...\") # Hand moving = noise in spelling\n",
    "            \n",
    "            # --- BRANCH 2: SIGNING MODE (Default) ---\n",
    "            else:\n",
    "                # In signing mode, we ONLY look for Words\n",
    "                # Check for Word input (Velocity High)\n",
    "                if velocity > VELOCITY_THRESHOLD:\n",
    "                    landmarks = extract_body_landmarks(results)\n",
    "                    sequence_buffer.append(landmarks)\n",
    "                    if len(sequence_buffer) > 45: sequence_buffer.pop(0)\n",
    "                    \n",
    "                    if len(sequence_buffer) >= 30:\n",
    "                        input_data = pre_process_word_input(sequence_buffer)\n",
    "                        pred = word_model.predict(input_data, verbose=0)\n",
    "                        \n",
    "                        if np.max(pred) > WORD_THRESHOLD:\n",
    "                            candidate = WORD_CLASSES[np.argmax(pred)]\n",
    "                            prediction_history.append(candidate)\n",
    "                        else:\n",
    "                            prediction_history.append(\"...\")\n",
    "                else:\n",
    "                    prediction_history.append(\"...\")\n",
    "\n",
    "            # --- STABILITY & DISPLAY ---\n",
    "            if len(prediction_history) > STABILITY_FRAMES:\n",
    "                prediction_history = prediction_history[-STABILITY_FRAMES:]\n",
    "            \n",
    "            if len(prediction_history) == STABILITY_FRAMES and len(set(prediction_history)) == 1:\n",
    "                stable_pred = prediction_history[0]\n",
    "                if stable_pred != \"...\" and stable_pred != current_display_text:\n",
    "                    current_display_text = stable_pred\n",
    "                    \n",
    "                    # Logic: If spelling, just add letter. If word, add word + space.\n",
    "                    if SPELLING_MODE:\n",
    "                         sentence.append(current_display_text)\n",
    "                    else:\n",
    "                         sentence.append(current_display_text)\n",
    "                    \n",
    "                    if len(sentence) > 7: sentence = sentence[-7:]\n",
    "\n",
    "        # --- DRAW TEXT ---\n",
    "        cv2.putText(frame, f\"Prediction: {current_display_text}\", (10, 450), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        \n",
    "        sentence_str = \" \".join(sentence) if not SPELLING_MODE else \"\".join(sentence)\n",
    "        cv2.putText(frame, f\"Sentence: {sentence_str}\", (10, 400), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "        \n",
    "        cv2.imshow('Hybrid TalkSign System', frame)\n",
    "        \n",
    "        # --- KEYBOARD TOGGLE ---\n",
    "        key = cv2.waitKey(10) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "        elif key == 32: # SPACE BAR\n",
    "            # Debounce the toggle\n",
    "            if time.time() - last_switch_time > 0.5:\n",
    "                SPELLING_MODE = not SPELLING_MODE\n",
    "                prediction_history = [] # Clear history on switch\n",
    "                current_display_text = \"\"\n",
    "                last_switch_time = time.time()\n",
    "                print(f\"Switched Mode: {SPELLING_MODE}\")\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ee1bbaac-ef03-4912-a79f-62a887481459",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-generativeai in c:\\users\\user\\desktop\\jupyter notebook\\my_venv\\lib\\site-packages (0.8.6)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in c:\\users\\user\\desktop\\jupyter notebook\\my_venv\\lib\\site-packages (from google-generativeai) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in c:\\users\\user\\desktop\\jupyter notebook\\my_venv\\lib\\site-packages (from google-generativeai) (2.28.1)\n",
      "Requirement already satisfied: google-api-python-client in c:\\users\\user\\desktop\\jupyter notebook\\my_venv\\lib\\site-packages (from google-generativeai) (2.187.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\user\\desktop\\jupyter notebook\\my_venv\\lib\\site-packages (from google-generativeai) (2.45.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\user\\desktop\\jupyter notebook\\my_venv\\lib\\site-packages (from google-generativeai) (5.29.5)\n",
      "Requirement already satisfied: pydantic in c:\\users\\user\\desktop\\jupyter notebook\\my_venv\\lib\\site-packages (from google-generativeai) (2.12.5)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\desktop\\jupyter notebook\\my_venv\\lib\\site-packages (from google-generativeai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\user\\desktop\\jupyter notebook\\my_venv\\lib\\site-packages (from google-generativeai) (4.14.1)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\user\\desktop\\jupyter notebook\\my_venv\\lib\\site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.27.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\user\\desktop\\jupyter notebook\\my_venv\\lib\\site-packages (from google-api-core->google-generativeai) (1.72.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in c:\\users\\user\\desktop\\jupyter notebook\\my_venv\\lib\\site-packages (from google-api-core->google-generativeai) (2.32.4)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in c:\\users\\user\\desktop\\jupyter notebook\\my_venv\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.74.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in c:\\users\\user\\desktop\\jupyter notebook\\my_venv\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in c:\\users\\user\\desktop\\jupyter notebook\\my_venv\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (6.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\user\\desktop\\jupyter notebook\\my_venv\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\user\\desktop\\jupyter notebook\\my_venv\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\user\\desktop\\jupyter notebook\\my_venv\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\desktop\\jupyter notebook\\my_venv\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\desktop\\jupyter notebook\\my_venv\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\desktop\\jupyter notebook\\my_venv\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.8.3)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\user\\desktop\\jupyter notebook\\my_venv\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in c:\\users\\user\\desktop\\jupyter notebook\\my_venv\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.31.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\user\\desktop\\jupyter notebook\\my_venv\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.3.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\user\\desktop\\jupyter notebook\\my_venv\\lib\\site-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
      "Requirement already satisfied: pyparsing<4,>=3.0.4 in c:\\users\\user\\desktop\\jupyter notebook\\my_venv\\lib\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\user\\desktop\\jupyter notebook\\my_venv\\lib\\site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\user\\desktop\\jupyter notebook\\my_venv\\lib\\site-packages (from pydantic->google-generativeai) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\user\\desktop\\jupyter notebook\\my_venv\\lib\\site-packages (from pydantic->google-generativeai) (0.4.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\desktop\\jupyter notebook\\my_venv\\lib\\site-packages (from tqdm->google-generativeai) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -U google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f66b212e-30a8-4334-aec8-e18abad2e7d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local model: llama3.2\n",
      "RAW GLOSS                      | CORRECTED ENGLISH\n",
      "------------------------------------------------------------\n",
      "HELLO ME SEAN ME DEAF          | Hello, I am Sean, and I am deaf.\n",
      "YESTERDAY YOU SCHOOL GO        | You went to school yesterday.\n",
      "ME GO SCHOOL LEARN             | I go to school to learn.\n",
      "HELLO ME SEAN ME LIKE GO WORK  | Hello, I am Sean and I like to go to work.\n",
      "ME FINISH EAT                  | I finish eating.\n",
      "ME GO MEET FAMILY TOMORROW     | I will meet my family tomorrow.\n",
      "------------------------------------------------------------\n",
      "Total time: 5.52 seconds\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "import time\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "# We use 'llama3.2' because it is fast and runs easily on most laptops.\n",
    "# Ensure you ran \"ollama pull llama3.2\" in your terminal first.\n",
    "LOCAL_MODEL = \"llama3.2\" \n",
    "\n",
    "def correct_grammar_local(raw_gloss):\n",
    "    \"\"\"\n",
    "    Translates ASL Gloss to English using a LOCAL LLM (Ollama).\n",
    "    \"\"\"\n",
    "    \n",
    "    # We use the exact same prompt structure as your Gemini code\n",
    "    prompt = f\"\"\"\n",
    "    You are a strictly mechanical ASL-to-English translation engine. You do not speak to the user. You only output the translated sentence.\n",
    "\n",
    "    ### TRANSLATION RULES:\n",
    "    1. Syntax: Convert ASL Topic-Comment to English Subject-Verb-Object (SVO).\n",
    "    2. Tense: \"FINISH\" usually means past tense. Time markers (YESTERDAY) apply to the whole sentence.\n",
    "    3. Articles: Add \"the\", \"a\", \"is\", \"are\" where missing.\n",
    "    4. Pronouns: Convert \"ME\" -> \"I/My\", \"YOU\" -> \"You/Your\".\n",
    "    5. **GRAMMAR:** Convert Topic-Comment to SVO. Add \"is/am/are\" where needed.\n",
    "    6. **COMPLETENESS:** Do NOT summarize. You MUST include every name, place, word, gloss and noun found in the input.\n",
    "       - Example: \"ME SEAN\" -> \"I am Sean\". \n",
    "    7. Output: Just the translated sentence. No quotes.\n",
    "\n",
    "    \n",
    "    ASL Gloss: \"{raw_gloss}\"\n",
    "    English Translation:\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Send request to local Ollama instance\n",
    "        response = ollama.chat(model=LOCAL_MODEL, messages=[\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': prompt,\n",
    "            },\n",
    "        ])\n",
    "        \n",
    "        # Extract text content\n",
    "        return response['message']['content'].strip()\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"Local Logic Error: {e}\"\n",
    "\n",
    "# --- TEST SUITE ---\n",
    "test_sentences = [\n",
    "    \"HELLO ME SEAN ME DEAF\",\n",
    "    \"YESTERDAY YOU SCHOOL GO\",\n",
    "    \"ME GO SCHOOL LEARN\",\n",
    "    \"HELLO ME SEAN ME LIKE GO WORK\",\n",
    "    \"ME FINISH EAT\", \n",
    "    \"ME GO MEET FAMILY TOMORROW\"\n",
    "]\n",
    "\n",
    "print(f\"Running on local model: {LOCAL_MODEL}\")\n",
    "print(f\"{'RAW GLOSS':<30} | {'CORRECTED ENGLISH'}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for gloss in test_sentences:\n",
    "    english = correct_grammar_local(gloss)\n",
    "    print(f\"{gloss:<30} | {english}\")\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"-\" * 60)\n",
    "print(f\"Total time: {end_time - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3c3a560d-7e56-4c0a-b085-57df9980ab6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System Ready!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import pandas as pd\n",
    "import time\n",
    "import threading\n",
    "import ollama \n",
    "import os\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "WORD_MODEL_PATH = \"robust_word_model.h5\" \n",
    "ALPHA_MODEL_PATH = \"asl_alphabet_model.h5\"\n",
    "LOCAL_LLM_MODEL = \"llama3.2\" \n",
    "\n",
    "# Tuning Parameters\n",
    "WORD_THRESHOLD = 0.70\n",
    "ALPHA_THRESHOLD = 0.70\n",
    "STABILITY_FRAMES = 5\n",
    "PREDICTION_COOLDOWN = 0.75  \n",
    "AUTO_TRANSLATE_DELAY = 3.0 \n",
    "\n",
    "# NEW: Grace period for hand loss (prevent accidental resets)\n",
    "MISSING_HAND_TOLERANCE = 0.8 \n",
    "\n",
    "WORD_CLASSES = [\n",
    "    \"me\", \"you\", \"we\", \"they\", \"hello\", \n",
    "    \"who\", \"what\", \"yes\", \"no\", \"fine\", \"help\", \"meet\", \"good\",\n",
    "    \"want\", \"have\", \"like\", \"need\", \"go\", \"walk\", \n",
    "    \"play\", \"work\", \"learn\", \"eat\", \"drink\", \"finish\",\n",
    "    \"book\", \"family\", \"school\", \"computer\", \"deaf\", \"J\", \"Z\"\n",
    "]\n",
    "ALPHABET_CLASSES = list(\"ABCDEFGHIKLMNOPQRSTUVWXY\")\n",
    "\n",
    "# --- LOAD MODELS ---\n",
    "print(\"Loading Models...\")\n",
    "try:\n",
    "    word_model = tf.keras.models.load_model(WORD_MODEL_PATH)\n",
    "except:\n",
    "    word_model = keras.saving.load_model(WORD_MODEL_PATH)\n",
    "\n",
    "try:\n",
    "    alpha_model = tf.keras.models.load_model(ALPHA_MODEL_PATH)\n",
    "except:\n",
    "    alpha_model = keras.saving.load_model(ALPHA_MODEL_PATH)\n",
    "\n",
    "mp_holistic = mp.solutions.holistic\n",
    "print(\"System Ready!\")\n",
    "\n",
    "# --- HELPER: INPUT PROCESSING ---\n",
    "def extract_body_landmarks(results):\n",
    "    vec = []\n",
    "    if results.pose_landmarks:\n",
    "        for lm in results.pose_landmarks.landmark: vec.extend([lm.x, lm.y, lm.z])\n",
    "    else: vec.extend([0.0]*99)\n",
    "    if results.left_hand_landmarks:\n",
    "        for lm in results.left_hand_landmarks.landmark: vec.extend([lm.x, lm.y, lm.z])\n",
    "    else: vec.extend([0.0]*63)\n",
    "    if results.right_hand_landmarks:\n",
    "        for lm in results.right_hand_landmarks.landmark: vec.extend([lm.x, lm.y, lm.z])\n",
    "    else: vec.extend([0.0]*63)\n",
    "    return vec\n",
    "\n",
    "def pre_process_word_input(data):\n",
    "    df = pd.DataFrame(data).replace(0.0, np.nan).interpolate(limit_direction='both').fillna(0.0)\n",
    "    data = df.values.astype(np.float32).reshape(-1, 75, 3)\n",
    "    for i in range(data.shape[0]):\n",
    "        left, right = data[i, 11], data[i, 12] \n",
    "        center = (left + right) / 2.0\n",
    "        width = np.linalg.norm(left - right) + 1e-6\n",
    "        data[i] = (data[i] - center) / (width / 2.0)\n",
    "    norm_seq = data.reshape(-1, 225)\n",
    "    res = np.zeros((30, 225))\n",
    "    for j in range(225): res[:, j] = np.interp(np.linspace(0, len(norm_seq)-1, 30), np.arange(len(norm_seq)), norm_seq[:, j])\n",
    "    return np.expand_dims(res, axis=0)\n",
    "\n",
    "def extract_hand_for_alphabet(hand_landmarks):\n",
    "    if not hand_landmarks: return None\n",
    "    landmarks = np.array([[lm.x, lm.y, lm.z] for lm in hand_landmarks.landmark])\n",
    "    wrist = landmarks[0]\n",
    "    landmarks = landmarks - wrist\n",
    "    scale = np.linalg.norm(landmarks[12]) + 1e-6\n",
    "    landmarks = landmarks / scale\n",
    "    flat_coords = landmarks.flatten()\n",
    "    \n",
    "    distances = []\n",
    "    tips = [4, 8, 12, 16, 20] \n",
    "    for i in range(1, 5):\n",
    "        d = np.linalg.norm(landmarks[tips[0]] - landmarks[tips[i]])\n",
    "        distances.append(d)\n",
    "    for i in range(4):\n",
    "        d = np.linalg.norm(landmarks[tips[i]] - landmarks[tips[i+1]])\n",
    "        distances.append(d)\n",
    "    for i in range(5):\n",
    "        d = np.linalg.norm(landmarks[tips[i]]) \n",
    "        distances.append(d)\n",
    "        \n",
    "    vectors = []\n",
    "    finger_bases = [2, 5, 9, 13, 17] \n",
    "    for i in range(5):\n",
    "        vec = landmarks[tips[i]] - landmarks[finger_bases[i]]\n",
    "        vectors.append(vec)\n",
    "        \n",
    "    angles = []\n",
    "    for i in range(4):\n",
    "        v1 = vectors[i]\n",
    "        v2 = vectors[i+1]\n",
    "        cosine = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2) + 1e-6)\n",
    "        angle = np.arccos(np.clip(cosine, -1.0, 1.0))\n",
    "        angles.append(angle)\n",
    "    \n",
    "    features = np.concatenate([flat_coords, np.array(distances), np.array(angles)])\n",
    "    return features.reshape(1, -1)\n",
    "\n",
    "# --- HELPER: LOCAL GRAMMAR THREAD ---\n",
    "final_corrected_sentence = \"\"\n",
    "is_correcting = False\n",
    "last_translation_time = 0\n",
    "\n",
    "def correct_grammar_async(raw_text):\n",
    "    global final_corrected_sentence, is_correcting, last_translation_time\n",
    "    is_correcting = True\n",
    "    prompt = f\"\"\"\n",
    "    You are a strictly mechanical ASL-to-English translation engine. You do not speak to the user. You only output the translated sentence.\n",
    "\n",
    "    ### TRANSLATION RULES:\n",
    "    1. Syntax: Convert ASL Topic-Comment to English Subject-Verb-Object (SVO).\n",
    "    2. Tense: \"FINISH\" usually means past tense. Time markers (YESTERDAY) apply to the whole sentence.\n",
    "    3. Articles: Add \"the\", \"a\", \"is\", \"are\" where missing.\n",
    "    4. Pronouns: Convert \"ME\" -> \"I/My\", \"YOU\" -> \"You/Your\".\n",
    "    5. **GRAMMAR:** Convert Topic-Comment to SVO. Add \"is/am/are\" where needed.\n",
    "    6. **COMPLETENESS:** Do NOT summarize. You MUST include every name, place, word, gloss and noun found in the input.\n",
    "       - Example: \"ME SEAN\" -> \"I am Sean\". \n",
    "    7. Output: Just the translated sentence. No quotes.\n",
    "\n",
    "    ASL Gloss: \"{raw_text}\"\n",
    "    English Translation:\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = ollama.chat(model=LOCAL_LLM_MODEL, messages=[{'role': 'user', 'content': prompt}])\n",
    "        final_corrected_sentence = response['message']['content'].strip()\n",
    "        last_translation_time = time.time()\n",
    "    except Exception as e:\n",
    "        print(f\"LLM Error: {e}\")\n",
    "        final_corrected_sentence = \"Translation Error (Local)\"\n",
    "    is_correcting = False\n",
    "\n",
    "# --- MAIN LOOP ---\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Buffers\n",
    "sequence_buffer = []      \n",
    "prediction_history = []   \n",
    "raw_tokens = []           \n",
    "current_display_text = \"\"\n",
    "\n",
    "# Logic Flags\n",
    "SPELLING_MODE = False\n",
    "last_sign_time = time.time()\n",
    "hands_lost_time = None\n",
    "translation_triggered = False\n",
    "last_switch_time = 0\n",
    "\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret: break\n",
    "        \n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = holistic.process(image)\n",
    "        \n",
    "        hands_visible = (results.left_hand_landmarks is not None) or (results.right_hand_landmarks is not None)\n",
    "        active_hand = results.right_hand_landmarks or results.left_hand_landmarks\n",
    "        \n",
    "        # --- CALCULATE STATUS ---\n",
    "        time_since_sign = time.time() - last_sign_time\n",
    "        is_cooldown = time_since_sign < PREDICTION_COOLDOWN\n",
    "        \n",
    "        status_text = \"\"\n",
    "        status_color = (255, 255, 255)\n",
    "\n",
    "        if is_cooldown:\n",
    "            status_text = f\"COOLDOWN ({PREDICTION_COOLDOWN - time_since_sign:.1f}s)\"\n",
    "            status_color = (0, 165, 255) \n",
    "        elif not hands_visible:\n",
    "            status_text = \"WAITING...\"\n",
    "            status_color = (200, 200, 200) \n",
    "        else:\n",
    "            status_text = \"TRACKING...\"\n",
    "            status_color = (0, 255, 0) \n",
    "\n",
    "        # --- LOGIC HANDLING ---\n",
    "        \n",
    "        # 1. NO HANDS DETECTED\n",
    "        if not hands_visible:\n",
    "            if hands_lost_time is None:\n",
    "                hands_lost_time = time.time()\n",
    "            \n",
    "            time_missing = time.time() - hands_lost_time\n",
    "            \n",
    "            if time_missing > MISSING_HAND_TOLERANCE:\n",
    "                sequence_buffer = []\n",
    "                prediction_history = []\n",
    "                \n",
    "                if time_missing > AUTO_TRANSLATE_DELAY and not translation_triggered:\n",
    "                    if len(raw_tokens) > 0:\n",
    "                        full_text = \"\".join(raw_tokens).strip()\n",
    "                        threading.Thread(target=correct_grammar_async, args=(full_text,)).start()\n",
    "                        raw_tokens = [] \n",
    "                        current_display_text = \"\"\n",
    "                        translation_triggered = True\n",
    "\n",
    "            if final_corrected_sentence and (time.time() - last_translation_time > 4.0):\n",
    "                final_corrected_sentence = \"\"\n",
    "            \n",
    "        else:\n",
    "            hands_lost_time = None \n",
    "            translation_triggered = False\n",
    "            \n",
    "            if not is_cooldown:\n",
    "                if SPELLING_MODE:\n",
    "                    inp = extract_hand_for_alphabet(active_hand)\n",
    "                    if inp is not None:\n",
    "                        pred = alpha_model.predict(inp, verbose=0)\n",
    "                        if np.max(pred) > ALPHA_THRESHOLD:\n",
    "                            prediction_history.append(ALPHABET_CLASSES[np.argmax(pred)])\n",
    "                        else:\n",
    "                            prediction_history.append(\"...\")\n",
    "                else:\n",
    "                    landmarks = extract_body_landmarks(results)\n",
    "                    sequence_buffer.append(landmarks)\n",
    "                    if len(sequence_buffer) > 45: sequence_buffer.pop(0)\n",
    "                    \n",
    "                    if len(sequence_buffer) >= 30:\n",
    "                        inp = pre_process_word_input(sequence_buffer)\n",
    "                        pred = word_model.predict(inp, verbose=0)\n",
    "                        if np.max(pred) > WORD_THRESHOLD:\n",
    "                            prediction_history.append(WORD_CLASSES[np.argmax(pred)])\n",
    "                        else:\n",
    "                            prediction_history.append(\"...\")\n",
    "\n",
    "                if len(prediction_history) > STABILITY_FRAMES:\n",
    "                    prediction_history = prediction_history[-STABILITY_FRAMES:]\n",
    "                \n",
    "                if len(prediction_history) == STABILITY_FRAMES and len(set(prediction_history)) == 1:\n",
    "                    stable = prediction_history[0]\n",
    "                    if stable != \"...\" and stable != current_display_text:\n",
    "                        current_display_text = stable\n",
    "                        if SPELLING_MODE:\n",
    "                            raw_tokens.append(stable)\n",
    "                        else:\n",
    "                            raw_tokens.append(stable)\n",
    "                            raw_tokens.append(\" \")\n",
    "                        \n",
    "                        last_sign_time = time.time()\n",
    "                        sequence_buffer.clear()\n",
    "                        prediction_history = []\n",
    "\n",
    "        # --- UI DISPLAY (No Black Bar) ---\n",
    "        \n",
    "        # 1. Mode (Top Left)\n",
    "        mode_str = \"SPELLING\" if SPELLING_MODE else \"SIGNING\"\n",
    "        mode_color = (255, 0, 255) if SPELLING_MODE else (0, 255, 0)\n",
    "        # Draw outline for visibility\n",
    "        cv2.putText(frame, f\"MODE: {mode_str}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,0), 4)\n",
    "        cv2.putText(frame, f\"MODE: {mode_str}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, mode_color, 2)\n",
    "        \n",
    "        # 2. Status (Below Mode)\n",
    "        cv2.putText(frame, status_text, (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,0,0), 3)\n",
    "        cv2.putText(frame, status_text, (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.6, status_color, 1)\n",
    "\n",
    "        # 3. Raw Tokens (Bottom Center - dynamic position)\n",
    "        h, w, _ = frame.shape\n",
    "        raw_str = \"\".join(raw_tokens)\n",
    "        if len(raw_str) > 40: raw_str = \"...\" + raw_str[-40:]\n",
    "        \n",
    "        if raw_str:\n",
    "            cv2.putText(frame, f\"RAW: {raw_str}\", (10, h - 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,0), 4)\n",
    "            cv2.putText(frame, f\"RAW: {raw_str}\", (10, h - 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "        \n",
    "        # 4. Translation (Bottom Center)\n",
    "        final_str = \"Correcting...\" if is_correcting else final_corrected_sentence\n",
    "        txt_color = (0, 255, 255) if is_correcting else (0, 255, 0)\n",
    "        \n",
    "        if final_str:\n",
    "            cv2.putText(frame, final_str, (10, h - 20), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,0,0), 4)\n",
    "            cv2.putText(frame, final_str, (10, h - 20), cv2.FONT_HERSHEY_SIMPLEX, 0.8, txt_color, 2)\n",
    "\n",
    "        # Draw Skeleton\n",
    "        if results.pose_landmarks:\n",
    "             mp.solutions.drawing_utils.draw_landmarks(frame, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                mp.solutions.drawing_utils.DrawingSpec(color=(255,255,255), thickness=1, circle_radius=1),\n",
    "                mp.solutions.drawing_utils.DrawingSpec(color=(180,180,180), thickness=1, circle_radius=1))\n",
    "        if results.right_hand_landmarks:\n",
    "            mp.solutions.drawing_utils.draw_landmarks(frame, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "        if results.left_hand_landmarks:\n",
    "            mp.solutions.drawing_utils.draw_landmarks(frame, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "\n",
    "        cv2.imshow('TalkSign Final (Clean UI)', frame)\n",
    "        \n",
    "        key = cv2.waitKey(10) & 0xFF\n",
    "        if key == ord('q'): break\n",
    "        elif key == 32: # SPACEBAR\n",
    "            if time.time() - last_switch_time > 0.5:\n",
    "                SPELLING_MODE = not SPELLING_MODE\n",
    "                if raw_tokens and raw_tokens[-1] != \" \": raw_tokens.append(\" \")\n",
    "                prediction_history = []\n",
    "                last_switch_time = time.time()\n",
    "        elif key == ord('c'):\n",
    "            raw_tokens = []\n",
    "            final_corrected_sentence = \"\"\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ac9191d-5354-4f5b-92bc-decf384d1c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\JUPYTER NOTEBOOK\\my_venv\\Lib\\site-packages\\keras\\src\\export\\tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Models...\n",
      "Loaded Robust Model: robust_word_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Alphabet Model: asl_alphabet_model.h5\n",
      "System Ready!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import tensorflow as tf\n",
    "import keras # Added for Keras 3 compatibility\n",
    "import pandas as pd\n",
    "import time\n",
    "import threading\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "WORD_MODEL_PATH = \"robust_word_model.h5\"\n",
    "ALPHA_MODEL_PATH = \"asl_alphabet_model.h5\"\n",
    "\n",
    "# Google Gemini API Key\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"API_KEY_HERE\" \n",
    "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
    "grammar_model = genai.GenerativeModel('gemini-2.5-flash') \n",
    "\n",
    "# Tuning Parameters\n",
    "WORD_THRESHOLD = 0.75\n",
    "ALPHA_THRESHOLD = 0.95\n",
    "STABILITY_FRAMES = 5\n",
    "PREDICTION_COOLDOWN = 1.25  # Seconds to wait after a sign\n",
    "AUTO_TRANSLATE_DELAY = 3.0 # Seconds of \"no hands\" before grammar check\n",
    "\n",
    "WORD_CLASSES = [\n",
    "    \"me\", \"you\", \"we\", \"they\", \"hello\", # 'she' -> 'hello'\n",
    "    \"who\", \"what\", \"yes\", \"no\", \"fine\", \"help\", \"meet\", \"good\",\n",
    "    \"want\", \"have\", \"like\", \"need\", \"go\", \"walk\", \n",
    "    \"play\", \"work\", \"learn\", \"eat\", \"drink\", \"finish\",\n",
    "    \"book\", \"family\", \"school\", \"computer\", \"deaf\", \"j\", \"z\"\n",
    "]\n",
    "ALPHABET_CLASSES = list(\"ABCDEFGHIKLMNOPQRSTUVWXY\")\n",
    "\n",
    "# --- LOAD MODELS (Robust Loading) ---\n",
    "print(\"Loading Models...\")\n",
    "try:\n",
    "    word_model = tf.keras.models.load_model(WORD_MODEL_PATH)\n",
    "except:\n",
    "    word_model = keras.saving.load_model(WORD_MODEL_PATH)\n",
    "\n",
    "try:\n",
    "    # Try standard load first, fallback to Keras 3 if needed\n",
    "    alpha_model = tf.keras.models.load_model(ALPHA_MODEL_PATH)\n",
    "except:\n",
    "    alpha_model = keras.saving.load_model(ALPHA_MODEL_PATH)\n",
    "\n",
    "mp_holistic = mp.solutions.holistic\n",
    "print(\"System Ready!\")\n",
    "\n",
    "# --- HELPER: INPUT PROCESSING ---\n",
    "def extract_body_landmarks(results):\n",
    "    vec = []\n",
    "    if results.pose_landmarks:\n",
    "        for lm in results.pose_landmarks.landmark: vec.extend([lm.x, lm.y, lm.z])\n",
    "    else: vec.extend([0.0]*99)\n",
    "    if results.left_hand_landmarks:\n",
    "        for lm in results.left_hand_landmarks.landmark: vec.extend([lm.x, lm.y, lm.z])\n",
    "    else: vec.extend([0.0]*63)\n",
    "    if results.right_hand_landmarks:\n",
    "        for lm in results.right_hand_landmarks.landmark: vec.extend([lm.x, lm.y, lm.z])\n",
    "    else: vec.extend([0.0]*63)\n",
    "    return vec\n",
    "\n",
    "def pre_process_word_input(data):\n",
    "    df = pd.DataFrame(data).replace(0.0, np.nan).interpolate(limit_direction='both').fillna(0.0)\n",
    "    data = df.values.astype(np.float32).reshape(-1, 75, 3)\n",
    "    for i in range(data.shape[0]):\n",
    "        left, right = data[i, 11], data[i, 12] \n",
    "        center = (left + right) / 2.0\n",
    "        width = np.linalg.norm(left - right) + 1e-6\n",
    "        data[i] = (data[i] - center) / (width / 2.0)\n",
    "    norm_seq = data.reshape(-1, 225)\n",
    "    res = np.zeros((30, 225))\n",
    "    for j in range(225): res[:, j] = np.interp(np.linspace(0, len(norm_seq)-1, 30), np.arange(len(norm_seq)), norm_seq[:, j])\n",
    "    return np.expand_dims(res, axis=0)\n",
    "\n",
    "def extract_hand_for_alphabet(hand_landmarks):\n",
    "    \"\"\"\n",
    "    UPDATED: Extracts 80 Features (Coords + Distances + Angles)\n",
    "    Matches the 'Pro' Alphabet Model logic.\n",
    "    \"\"\"\n",
    "    if not hand_landmarks: return None\n",
    "    \n",
    "    # 1. Convert to NumPy (21, 3)\n",
    "    landmarks = np.array([[lm.x, lm.y, lm.z] for lm in hand_landmarks.landmark])\n",
    "    \n",
    "    # 2. Normalize to Wrist\n",
    "    wrist = landmarks[0]\n",
    "    landmarks = landmarks - wrist\n",
    "    \n",
    "    # 3. Scale Normalization (by Middle Finger Length)\n",
    "    scale = np.linalg.norm(landmarks[12]) + 1e-6\n",
    "    landmarks = landmarks / scale\n",
    "    \n",
    "    flat_coords = landmarks.flatten() # 63 features\n",
    "    \n",
    "    # 4. Calculate Distances (13 features)\n",
    "    distances = []\n",
    "    tips = [4, 8, 12, 16, 20] # Thumb, Index, Middle, Ring, Pinky Tips\n",
    "    \n",
    "    # A. Thumb to others\n",
    "    for i in range(1, 5):\n",
    "        d = np.linalg.norm(landmarks[tips[0]] - landmarks[tips[i]])\n",
    "        distances.append(d)\n",
    "    # B. Adjacent tips\n",
    "    for i in range(4):\n",
    "        d = np.linalg.norm(landmarks[tips[i]] - landmarks[tips[i+1]])\n",
    "        distances.append(d)\n",
    "    # C. Wrist to tips\n",
    "    for i in range(5):\n",
    "        d = np.linalg.norm(landmarks[tips[i]]) \n",
    "        distances.append(d)\n",
    "        \n",
    "    # 5. Calculate Angles (4 features)\n",
    "    vectors = []\n",
    "    finger_bases = [2, 5, 9, 13, 17] # Proximal joints\n",
    "    for i in range(5):\n",
    "        vec = landmarks[tips[i]] - landmarks[finger_bases[i]]\n",
    "        vectors.append(vec)\n",
    "        \n",
    "    angles = []\n",
    "    for i in range(4):\n",
    "        v1 = vectors[i]\n",
    "        v2 = vectors[i+1]\n",
    "        cosine = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2) + 1e-6)\n",
    "        angle = np.arccos(np.clip(cosine, -1.0, 1.0))\n",
    "        angles.append(angle)\n",
    "    \n",
    "    # Total: 63 + 13 + 4 = 80 Features\n",
    "    features = np.concatenate([flat_coords, np.array(distances), np.array(angles)])\n",
    "    return features.reshape(1, -1)\n",
    "\n",
    "# --- HELPER: GRAMMAR THREAD ---\n",
    "final_corrected_sentence = \"\"\n",
    "is_correcting = False\n",
    "last_translation_time = 0\n",
    "\n",
    "def correct_grammar_async(raw_text):\n",
    "    global final_corrected_sentence, is_correcting, last_translation_time\n",
    "    is_correcting = True\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert ASL (American Sign Language) interpreter. \n",
    "    Translate the following ASL Gloss into natural, spoken English.\n",
    "    \n",
    "    - Fix the grammar, word order, and tense.\n",
    "    - Convert pronouns (ME -> I/My) correctly based on context.\n",
    "    - Do not output quotation marks or explanations. Just the sentence.\n",
    "    - If the glosses seems ambiguous, translate them to the closest sentence you can form\n",
    "\n",
    "    ASL Gloss: \"{raw_text}\"\n",
    "    English Translation:\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = grammar_model.generate_content(prompt)\n",
    "        final_corrected_sentence = response.text.strip()\n",
    "        last_translation_time = time.time() # Mark time for auto-clear\n",
    "    except:\n",
    "        final_corrected_sentence = \"Translation Error\"\n",
    "    is_correcting = False\n",
    "\n",
    "# --- MAIN LOOP ---\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Buffers\n",
    "sequence_buffer = []      \n",
    "prediction_history = []   \n",
    "raw_tokens = []           \n",
    "current_display_text = \"\"\n",
    "\n",
    "# Logic Flags\n",
    "SPELLING_MODE = False\n",
    "last_sign_time = time.time()\n",
    "hands_lost_time = None\n",
    "translation_triggered = False\n",
    "last_switch_time = 0\n",
    "\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret: break\n",
    "        \n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = holistic.process(image)\n",
    "        \n",
    "        hands_visible = (results.left_hand_landmarks is not None) or (results.right_hand_landmarks is not None)\n",
    "        active_hand = results.right_hand_landmarks or results.left_hand_landmarks\n",
    "        \n",
    "        # --- CALCULATE STATUS ---\n",
    "        time_since_sign = time.time() - last_sign_time\n",
    "        is_cooldown = time_since_sign < PREDICTION_COOLDOWN\n",
    "        \n",
    "        status_text = \"\"\n",
    "        status_color = (255, 255, 255)\n",
    "\n",
    "        if is_cooldown:\n",
    "            status_text = f\"COOLDOWN ({PREDICTION_COOLDOWN - time_since_sign:.1f}s)\"\n",
    "            status_color = (0, 165, 255) # Orange\n",
    "        \n",
    "        elif not hands_visible:\n",
    "            status_text = \"WAITING FOR HANDS...\"\n",
    "            status_color = (100, 100, 100) # Gray\n",
    "        \n",
    "        else:\n",
    "            status_text = \"TRACKING...\"\n",
    "            status_color = (0, 255, 0) # Green\n",
    "\n",
    "        # --- LOGIC HANDLING ---\n",
    "        \n",
    "        # 1. AUTO-TRANSLATE & CLEANUP (No Hands Logic)\n",
    "        if not hands_visible:\n",
    "            if hands_lost_time is None:\n",
    "                hands_lost_time = time.time()\n",
    "            \n",
    "            elif (time.time() - hands_lost_time > AUTO_TRANSLATE_DELAY) and not translation_triggered:\n",
    "                if len(raw_tokens) > 0:\n",
    "                    full_text = \"\".join(raw_tokens).strip()\n",
    "                    threading.Thread(target=correct_grammar_async, args=(full_text,)).start()\n",
    "                    raw_tokens = [] \n",
    "                    current_display_text = \"\"\n",
    "                    translation_triggered = True\n",
    "\n",
    "            # Auto-Clear Translated Text (e.g. 4 seconds after translation appears)\n",
    "            if final_corrected_sentence and (time.time() - last_translation_time > 4.0):\n",
    "                final_corrected_sentence = \"\"\n",
    "\n",
    "            # Force Clean Slate\n",
    "            sequence_buffer = []\n",
    "            prediction_history = []\n",
    "            \n",
    "        else:\n",
    "            # Hands Visible Logic\n",
    "            hands_lost_time = None\n",
    "            translation_triggered = False\n",
    "            \n",
    "            # If in cooldown, we just wait. If not, we predict.\n",
    "            if not is_cooldown:\n",
    "                if SPELLING_MODE:\n",
    "                    # ALPHABET MODE\n",
    "                    inp = extract_hand_for_alphabet(active_hand)\n",
    "                    if inp is not None:\n",
    "                        pred = alpha_model.predict(inp, verbose=0)\n",
    "                        if np.max(pred) > ALPHA_THRESHOLD:\n",
    "                            prediction_history.append(ALPHABET_CLASSES[np.argmax(pred)])\n",
    "                        else:\n",
    "                            prediction_history.append(\"...\")\n",
    "                else:\n",
    "                    # WORD MODE\n",
    "                    landmarks = extract_body_landmarks(results)\n",
    "                    sequence_buffer.append(landmarks)\n",
    "                    if len(sequence_buffer) > 45: sequence_buffer.pop(0)\n",
    "                    \n",
    "                    if len(sequence_buffer) >= 30:\n",
    "                        inp = pre_process_word_input(sequence_buffer)\n",
    "                        pred = word_model.predict(inp, verbose=0)\n",
    "                        if np.max(pred) > WORD_THRESHOLD:\n",
    "                            prediction_history.append(WORD_CLASSES[np.argmax(pred)])\n",
    "                        else:\n",
    "                            prediction_history.append(\"...\")\n",
    "\n",
    "                # Stability Check\n",
    "                if len(prediction_history) > STABILITY_FRAMES:\n",
    "                    prediction_history = prediction_history[-STABILITY_FRAMES:]\n",
    "                \n",
    "                if len(prediction_history) == STABILITY_FRAMES and len(set(prediction_history)) == 1:\n",
    "                    stable = prediction_history[0]\n",
    "                    \n",
    "                    if stable != \"...\" and stable != current_display_text:\n",
    "                        current_display_text = stable\n",
    "                        if SPELLING_MODE:\n",
    "                            raw_tokens.append(stable)\n",
    "                        else:\n",
    "                            raw_tokens.append(stable)\n",
    "                            raw_tokens.append(\" \")\n",
    "                        \n",
    "                        # --- CLEAN SLATE TRIGGER ---\n",
    "                        last_sign_time = time.time() # Trigger Cooldown\n",
    "                        sequence_buffer.clear()      # Throw away frames used for this sign\n",
    "                        prediction_history = []      # Reset stability history\n",
    "\n",
    "        # --- UI DISPLAY ---\n",
    "        cv2.rectangle(frame, (0, 0), (640, 180), (30, 30, 30), -1)\n",
    "        \n",
    "        # Line 1: Mode (Always Visible)\n",
    "        mode_str = \"MODE: SPELLING (Letters)\" if SPELLING_MODE else \"MODE: SIGNING (Words)\"\n",
    "        mode_color = (255, 0, 255) if SPELLING_MODE else (0, 255, 0) # Purple / Green\n",
    "        cv2.putText(frame, mode_str, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, mode_color, 2)\n",
    "        \n",
    "        # Line 2: Status (Cooldown / Waiting / Tracking)\n",
    "        cv2.putText(frame, f\"STATUS: {status_text}\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.6, status_color, 1)\n",
    "\n",
    "        # Line 3: Raw Text\n",
    "        raw_str = \"\".join(raw_tokens)\n",
    "        if len(raw_str) > 40: raw_str = \"...\" + raw_str[-40:]\n",
    "        cv2.putText(frame, f\"RAW: {raw_str}\", (10, 100), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "        \n",
    "        # Line 4: Final Translation\n",
    "        final_str = \"Correcting Grammar...\" if is_correcting else final_corrected_sentence\n",
    "        txt_color = (0, 255, 255) if is_correcting else (0, 255, 0)\n",
    "        cv2.putText(frame, f\"FINAL: {final_str}\", (10, 150), cv2.FONT_HERSHEY_SIMPLEX, 0.7, txt_color, 2)\n",
    "\n",
    "        # Draw Skeleton\n",
    "        if results.pose_landmarks:\n",
    "             mp.solutions.drawing_utils.draw_landmarks(frame, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                mp.solutions.drawing_utils.DrawingSpec(color=(255,255,255), thickness=1, circle_radius=1),\n",
    "                mp.solutions.drawing_utils.DrawingSpec(color=(180,180,180), thickness=1, circle_radius=1))\n",
    "        if results.right_hand_landmarks:\n",
    "            mp.solutions.drawing_utils.draw_landmarks(frame, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "        if results.left_hand_landmarks:\n",
    "            mp.solutions.drawing_utils.draw_landmarks(frame, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "\n",
    "        cv2.imshow('TalkSign Final', frame)\n",
    "        \n",
    "        # --- INPUTS ---\n",
    "        key = cv2.waitKey(10) & 0xFF\n",
    "        if key == ord('q'): break\n",
    "        elif key == 32: # SPACEBAR (Toggle Mode)\n",
    "            if time.time() - last_switch_time > 0.5:\n",
    "                SPELLING_MODE = not SPELLING_MODE\n",
    "                if raw_tokens and raw_tokens[-1] != \" \": raw_tokens.append(\" \")\n",
    "                prediction_history = []\n",
    "                last_switch_time = time.time()\n",
    "        elif key == ord('c'):\n",
    "            raw_tokens = []\n",
    "            final_corrected_sentence = \"\"\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
